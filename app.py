import streamlit as st
import fitz  # PyMuPDF
import google.generativeai as genai
import re
import json
import genanki
import tempfile
import os
import io
import uuid
import concurrent.futures
import random
import sys
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path
from openai import OpenAI
from docx import Document
from docx.oxml import OxmlElement
from pptx import Presentation
from difflib import SequenceMatcher
import subprocess
import shutil
import base64
import zipfile
import xml.etree.ElementTree as ET
import importlib.util
import hashlib
import requests

# ============================================================================
# ê°ì‚¬ ë¡œê·¸ (append-only JSONL)
# ============================================================================
def _hash_text(text: str) -> str:
    if not text:
        return ""
    return hashlib.sha256(text.encode("utf-8")).hexdigest()[:16]

def append_audit_log(event: str, payload: dict, user_id=None):
    try:
        row = {
            "run_id": str(int(time.time() * 1000)),
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "event": event,
            **(payload or {}),
        }
        with open(get_audit_log_file(user_id=user_id), "a", encoding="utf-8") as f:
            f.write(json.dumps(row, ensure_ascii=False) + "\n")
    except Exception:
        # ê°ì‚¬ ë¡œê·¸ ì‹¤íŒ¨ëŠ” ì•± ì‹¤í–‰ì„ ë§‰ì§€ ì•ŠìŒ
        pass

def _gemini_usage_tokens(response):
    usage = getattr(response, "usage_metadata", None)
    if not usage:
        return None
    total = getattr(usage, "total_token_count", None)
    if total is not None:
        return total
    prompt_t = getattr(usage, "prompt_token_count", None)
    cand_t = getattr(usage, "candidates_token_count", None)
    if prompt_t is None and cand_t is None:
        return None
    return (prompt_t or 0) + (cand_t or 0)

def _openai_usage_tokens(response):
    usage = getattr(response, "usage", None)
    if usage is None:
        return None
    if isinstance(usage, dict):
        return usage.get("total_tokens", None)
    return getattr(usage, "total_tokens", None)
# FSRS (optional)
try:
    from fsrs import Scheduler, Card, Rating, ReviewLog
    FSRS_AVAILABLE = True
except Exception:
    FSRS_AVAILABLE = False

FSRS_DEFAULT_PARAMETERS = (
    0.212, 1.2931, 2.3065, 8.2956, 6.4133, 0.8334, 3.0194, 0.001,
    1.8722, 0.1666, 0.796, 1.4835, 0.0614, 0.2629, 1.6483, 0.6014,
    1.8729, 0.5425, 0.0912, 0.0658, 0.1542,
)

MODE_MCQ = "ğŸ“ ê°ê´€ì‹ ë¬¸ì œ (Case Study)"
MODE_CLOZE = "ğŸ§© ë¹ˆì¹¸ ëš«ê¸° (Anki Cloze)"
MODE_SHORT = "ğŸ§  ë‹¨ë‹µí˜• ë¬¸ì œ"
MODE_ESSAY = "ğŸ§¾ ì„œìˆ í˜• ë¬¸ì œ"

# ============================================================================
# ì´ˆê¸° ì„¤ì •
# ============================================================================
st.set_page_config(page_title="Axioma Qbank", page_icon="ğŸ§¬", layout="wide")

def get_app_data_dir():
    env_dir = os.getenv("AXIOMA_QBANK_DATA_DIR", "").strip() or os.getenv("MEDTUTOR_DATA_DIR", "").strip()
    if env_dir:
        base = Path(env_dir).expanduser()
        try:
            base.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass
        return base
    if getattr(sys, "frozen", False):
        new_base = Path.home() / "AxiomaQbank"
        old_base = Path.home() / "MedTutor"
        base = old_base if old_base.exists() and not new_base.exists() else new_base
        try:
            base.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass
        return base
    base = Path.cwd()
    try:
        base.mkdir(parents=True, exist_ok=True)
    except Exception:
        pass
    return base

DATA_DIR = get_app_data_dir()
QUESTION_BANK_FILE = str(DATA_DIR / "questions.json")
EXAM_HISTORY_FILE = str(DATA_DIR / "exam_history.json")
USER_SETTINGS_FILE = str(DATA_DIR / "user_settings.json")
AUDIT_LOG_FILE = str(DATA_DIR / "audit_log.jsonl")
AUTH_USERS_FILE = str(DATA_DIR / "auth_users.json")
SUPABASE_URL = os.getenv("SUPABASE_URL", "").rstrip("/")
SUPABASE_ANON_KEY = os.getenv("SUPABASE_ANON_KEY", "")
SUPABASE_TABLE = "medtutor_user_data"

def sanitize_user_id(user_id):
    text = (user_id or "").strip()
    if not text:
        return "guest"
    return re.sub(r"[^a-zA-Z0-9._-]", "_", text)[:80] or "guest"

def is_valid_email(value):
    text = (value or "").strip()
    return bool(re.match(r"^[^@\s]+@[^@\s]+\.[^@\s]+$", text))

def get_current_user_id():
    return sanitize_user_id(st.session_state.get("auth_user_id", "guest"))

def get_user_data_dir(user_id=None):
    uid = sanitize_user_id(user_id) if user_id is not None else get_current_user_id()
    base = DATA_DIR / "users" / uid
    try:
        base.mkdir(parents=True, exist_ok=True)
    except Exception:
        pass
    return base

def get_question_bank_file(user_id=None):
    return str(get_user_data_dir(user_id) / "questions.json")

def get_exam_history_file(user_id=None):
    return str(get_user_data_dir(user_id) / "exam_history.json")

def get_user_settings_file(user_id=None):
    return str(get_user_data_dir(user_id) / "user_settings.json")

def get_audit_log_file(user_id=None):
    return str(get_user_data_dir(user_id) / "audit_log.jsonl")

MODEL_PRICING_USD_PER_1M = {
    "gpt-4o-mini": {"input": 0.15, "output": 0.60, "blended": 0.30},
    "gemini-2.5-flash-lite": {"input": 0.10, "output": 0.40, "blended": 0.20},
    "gemini-2.5-flash": {"input": 0.30, "output": 2.50, "blended": 0.90},
}

def get_configured_admin_users():
    raw = os.getenv("AXIOMA_ADMIN_USERS", "").strip()
    if not raw:
        raw = os.getenv("MEDTUTOR_ADMIN_USERS", "").strip()
    users = set()
    for token in raw.split(","):
        value = token.strip()
        if value:
            users.add(value.lower())
    return users

def is_admin_user():
    admins = get_configured_admin_users()
    if not admins:
        return False
    uid = str(st.session_state.get("auth_user_id", "")).strip().lower()
    email = str(st.session_state.get("auth_email", "")).strip().lower()
    return uid in admins or email in admins

def list_local_user_ids():
    users_dir = DATA_DIR / "users"
    if not users_dir.exists():
        return []
    result = []
    for item in users_dir.iterdir():
        if item.is_dir():
            result.append(item.name)
    return sorted(result)

def read_audit_rows_for_user(user_id):
    rows = []
    path = Path(get_audit_log_file(user_id))
    if not path.exists():
        return rows
    try:
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    row = json.loads(line)
                except Exception:
                    continue
                if isinstance(row, dict):
                    rows.append(row)
    except Exception:
        return []
    return rows

def summarize_usage_rows(rows):
    summary_by_model = {}
    for row in rows:
        model = str(row.get("model") or "unknown")
        event = str(row.get("event") or "")
        usage_tokens = row.get("usage_tokens")
        item = summary_by_model.setdefault(
            model,
            {
                "calls": 0,
                "tokens": 0,
                "gen_calls": 0,
                "grade_calls": 0,
            },
        )
        item["calls"] += 1
        if isinstance(usage_tokens, int):
            item["tokens"] += usage_tokens
        if event == "gen.question":
            item["gen_calls"] += 1
        if event.startswith("grade."):
            item["grade_calls"] += 1
    return summary_by_model

def estimate_cost_usd_from_summary(summary_by_model):
    total = 0.0
    breakdown = []
    for model, item in summary_by_model.items():
        tokens = int(item.get("tokens", 0))
        price = MODEL_PRICING_USD_PER_1M.get(model, {}).get("blended")
        if price is None:
            usd = None
        else:
            usd = (tokens / 1_000_000.0) * price
            total += usd
        breakdown.append(
            {
                "model": model,
                "calls": int(item.get("calls", 0)),
                "tokens": tokens,
                "est_cost_usd": usd,
                "gen_calls": int(item.get("gen_calls", 0)),
                "grade_calls": int(item.get("grade_calls", 0)),
            }
        )
    breakdown.sort(key=lambda x: (x["tokens"], x["calls"]), reverse=True)
    return total, breakdown

def is_supabase_enabled():
    return bool(SUPABASE_URL and SUPABASE_ANON_KEY)

def is_supabase_required():
    value = os.getenv("AXIOMA_REQUIRE_SUPABASE", "1").strip().lower()
    return value not in {"0", "false", "no", "off"}

if is_supabase_required() and not is_supabase_enabled():
    st.title("Axioma Qbank")
    st.error("ì´ ë°°í¬ëŠ” Supabase ì¸ì¦/ì €ì¥ì„ í•„ìˆ˜ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    st.info("Secretsì— SUPABASE_URL, SUPABASE_ANON_KEYë¥¼ ì„¤ì •í•œ ë’¤ ì•±ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.")
    st.stop()

def _supabase_headers(access_token=None):
    token = access_token or SUPABASE_ANON_KEY
    return {
        "apikey": SUPABASE_ANON_KEY,
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
    }

def _supabase_error_message(response):
    try:
        data = response.json()
        return data.get("msg") or data.get("error_description") or data.get("message") or f"HTTP {response.status_code}"
    except Exception:
        return f"HTTP {response.status_code}"

def _default_remote_bundle():
    return {
        "questions": {"text": [], "cloze": []},
        "exam_history": [],
        "user_settings": {},
    }

def _normalize_remote_bundle(bundle):
    data = bundle if isinstance(bundle, dict) else {}
    questions = data.get("questions")
    exam_history = data.get("exam_history")
    user_settings = data.get("user_settings")
    return {
        "questions": questions if isinstance(questions, dict) else {"text": [], "cloze": []},
        "exam_history": exam_history if isinstance(exam_history, list) else [],
        "user_settings": user_settings if isinstance(user_settings, dict) else {},
    }

def supabase_sign_up(email, password):
    if not is_supabase_enabled():
        return False, "SUPABASE_URL / SUPABASE_ANON_KEY ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
    payload = {"email": (email or "").strip(), "password": password or ""}
    if not payload["email"]:
        return False, "ì´ë©”ì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    if len(payload["password"]) < 6:
        return False, "ë¹„ë°€ë²ˆí˜¸ëŠ” 6ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤."
    resp = requests.post(
        f"{SUPABASE_URL}/auth/v1/signup",
        headers=_supabase_headers(),
        json=payload,
        timeout=10,
    )
    if resp.status_code not in (200, 201):
        return False, _supabase_error_message(resp)
    return True, "íšŒì›ê°€ì…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë©”ì¼ ì¸ì¦ ì„¤ì •ì´ ì¼œì ¸ ìˆë‹¤ë©´ ì¸ì¦ í›„ ë¡œê·¸ì¸í•˜ì„¸ìš”."

def supabase_sign_in(email, password):
    if not is_supabase_enabled():
        return False, "SUPABASE_URL / SUPABASE_ANON_KEY ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
    payload = {"email": (email or "").strip(), "password": password or ""}
    if not payload["email"] or not payload["password"]:
        return False, "ì´ë©”ì¼ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    resp = requests.post(
        f"{SUPABASE_URL}/auth/v1/token?grant_type=password",
        headers=_supabase_headers(),
        json=payload,
        timeout=10,
    )
    if resp.status_code != 200:
        return False, _supabase_error_message(resp)
    data = resp.json() or {}
    access_token = data.get("access_token")
    user = data.get("user") or {}
    user_id = user.get("id")
    email_value = user.get("email") or payload["email"]
    if not access_token or not user_id:
        return False, "ë¡œê·¸ì¸ í† í° ì •ë³´ë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    return True, {"user_id": user_id, "email": email_value, "access_token": access_token}

def supabase_fetch_user_bundle(user_id, access_token):
    if not (is_supabase_enabled() and user_id and access_token):
        return None
    params = {"select": "questions,exam_history,user_settings", "user_id": f"eq.{user_id}"}
    resp = requests.get(
        f"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE}",
        headers=_supabase_headers(access_token),
        params=params,
        timeout=10,
    )
    if resp.status_code != 200:
        return None
    rows = resp.json() or []
    if not rows:
        return _default_remote_bundle()
    return _normalize_remote_bundle(rows[0])

def supabase_upsert_user_bundle(user_id, access_token, bundle):
    if not (is_supabase_enabled() and user_id and access_token):
        return False
    body = {
        "user_id": user_id,
        "questions": (bundle or {}).get("questions", {"text": [], "cloze": []}),
        "exam_history": (bundle or {}).get("exam_history", []),
        "user_settings": (bundle or {}).get("user_settings", {}),
        "updated_at": datetime.now(timezone.utc).isoformat(),
    }
    headers = _supabase_headers(access_token)
    headers["Prefer"] = "resolution=merge-duplicates,return=representation"
    resp = requests.post(
        f"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE}",
        headers=headers,
        json=body,
        timeout=10,
    )
    return resp.status_code in (200, 201)

def use_remote_user_store(user_id=None):
    if not is_supabase_enabled():
        return False
    uid = sanitize_user_id(user_id) if user_id is not None else sanitize_user_id(st.session_state.get("auth_user_id", ""))
    token = st.session_state.get("auth_access_token")
    return bool(uid and uid != "guest" and token)

def load_remote_bundle(force=False):
    if not use_remote_user_store():
        return None
    uid = sanitize_user_id(st.session_state.get("auth_user_id", ""))
    token = st.session_state.get("auth_access_token")
    cache_key = f"remote_bundle:{uid}"
    cache = st.session_state.get("remote_bundle_cache", {})
    if not force and cache_key in cache:
        return _normalize_remote_bundle(cache[cache_key])
    bundle = supabase_fetch_user_bundle(uid, token)
    if bundle is None:
        return None
    if bundle == _default_remote_bundle():
        supabase_upsert_user_bundle(uid, token, bundle)
    cache[cache_key] = bundle
    st.session_state.remote_bundle_cache = cache
    return _normalize_remote_bundle(bundle)

def save_remote_bundle(bundle):
    if not use_remote_user_store():
        return False
    uid = sanitize_user_id(st.session_state.get("auth_user_id", ""))
    token = st.session_state.get("auth_access_token")
    norm = _normalize_remote_bundle(bundle)
    ok = supabase_upsert_user_bundle(uid, token, norm)
    if ok:
        cache = st.session_state.get("remote_bundle_cache", {})
        cache[f"remote_bundle:{uid}"] = norm
        st.session_state.remote_bundle_cache = cache
    return ok

def notify_remote_store_failure(message):
    try:
        st.session_state.last_action_notice = message
    except Exception:
        pass

PROMPT_VERSION = "v1"
GRADER_VERSION = "v1"
LLM_TEMPERATURE = 0.0
def _get_llm_seed():
    try:
        return int(os.getenv("GEN_SEED", "123"))
    except Exception:
        return None
LLM_SEED = _get_llm_seed()
def get_query_param(name, default=None):
    try:
        params = st.query_params
        if name in params:
            val = params[name]
            if isinstance(val, list):
                return val[0] if val else default
            return val
        return default
    except Exception:
        try:
            params = st.experimental_get_query_params()
            return params.get(name, [default])[0]
        except Exception:
            return default

def resolve_theme_mode_from_query(theme_param, default="Light"):
    value = str(theme_param or "").strip().lower()
    if value == "dark":
        return "Dark"
    if value == "light":
        return "Light"
    return default

def resolve_mobile_flag_from_query(mobile_param):
    value = str(mobile_param or "").strip().lower()
    return value in {"1", "true", "yes", "y", "mobile"}

safe_param = get_query_param("safe", None)
ping_param = get_query_param("ping", "0")
theme_param = get_query_param("theme", None)
mobile_param = get_query_param("mobile", "0")
resolved_theme_mode = resolve_theme_mode_from_query(theme_param, default="Light")
MOBILE_CLIENT = resolve_mobile_flag_from_query(mobile_param)

DEBUG_MODE = str(ping_param) == "1"
if DEBUG_MODE:
    st.write("âœ… DEBUG: app.py loaded")
    st.write(f"Streamlit version: {st.__version__}")
    st.write(f"safe_param={safe_param}")
    st.stop()

LOCK_SAFE = str(safe_param) == "1"
LOCK_THEME = str(safe_param) == "0"

if "theme_enabled" not in st.session_state:
    st.session_state.theme_enabled = True if safe_param is None else LOCK_THEME
if "auth_user_id" not in st.session_state:
    st.session_state.auth_user_id = ""
if "auth_access_token" not in st.session_state:
    st.session_state.auth_access_token = ""
if "auth_email" not in st.session_state:
    st.session_state.auth_email = ""

# Session State ì´ˆê¸°í™”
if "current_question_idx" not in st.session_state:
    st.session_state.current_question_idx = 0
if "exam_questions" not in st.session_state:
    st.session_state.exam_questions = []
if "user_answers" not in st.session_state:
    st.session_state.user_answers = {}
if "exam_started" not in st.session_state:
    st.session_state.exam_started = False
if "exam_finished" not in st.session_state:
    st.session_state.exam_finished = False
if "exam_mode" not in st.session_state:
    st.session_state.exam_mode = "ì‹œí—˜ëª¨ë“œ"
if "exam_type" not in st.session_state:
    st.session_state.exam_type = "ê°ê´€ì‹"
if "auto_next" not in st.session_state:
    st.session_state.auto_next = False
if "auto_advance_guard" not in st.session_state:
    st.session_state.auto_advance_guard = None
if "revealed_answers" not in st.session_state:
    st.session_state.revealed_answers = set()
if "explanation_default" not in st.session_state:
    st.session_state.explanation_default = False
if "exam_stats_applied" not in st.session_state:
    st.session_state.exam_stats_applied = False
if "graded_questions" not in st.session_state:
    st.session_state.graded_questions = set()
# (trend_days retained for future use)
if "trend_days" not in st.session_state:
    st.session_state.trend_days = 14
if "wrong_priority" not in st.session_state:
    st.session_state.wrong_priority = "ì˜¤ë‹µ íšŸìˆ˜"
if "current_exam_meta" not in st.session_state:
    st.session_state.current_exam_meta = {}
if "exam_history_saved" not in st.session_state:
    st.session_state.exam_history_saved = False
if "gemini_model_id" not in st.session_state:
    st.session_state.gemini_model_id = "gemini-2.5-flash"
if "ai_model" not in st.session_state:
    st.session_state.ai_model = "ğŸ”µ Google Gemini"
if "api_key" not in st.session_state:
    st.session_state.api_key = None
if "openai_api_key" not in st.session_state:
    st.session_state.openai_api_key = None
if "dual_exam_text" not in st.session_state:
    st.session_state.dual_exam_text = ""
if "dual_exam_images" not in st.session_state:
    st.session_state.dual_exam_images = []
if "dual_exam_page_text" not in st.session_state:
    st.session_state.dual_exam_page_text = []
if "dual_match_scores" not in st.session_state:
    st.session_state.dual_match_scores = {}
if "wrong_weight_recent" not in st.session_state:
    st.session_state.wrong_weight_recent = 0.7
if "wrong_weight_count" not in st.session_state:
    st.session_state.wrong_weight_count = 0.3
if "theme_mode" not in st.session_state:
    st.session_state.theme_mode = resolved_theme_mode
if "theme_bg" not in st.session_state:
    st.session_state.theme_bg = "Gradient"
if "last_action_notice" not in st.session_state:
    st.session_state.last_action_notice = ""
if "generation_failure" not in st.session_state:
    st.session_state.generation_failure = ""
if "generation_preview_items" not in st.session_state:
    st.session_state.generation_preview_items = []
if "generation_preview_mode" not in st.session_state:
    st.session_state.generation_preview_mode = "ğŸ“ ê°ê´€ì‹ ë¬¸ì œ (Case Study)"
if "generation_preview_subject" not in st.session_state:
    st.session_state.generation_preview_subject = "General"
if "generation_preview_unit" not in st.session_state:
    st.session_state.generation_preview_unit = "ë¯¸ë¶„ë¥˜"
if "generation_prewarm_cache" not in st.session_state:
    st.session_state["generation_prewarm_cache"] = {}
if "generation_prewarm_errors" not in st.session_state:
    st.session_state["generation_prewarm_errors"] = {}
if "generation_async_job" not in st.session_state:
    st.session_state["generation_async_job"] = None
if "export_docx_bytes" not in st.session_state:
    st.session_state.export_docx_bytes = b""
if "exam_mode_entry_anchor" not in st.session_state:
    st.session_state.exam_mode_entry_anchor = ""
if "heatmap_bins" not in st.session_state:
    st.session_state.heatmap_bins = [0, 1, 3, 6, 10]
if "heatmap_colors" not in st.session_state:
    st.session_state.heatmap_colors = ["#ffffff", "#d7f3f0", "#b2e9e3", "#7fd6cc", "#4fc1b6", "#1f8e86"]
if "profile_name" not in st.session_state:
    st.session_state.profile_name = "default"
if "select_placeholder_exam" not in st.session_state:
    st.session_state.select_placeholder_exam = "ì„ íƒí•˜ì„¸ìš”"
if "select_placeholder_study" not in st.session_state:
    st.session_state.select_placeholder_study = "ì„ íƒí•˜ì„¸ìš”"
if "past_exam_text" not in st.session_state:
    st.session_state.past_exam_text = ""
if "past_exam_items" not in st.session_state:
    st.session_state.past_exam_items = []
if "past_exam_file" not in st.session_state:
    st.session_state.past_exam_file = ""
if "past_exam_images" not in st.session_state:
    st.session_state.past_exam_images = []
if "image_display_width" not in st.session_state:
    st.session_state.image_display_width = 520
if "past_exam_anchors" not in st.session_state:
    st.session_state.past_exam_anchors = {}
if "user_data_cache" not in st.session_state:
    st.session_state["user_data_cache"] = {}
if "home_visual_loaded" not in st.session_state:
    st.session_state.home_visual_loaded = False

def reset_runtime_state_for_auth_change():
    volatile_keys = [
        "exam_questions",
        "user_answers",
        "revealed_answers",
        "graded_questions",
        "current_exam_meta",
        "exam_started",
        "exam_finished",
        "exam_history_saved",
        "generation_preview_items",
        "generation_failure",
        "generation_prewarm_cache",
        "generation_prewarm_errors",
        "generation_async_job",
        "last_action_notice",
        "past_exam_items",
        "past_exam_images",
        "past_exam_text",
        "fsrs_settings_initialized",
        "remote_bundle_cache",
        "user_data_cache",
    ]
    for key in volatile_keys:
        if key in st.session_state:
            del st.session_state[key]

def _user_data_cache_key(kind, user_id=None):
    if user_id is not None:
        uid = sanitize_user_id(user_id)
        scope = "local"
    elif use_remote_user_store():
        uid = sanitize_user_id(st.session_state.get("auth_user_id", ""))
        scope = "remote"
    else:
        uid = get_current_user_id()
        scope = "local"
    return f"{kind}:{scope}:{uid}"

def _get_user_data_cache(kind, user_id=None):
    cache = st.session_state.get("user_data_cache", {})
    return cache.get(_user_data_cache_key(kind, user_id=user_id))

def _set_user_data_cache(kind, value, user_id=None):
    cache = st.session_state.get("user_data_cache", {})
    cache[_user_data_cache_key(kind, user_id=user_id)] = value
    st.session_state["user_data_cache"] = cache
    return value

def _get_or_load_user_data(kind, loader, user_id=None, force=False):
    if not force:
        cached = _get_user_data_cache(kind, user_id=user_id)
        if cached is not None:
            return cached
    data = loader()
    return _set_user_data_cache(kind, data, user_id=user_id)

def build_upload_signature(file_name, file_bytes):
    data = file_bytes if isinstance(file_bytes, (bytes, bytearray)) else b""
    ext = Path(file_name or "").suffix.lower()
    digest = hashlib.sha256(data).hexdigest()[:16]
    return f"{ext}:{len(data)}:{digest}"

def make_uploaded_file_from_bytes(file_name, file_bytes):
    proxy = io.BytesIO(file_bytes if isinstance(file_bytes, (bytes, bytearray)) else b"")
    proxy.name = file_name or "uploaded.bin"
    return proxy

def _prewarm_cache_key(kind, signature):
    return f"{kind}:{signature}"

def get_generation_prewarm_text(kind, signature):
    key = _prewarm_cache_key(kind, signature)
    return st.session_state.get("generation_prewarm_cache", {}).get(key)

def set_generation_prewarm_text(kind, signature, text):
    key = _prewarm_cache_key(kind, signature)
    cache = st.session_state.get("generation_prewarm_cache", {})
    cache[key] = text
    st.session_state["generation_prewarm_cache"] = cache
    errors = st.session_state.get("generation_prewarm_errors", {})
    if key in errors:
        del errors[key]
    st.session_state["generation_prewarm_errors"] = errors
    return text

def get_generation_prewarm_error(kind, signature):
    key = _prewarm_cache_key(kind, signature)
    return st.session_state.get("generation_prewarm_errors", {}).get(key)

def set_generation_prewarm_error(kind, signature, error_text):
    key = _prewarm_cache_key(kind, signature)
    errors = st.session_state.get("generation_prewarm_errors", {})
    errors[key] = error_text
    st.session_state["generation_prewarm_errors"] = errors

def clear_generation_prewarm_error(kind, signature):
    key = _prewarm_cache_key(kind, signature)
    errors = st.session_state.get("generation_prewarm_errors", {})
    if key in errors:
        del errors[key]
    st.session_state["generation_prewarm_errors"] = errors

@st.cache_resource(show_spinner=False)
def get_generation_executor():
    return concurrent.futures.ThreadPoolExecutor(max_workers=2)

def get_generation_runtime_context():
    return {
        "gemini_model_id": get_gemini_model_id(),
        "audit_user_id": get_current_user_id(),
    }

def start_generation_async_job(
    raw_text,
    mode,
    ai_model,
    num_items,
    chunk_size,
    overlap,
    api_key,
    openai_api_key,
    style_text,
    subject,
    unit,
    resolved_flavor=None,
    mix_basic_ratio=70,
    runtime_context=None,
):
    context = runtime_context if isinstance(runtime_context, dict) else {}
    executor = get_generation_executor()
    future = executor.submit(
        generate_content_in_chunks,
        raw_text,
        mode,
        ai_model,
        num_items,
        chunk_size,
        overlap,
        api_key,
        openai_api_key,
        style_text,
        False,
        context.get("gemini_model_id"),
        context.get("audit_user_id"),
        resolved_flavor,
        mix_basic_ratio,
    )
    return {
        "id": str(uuid.uuid4()),
        "status": "running",
        "created_at": datetime.now(timezone.utc).isoformat(),
        "future": future,
        "mode": mode,
        "subject": subject,
        "unit": unit,
        "num_items": int(num_items),
        "resolved_flavor": resolved_flavor or "",
        "mix_basic_ratio": int(mix_basic_ratio or 70),
    }

def update_generation_async_job_state(job):
    if not isinstance(job, dict):
        return None
    status = job.get("status")
    if status in ("done", "error", "cancelled"):
        return job
    future = job.get("future")
    if future is None:
        job["status"] = "error"
        job["error"] = "ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        job["completed_at"] = datetime.now(timezone.utc).isoformat()
        return job
    if not future.done():
        job["status"] = "running"
        return job
    try:
        result = future.result()
        job["result"] = result if isinstance(result, list) else []
        job["status"] = "done"
    except Exception as e:
        job["status"] = "error"
        job["error"] = str(e)
    job["completed_at"] = datetime.now(timezone.utc).isoformat()
    return job

def load_generation_queue_items():
    settings = load_user_settings()
    items = settings.get("generation_queue_v1")
    if not isinstance(items, list):
        return []
    out = []
    for item in items:
        if isinstance(item, dict) and item.get("id"):
            out.append(item)
    return out

def save_generation_queue_items(items):
    settings = load_user_settings()
    settings["generation_queue_v1"] = items if isinstance(items, list) else []
    return save_user_settings(settings)

def build_generation_queue_item(
    source_name,
    source_signature,
    raw_text,
    style_text,
    flavor_choice,
    resolved_flavor,
    mix_basic_ratio,
    mode,
    num_items,
    subject,
    unit,
    ai_model,
    chunk_size,
    overlap,
    quality_filter,
    min_length,
):
    return {
        "id": str(uuid.uuid4()),
        "source_name": source_name,
        "source_signature": source_signature or "",
        "status": "queued",
        "created_at": datetime.now(timezone.utc).isoformat(),
        "raw_text": raw_text,
        "style_text": style_text or "",
        "flavor_choice": str(flavor_choice or ""),
        "resolved_flavor": str(resolved_flavor or ""),
        "mix_basic_ratio": int(mix_basic_ratio or 70),
        "mode": mode,
        "num_items": int(num_items),
        "subject": subject,
        "unit": unit,
        "ai_model": ai_model,
        "chunk_size": int(chunk_size),
        "overlap": int(overlap),
        "quality_filter": bool(quality_filter),
        "min_length": int(min_length),
    }

def is_duplicate_generation_queue_item(
    queue_items,
    source_signature,
    flavor_choice,
    mode,
    num_items,
    subject,
    unit,
):
    items = queue_items if isinstance(queue_items, list) else []
    sig = str(source_signature or "")
    for item in items:
        if item.get("status") not in {"queued", "running"}:
            continue
        if str(item.get("source_signature") or "") != sig:
            continue
        if str(item.get("mode") or "") != str(mode or ""):
            continue
        if str(item.get("flavor_choice") or "") != str(flavor_choice or ""):
            continue
        if int(item.get("num_items", 0)) != int(num_items or 0):
            continue
        if str(item.get("subject") or "") != str(subject or ""):
            continue
        if str(item.get("unit") or "") != str(unit or ""):
            continue
        return True
    return False

def remove_generation_queue_job(queue_items, job_id):
    items = queue_items if isinstance(queue_items, list) else []
    out = [x for x in items if str(x.get("id")) != str(job_id)]
    return (len(out) < len(items)), out

def _drop_generation_job_payload(item):
    if not isinstance(item, dict):
        return item
    slim = dict(item)
    slim.pop("raw_text", None)
    slim.pop("style_text", None)
    slim.pop("result", None)
    return slim

def start_next_generation_queue_job_if_idle(queue_items, api_key=None, openai_api_key=None, runtime_context=None):
    items = queue_items if isinstance(queue_items, list) else []
    active = st.session_state.get("generation_async_job")
    if isinstance(active, dict) and active.get("status") == "running":
        return items, False
    for idx, item in enumerate(items):
        if item.get("status") != "queued":
            continue
        job = start_generation_async_job(
            raw_text=item.get("raw_text", ""),
            mode=item.get("mode", MODE_MCQ),
            ai_model=item.get("ai_model", st.session_state.get("ai_model", "ğŸ”µ Google Gemini")),
            num_items=int(item.get("num_items", 10)),
            chunk_size=int(item.get("chunk_size", 8000)),
            overlap=int(item.get("overlap", 500)),
            api_key=api_key,
            openai_api_key=openai_api_key,
            style_text=item.get("style_text", ""),
            subject=item.get("subject", "General"),
            unit=item.get("unit", "ë¯¸ë¶„ë¥˜"),
            resolved_flavor=item.get("resolved_flavor", ""),
            mix_basic_ratio=int(item.get("mix_basic_ratio", 70)),
            runtime_context=runtime_context,
        )
        job["queue_id"] = item.get("id")
        st.session_state["generation_async_job"] = job
        item["status"] = "running"
        item["started_at"] = datetime.now(timezone.utc).isoformat()
        items[idx] = item
        return items, True
    return items, False

def reconcile_generation_queue_with_async(queue_items, default_quality_filter=True, default_min_length=30):
    items = queue_items if isinstance(queue_items, list) else []
    notices = []
    async_job = st.session_state.get("generation_async_job")
    if not isinstance(async_job, dict):
        return items, notices
    async_job = update_generation_async_job_state(async_job)
    st.session_state["generation_async_job"] = async_job
    status = async_job.get("status")
    if status == "running":
        return items, notices

    queue_id = str(async_job.get("queue_id") or "")
    target_idx = -1
    for idx, item in enumerate(items):
        if str(item.get("id")) == queue_id:
            target_idx = idx
            break
    if target_idx < 0:
        st.session_state["generation_async_job"] = None
        return items, notices

    target = dict(items[target_idx])
    target["completed_at"] = datetime.now(timezone.utc).isoformat()

    if status == "done":
        result = async_job.get("result") or []
        if result and isinstance(result, list):
            saved_count = add_questions_to_bank(
                result,
                target.get("mode", MODE_MCQ),
                target.get("subject", "General"),
                target.get("unit", "ë¯¸ë¶„ë¥˜"),
                quality_filter=bool(target.get("quality_filter", default_quality_filter)),
                min_length=int(target.get("min_length", default_min_length)),
            )
            target["status"] = "done"
            target["result_count"] = len(result)
            target["saved_count"] = int(saved_count)
            notices.append(f"ìƒì„± ì™„ë£Œ: {target.get('source_name', '')} ({saved_count}ê°œ ì €ì¥)")
        else:
            target["status"] = "failed"
            target["error"] = "ìƒì„± ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
            notices.append(f"ìƒì„± ì‹¤íŒ¨: {target.get('source_name', '')} (ê²°ê³¼ ì—†ìŒ)")
    elif status == "cancelled":
        target["status"] = "cancelled"
        target["error"] = async_job.get("error", "ì‚¬ìš©ì ì·¨ì†Œ")
        notices.append(f"ì‘ì—… ì·¨ì†Œ: {target.get('source_name', '')}")
    else:
        target["status"] = "failed"
        target["error"] = async_job.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
        notices.append(f"ìƒì„± ì‹¤íŒ¨: {target.get('source_name', '')}")

    items[target_idx] = _drop_generation_job_payload(target)
    st.session_state["generation_async_job"] = None
    return items, notices

def revive_stale_running_queue_items(queue_items):
    items = queue_items if isinstance(queue_items, list) else []
    async_job = st.session_state.get("generation_async_job")
    if isinstance(async_job, dict) and async_job.get("status") == "running":
        return items, False
    changed = False
    for idx, item in enumerate(items):
        if item.get("status") == "running":
            restored = dict(item)
            restored["status"] = "queued"
            restored.pop("started_at", None)
            items[idx] = restored
            changed = True
    return items, changed

# ============================================================================
# JSON ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜
# ============================================================================
def load_auth_users():
    if os.path.exists(AUTH_USERS_FILE):
        try:
            with open(AUTH_USERS_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data if isinstance(data, dict) else {}
        except Exception:
            return {}
    return {}

def save_auth_users(data):
    with open(AUTH_USERS_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def _hash_password(password, salt_hex):
    raw = hashlib.pbkdf2_hmac("sha256", password.encode("utf-8"), bytes.fromhex(salt_hex), 120000)
    return raw.hex()

def register_user_account(user_id, password):
    if is_supabase_required() and not is_supabase_enabled():
        return False, "Supabase ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ìš´ì˜ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
    if is_supabase_enabled():
        return supabase_sign_up(user_id, password)
    uid = sanitize_user_id(user_id)
    if uid == "guest":
        return False, "ì•„ì´ë””ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    if len(password or "") < 6:
        return False, "ë¹„ë°€ë²ˆí˜¸ëŠ” 6ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤."
    users = load_auth_users()
    if uid in users:
        return False, "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì•„ì´ë””ì…ë‹ˆë‹¤."
    salt_hex = os.urandom(16).hex()
    users[uid] = {
        "salt": salt_hex,
        "password_hash": _hash_password(password, salt_hex),
        "created_at": datetime.now(timezone.utc).isoformat(),
    }
    save_auth_users(users)
    get_user_data_dir(uid)
    return True, "íšŒì›ê°€ì…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."

def authenticate_user_account(user_id, password):
    if is_supabase_required() and not is_supabase_enabled():
        return False, "Supabase ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ìš´ì˜ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
    if is_supabase_enabled():
        ok, payload = supabase_sign_in(user_id, password)
        if not ok:
            return False, payload
        st.session_state.auth_access_token = payload["access_token"]
        st.session_state.auth_email = payload["email"]
        return True, payload["user_id"]
    uid = sanitize_user_id(user_id)
    users = load_auth_users()
    row = users.get(uid)
    if not isinstance(row, dict):
        return False, "ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
    salt_hex = row.get("salt", "")
    expected = row.get("password_hash", "")
    if not salt_hex or not expected:
        return False, "ê³„ì • ì •ë³´ê°€ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤."
    current = _hash_password(password or "", salt_hex)
    if current != expected:
        return False, "ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
    return True, uid

def load_questions(user_id=None) -> dict:
    """questions.json íŒŒì¼ ë¡œë“œ"""
    cached = _get_user_data_cache("questions", user_id=user_id)
    if cached is not None:
        return ensure_question_ids(cached)
    if user_id is None and is_supabase_required():
        if use_remote_user_store():
            bundle = load_remote_bundle()
            if bundle is not None:
                data = ensure_question_ids(bundle.get("questions", {"text": [], "cloze": []}))
                return _set_user_data_cache("questions", data, user_id=user_id)
            notify_remote_store_failure("âš ï¸ Supabaseì—ì„œ ë¬¸í•­ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return _set_user_data_cache("questions", {"text": [], "cloze": []}, user_id=user_id)
    if user_id is None and use_remote_user_store():
        bundle = load_remote_bundle()
        if bundle is not None:
            data = ensure_question_ids(bundle.get("questions", {"text": [], "cloze": []}))
            return _set_user_data_cache("questions", data, user_id=user_id)
    question_bank_file = get_question_bank_file(user_id)
    if os.path.exists(question_bank_file):
        try:
            with open(question_bank_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # ë§ˆì´ê·¸ë ˆì´ì…˜: ê¸°ì¡´ í˜•ì‹ í™•ì¸ ë° í•„ìš”ì‹œ ë³€í™˜
                if data and isinstance(data.get("text"), list) and len(data.get("text", [])) > 0:
                    first = data["text"][0]
                    if isinstance(first, dict) and "content" in first and "type" not in first:
                        # ê¸°ì¡´ í˜•ì‹ (content í•„ë“œ) -> ìƒˆ í˜•ì‹ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
                        migrate_old_format(data, user_id=user_id)
                        return load_questions(user_id=user_id)  # ë‹¤ì‹œ ë¡œë“œ
                data = ensure_question_ids(data)
                return _set_user_data_cache("questions", data, user_id=user_id)
        except:
            return _set_user_data_cache("questions", {"text": [], "cloze": []}, user_id=user_id)
    return _set_user_data_cache("questions", {"text": [], "cloze": []}, user_id=user_id)

def migrate_old_format(data: dict, user_id=None):
    """ê¸°ì¡´ í˜•ì‹ì˜ questions.jsonì„ ìƒˆ í˜•ì‹ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    try:
        migrated_text = []
        migrated_cloze = []
        
        for item in data.get("text", []):
            if isinstance(item, dict) and "content" in item:
                # ê¸°ì¡´ í˜•ì‹ì—ì„œ íŒŒì‹±
                parsed = extract_mcq_components(item["content"])
                if parsed:
                    parsed["subject"] = item.get("subject", "General")
                    parsed["date_added"] = item.get("date_added", datetime.now().isoformat())
                    migrated_text.append(parsed)
        
        for item in data.get("cloze", []):
            if isinstance(item, dict) and "content" in item:
                # Cloze ê¸°ì¡´ í˜•ì‹ íŒŒì‹±
                content = item["content"]
                if '{{c1::' in content:
                    m = re.search(r'\{\{c1::(.+?)\}\}', content)
                    if m:
                        answer = m.group(1).strip()
                        front = re.sub(r'\{\{c1::.+?\}\}', '____', content)
                        migrated_cloze.append({
                            "type": "cloze",
                            "front": front,
                            "answer": answer,
                            "explanation": "",
                            "subject": item.get("subject", "General"),
                            "date_added": item.get("date_added", datetime.now().isoformat())
                        })
        
        # ìƒˆ í˜•ì‹ìœ¼ë¡œ ì €ì¥
        data["text"] = migrated_text
        data["cloze"] = migrated_cloze
        save_questions(data, user_id=user_id)
        
        import sys
        print(f"[MIGRATION] {len(migrated_text)}ê°œ MCQ, {len(migrated_cloze)}ê°œ Cloze ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ", file=sys.stderr)
    except Exception as e:
        import sys
        print(f"[MIGRATION ERROR] {str(e)}", file=sys.stderr)

def save_questions(data: dict, user_id=None):
    """questions.json íŒŒì¼ ì €ì¥"""
    if user_id is None and is_supabase_required():
        if not use_remote_user_store():
            notify_remote_store_failure("âš ï¸ Supabase ë¡œê·¸ì¸ ìƒíƒœê°€ ì•„ë‹ˆì–´ì„œ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        bundle = load_remote_bundle() or _default_remote_bundle()
        bundle["questions"] = data
        if save_remote_bundle(bundle):
            _set_user_data_cache("questions", data, user_id=user_id)
            return True
        notify_remote_store_failure("âš ï¸ Supabase ì €ì¥ ì‹¤íŒ¨ë¡œ ë¬¸í•­ ì €ì¥ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False
    if user_id is None and use_remote_user_store():
        bundle = load_remote_bundle() or _default_remote_bundle()
        bundle["questions"] = data
        if save_remote_bundle(bundle):
            _set_user_data_cache("questions", data, user_id=user_id)
            return True
    question_bank_file = get_question_bank_file(user_id)
    with open(question_bank_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    _set_user_data_cache("questions", data, user_id=user_id)
    return True

def load_exam_history(user_id=None):
    cached = _get_user_data_cache("exam_history", user_id=user_id)
    if cached is not None:
        return cached
    if user_id is None and is_supabase_required():
        if use_remote_user_store():
            bundle = load_remote_bundle()
            if bundle is not None:
                data = bundle.get("exam_history", [])
                if not isinstance(data, list):
                    data = []
                return _set_user_data_cache("exam_history", data, user_id=user_id)
            notify_remote_store_failure("âš ï¸ Supabaseì—ì„œ ì‹œí—˜ ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return _set_user_data_cache("exam_history", [], user_id=user_id)
    if user_id is None and use_remote_user_store():
        bundle = load_remote_bundle()
        if bundle is not None:
            data = bundle.get("exam_history", [])
            if not isinstance(data, list):
                data = []
            return _set_user_data_cache("exam_history", data, user_id=user_id)
    exam_history_file = get_exam_history_file(user_id)
    if os.path.exists(exam_history_file):
        try:
            with open(exam_history_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                if not isinstance(data, list):
                    data = []
                return _set_user_data_cache("exam_history", data, user_id=user_id)
        except Exception:
            return _set_user_data_cache("exam_history", [], user_id=user_id)
    return _set_user_data_cache("exam_history", [], user_id=user_id)

def save_exam_history(items, user_id=None):
    if user_id is None and is_supabase_required():
        if not use_remote_user_store():
            notify_remote_store_failure("âš ï¸ Supabase ë¡œê·¸ì¸ ìƒíƒœê°€ ì•„ë‹ˆì–´ì„œ ì‹œí—˜ ê¸°ë¡ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        bundle = load_remote_bundle() or _default_remote_bundle()
        bundle["exam_history"] = items if isinstance(items, list) else []
        if save_remote_bundle(bundle):
            _set_user_data_cache("exam_history", bundle["exam_history"], user_id=user_id)
            return True
        notify_remote_store_failure("âš ï¸ Supabase ì €ì¥ ì‹¤íŒ¨ë¡œ ì‹œí—˜ ê¸°ë¡ ì €ì¥ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False
    if user_id is None and use_remote_user_store():
        bundle = load_remote_bundle() or _default_remote_bundle()
        bundle["exam_history"] = items if isinstance(items, list) else []
        if save_remote_bundle(bundle):
            _set_user_data_cache("exam_history", bundle["exam_history"], user_id=user_id)
            return True
    exam_history_file = get_exam_history_file(user_id)
    with open(exam_history_file, "w", encoding="utf-8") as f:
        json.dump(items, f, ensure_ascii=False, indent=2)
    _set_user_data_cache("exam_history", items if isinstance(items, list) else [], user_id=user_id)
    return True

def add_exam_history(session, user_id=None):
    history = load_exam_history(user_id=user_id)
    history.insert(0, session)
    save_exam_history(history[:200], user_id=user_id)
    return history

def clear_question_bank(mode="all", user_id=None):
    data = load_questions(user_id=user_id)
    if mode == "mcq":
        data["text"] = []
    elif mode == "cloze":
        data["cloze"] = []
    else:
        data = {"text": [], "cloze": []}
    save_questions(data, user_id=user_id)
    return data

def clear_exam_history(user_id=None):
    save_exam_history([], user_id=user_id)

def load_user_settings(user_id=None):
    cached = _get_user_data_cache("user_settings", user_id=user_id)
    if cached is not None:
        return cached
    if user_id is None and is_supabase_required():
        if use_remote_user_store():
            bundle = load_remote_bundle()
            if bundle is not None:
                data = bundle.get("user_settings", {})
                if not isinstance(data, dict):
                    data = {}
                return _set_user_data_cache("user_settings", data, user_id=user_id)
            notify_remote_store_failure("âš ï¸ Supabaseì—ì„œ ì‚¬ìš©ì ì„¤ì •ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return _set_user_data_cache("user_settings", {}, user_id=user_id)
    if user_id is None and use_remote_user_store():
        bundle = load_remote_bundle()
        if bundle is not None:
            data = bundle.get("user_settings", {})
            if not isinstance(data, dict):
                data = {}
            return _set_user_data_cache("user_settings", data, user_id=user_id)
    user_settings_file = get_user_settings_file(user_id)
    if os.path.exists(user_settings_file):
        try:
            with open(user_settings_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                if not isinstance(data, dict):
                    data = {}
                return _set_user_data_cache("user_settings", data, user_id=user_id)
        except Exception:
            return _set_user_data_cache("user_settings", {}, user_id=user_id)
    return _set_user_data_cache("user_settings", {}, user_id=user_id)

def save_user_settings(data, user_id=None):
    if user_id is None and is_supabase_required():
        if not use_remote_user_store():
            notify_remote_store_failure("âš ï¸ Supabase ë¡œê·¸ì¸ ìƒíƒœê°€ ì•„ë‹ˆì–´ì„œ ì„¤ì •ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        bundle = load_remote_bundle() or _default_remote_bundle()
        bundle["user_settings"] = data if isinstance(data, dict) else {}
        if save_remote_bundle(bundle):
            _set_user_data_cache("user_settings", bundle["user_settings"], user_id=user_id)
            return True
        notify_remote_store_failure("âš ï¸ Supabase ì €ì¥ ì‹¤íŒ¨ë¡œ ì„¤ì • ì €ì¥ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False
    if user_id is None and use_remote_user_store():
        bundle = load_remote_bundle() or _default_remote_bundle()
        bundle["user_settings"] = data if isinstance(data, dict) else {}
        if save_remote_bundle(bundle):
            _set_user_data_cache("user_settings", bundle["user_settings"], user_id=user_id)
            return True
    user_settings_file = get_user_settings_file(user_id)
    with open(user_settings_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    _set_user_data_cache("user_settings", data if isinstance(data, dict) else {}, user_id=user_id)
    return True

def load_fsrs_settings():
    data = load_user_settings()
    default = {
        "desired_retention": 0.9,
        "learning_steps": [1, 10],
        "relearning_steps": [10],
        "maximum_interval": 36500,
        "enable_fuzzing": True,
        "parameters": list(FSRS_DEFAULT_PARAMETERS),
    }
    fsrs = data.get("fsrs_settings")
    if not isinstance(fsrs, dict):
        return default
    merged = {**default, **fsrs}
    return merged

def save_fsrs_settings(settings):
    data = load_user_settings()
    data["fsrs_settings"] = settings
    save_user_settings(data)

def get_gemini_model_id():
    return st.session_state.get("gemini_model_id") or "gemini-2.5-flash"

def _steps_to_timedelta(steps):
    out = []
    for s in steps:
        try:
            val = int(s)
            if val > 0:
                out.append(timedelta(minutes=val))
        except Exception:
            continue
    return tuple(out)

def get_fsrs_scheduler():
    if not FSRS_AVAILABLE:
        return None
    settings = load_fsrs_settings()
    params = settings.get("parameters") or list(FSRS_DEFAULT_PARAMETERS)
    try:
        return Scheduler(
            parameters=params,
            desired_retention=float(settings.get("desired_retention", 0.9)),
            learning_steps=_steps_to_timedelta(settings.get("learning_steps", [1, 10])),
            relearning_steps=_steps_to_timedelta(settings.get("relearning_steps", [10])),
            maximum_interval=int(settings.get("maximum_interval", 36500)),
            enable_fuzzing=bool(settings.get("enable_fuzzing", True)),
        )
    except Exception:
        return Scheduler()

# FSRS settings -> session state (initialize once)
if "fsrs_settings_initialized" not in st.session_state:
    _fsrs_settings = load_fsrs_settings()
    st.session_state.fsrs_settings_initialized = True
    st.session_state.fsrs_desired_retention = _fsrs_settings.get("desired_retention", 0.9)
    st.session_state.fsrs_learning_steps_text = ",".join(map(str, _fsrs_settings.get("learning_steps", [1, 10])))
    st.session_state.fsrs_relearning_steps_text = ",".join(map(str, _fsrs_settings.get("relearning_steps", [10])))
    st.session_state.fsrs_max_interval = _fsrs_settings.get("maximum_interval", 36500)
    st.session_state.fsrs_enable_fuzzing = _fsrs_settings.get("enable_fuzzing", True)
    st.session_state.fsrs_params_text = json.dumps(_fsrs_settings.get("parameters", list(FSRS_DEFAULT_PARAMETERS)))

def apply_profile_settings(profile_name):
    data = load_user_settings()
    prof = data.get(profile_name)
    if not isinstance(prof, dict):
        return False

    default_bins = [0, 1, 3, 6, 10]
    default_colors = ["#ffffff", "#d7f3f0", "#b2e9e3", "#7fd6cc", "#4fc1b6", "#1f8e86"]

    bins = prof.get("heatmap_bins")
    if isinstance(bins, list) and len(bins) >= 5:
        try:
            parsed_bins = [int(bins[i]) for i in range(5)]
            if parsed_bins[0] != 0:
                parsed_bins[0] = 0
            valid = all(parsed_bins[i] < parsed_bins[i + 1] for i in range(4))
            st.session_state.heatmap_bins = parsed_bins if valid else default_bins
        except Exception:
            st.session_state.heatmap_bins = default_bins
    else:
        st.session_state.heatmap_bins = default_bins

    colors = prof.get("heatmap_colors")
    if isinstance(colors, list) and len(colors) >= 6:
        normalized_colors = []
        for i in range(6):
            color = colors[i]
            if isinstance(color, str) and re.match(r"^#[0-9a-fA-F]{6}$", color):
                normalized_colors.append(color)
            else:
                normalized_colors.append(default_colors[i])
        st.session_state.heatmap_colors = normalized_colors
    else:
        st.session_state.heatmap_colors = default_colors

    st.session_state.select_placeholder_exam = str(
        prof.get("select_placeholder_exam", st.session_state.select_placeholder_exam)
    )
    st.session_state.select_placeholder_study = str(
        prof.get("select_placeholder_study", st.session_state.select_placeholder_study)
    )
    return True

def persist_profile_settings(profile_name):
    data = load_user_settings()
    safe_bins = st.session_state.heatmap_bins
    safe_colors = st.session_state.heatmap_colors
    if not (isinstance(safe_bins, list) and len(safe_bins) >= 5):
        safe_bins = [0, 1, 3, 6, 10]
    if not (isinstance(safe_colors, list) and len(safe_colors) >= 6):
        safe_colors = ["#ffffff", "#d7f3f0", "#b2e9e3", "#7fd6cc", "#4fc1b6", "#1f8e86"]
    data[profile_name] = {
        "heatmap_bins": safe_bins[:5],
        "heatmap_colors": safe_colors[:6],
        "select_placeholder_exam": st.session_state.select_placeholder_exam,
        "select_placeholder_study": st.session_state.select_placeholder_study,
    }
    save_user_settings(data)

def ensure_question_ids(data: dict) -> dict:
    """ëª¨ë“  ë¬¸í•­ì— ê³ ìœ  ID ë¶€ì—¬"""
    updated = False
    for item in data.get("text", []) + data.get("cloze", []):
        if isinstance(item, dict) and "id" not in item:
            item["id"] = str(uuid.uuid4())
            updated = True
    if updated:
        save_questions(data)
    return data

def add_questions_to_bank(questions_data, mode, subject="General", unit="ë¯¸ë¶„ë¥˜", quality_filter=True, min_length=20, batch_id=None):
    """ìƒì„±ëœ ë¬¸ì œë¥¼ question bankì— ì¶”ê°€ (êµ¬ì¡°í™”ëœ JSON í˜•ì‹)
    
    Args:
        questions_data: ë‹¤ìŒ ì¤‘ í•˜ë‚˜
            - êµ¬ì¡°í™”ëœ dictì˜ ë¦¬ìŠ¤íŠ¸: [{"problem": ..., "options": [...], "answer": 1, "explanation": ...}]
            - ë¬¸ìì—´: ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•¨
        mode: ëª¨ë“œ (ê°ê´€ì‹/ë¹ˆì¹¸/ë‹¨ë‹µí˜•/ì„œìˆ í˜•)
        subject: ê³¼ëª©ëª…
        quality_filter: í’ˆì§ˆ í•„í„°ë§ ì—¬ë¶€
        min_length: ìµœì†Œ ê¸¸ì´
    
    Returns:
        ì¶”ê°€ëœ ë¬¸ì œ ê°œìˆ˜
    """
    bank = load_questions()
    
    # ë¬¸ìì—´ì´ë©´ íŒŒì‹± (ê¸°ì¡´ í˜¸í™˜ì„±)
    if isinstance(questions_data, str):
        parsed_questions = parse_generated_text_to_structured(questions_data, mode)
    else:
        parsed_questions = questions_data if isinstance(questions_data, list) else [questions_data]
    
    added_count = 0
    if not batch_id:
        batch_id = datetime.now().strftime("%Y%m%d-%H%M%S") + "-" + uuid.uuid4().hex[:6]

    for q_data in parsed_questions:
        if not q_data:
            continue
        
        # í’ˆì§ˆ í•„í„°ë§
        if quality_filter:
            if mode == MODE_MCQ:
                problem_text = q_data.get("problem", "")
                if len(problem_text) < min_length:
                    continue
            else:
                front_text = q_data.get("front", "")
                if len(front_text) < min_length:
                    continue
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        q_data["subject"] = q_data.get("subject") or subject
        q_data["unit"] = q_data.get("unit") or unit
        q_data["date_added"] = datetime.now().isoformat()
        if "id" not in q_data:
            q_data["id"] = str(uuid.uuid4())
        q_data["batch_id"] = q_data.get("batch_id") or batch_id
        
        if mode == MODE_MCQ:
            bank["text"].append(q_data)
        else:
            bank["cloze"].append(q_data)
        
        added_count += 1
    
    save_questions(bank)
    return added_count

def add_questions_to_bank_auto(items, subject="General", unit="ë¯¸ë¶„ë¥˜", quality_filter=True, min_length=20, batch_id=None):
    """MCQ/Cloze í˜¼í•© ì…ë ¥ ìë™ ë¶„ë¥˜ í›„ ì €ì¥"""
    if not batch_id:
        batch_id = datetime.now().strftime("%Y%m%d-%H%M%S") + "-" + uuid.uuid4().hex[:6]
    mcq_items = []
    cloze_items = []
    for item in items:
        if not isinstance(item, dict):
            continue
        item["subject"] = item.get("subject") or subject
        item["unit"] = item.get("unit") or unit
        item["batch_id"] = item.get("batch_id") or batch_id
        if item.get("type") == "cloze":
            cloze_items.append(item)
        else:
            mcq_items.append(item)
    added = 0
    if mcq_items:
        added += add_questions_to_bank(mcq_items, MODE_MCQ, subject, unit, quality_filter, min_length, batch_id=batch_id)
    if cloze_items:
        added += add_questions_to_bank(cloze_items, MODE_CLOZE, subject, unit, quality_filter, min_length, batch_id=batch_id)
    return added


def parse_free_response_items(text, response_type="short"):
    items = []

    def append_item(obj):
        if not isinstance(obj, dict):
            return
        front = (obj.get("front") or obj.get("question") or obj.get("problem") or "").strip()
        answer = (obj.get("answer") or obj.get("reference_answer") or obj.get("model_answer") or "").strip()
        explanation = (obj.get("explanation") or obj.get("rationale") or "").strip()
        if front and answer:
            items.append({
                "type": "cloze",
                "response_type": response_type,
                "front": front,
                "answer": answer,
                "explanation": explanation,
            })

    parsed_json = _parse_json_from_text(text)
    if isinstance(parsed_json, dict):
        parsed_json = [parsed_json]
    if isinstance(parsed_json, list):
        for obj in parsed_json:
            append_item(obj)
        if items:
            return items

    blocks = re.split(r"\n-{3,}\n", text)
    for block in blocks:
        line = block.strip()
        if not line:
            continue
        if "\t" in line:
            cols = [c.strip() for c in line.split("\t")]
            if len(cols) >= 2 and cols[0] and cols[1]:
                items.append({
                    "type": "cloze",
                    "response_type": response_type,
                    "front": cols[0],
                    "answer": cols[1],
                    "explanation": cols[2] if len(cols) > 2 else "",
                })
            continue

        lines = [x.strip() for x in line.splitlines() if x.strip()]
        if len(lines) < 2:
            continue
        front = re.sub(r"^(ë¬¸í•­|ë¬¸ì œ|Q)\s*[:ï¼š]\s*", "", lines[0], flags=re.IGNORECASE).strip()
        answer = re.sub(r"^(ì •ë‹µ|ë‹µ|A)\s*[:ï¼š]\s*", "", lines[1], flags=re.IGNORECASE).strip()
        explanation = ""
        if len(lines) > 2:
            explanation = re.sub(r"^(í•´ì„¤|ì„¤ëª…)\s*[:ï¼š]\s*", "", "\n".join(lines[2:]), flags=re.IGNORECASE).strip()
        if front and answer:
            items.append({
                "type": "cloze",
                "response_type": response_type,
                "front": front,
                "answer": answer,
                "explanation": explanation,
            })
    return items


def parse_generated_text_to_structured(text, mode):
    """ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ íŒŒì‹±
    
    Returns:
        êµ¬ì¡°í™”ëœ dictì˜ ë¦¬ìŠ¤íŠ¸
    """
    results = []
    mode_mcq = globals().get("MODE_MCQ", "ğŸ“ ê°ê´€ì‹ ë¬¸ì œ (Case Study)")
    mode_cloze = globals().get("MODE_CLOZE", "ğŸ§© ë¹ˆì¹¸ ëš«ê¸° (Anki Cloze)")
    mode_short = globals().get("MODE_SHORT", "ğŸ§  ë‹¨ë‹µí˜• ë¬¸ì œ")
    mode_essay = globals().get("MODE_ESSAY", "ğŸ§¾ ì„œìˆ í˜• ë¬¸ì œ")
    
    if mode == mode_mcq:
        # 1) JSON í˜•ì‹ ìš°ì„  íŒŒì‹± (Gemini/OpenAI JSON ëŒ€ì‘)
        # ì „ì²´ í…ìŠ¤íŠ¸ê°€ JSON ë°°ì—´/ê°ì²´ì¸ ê²½ìš°
        try:
            stripped = text.strip()
            if stripped.startswith("{") or stripped.startswith("["):
                parsed = json.loads(stripped)
                if isinstance(parsed, dict):
                    parsed = [parsed]
                if isinstance(parsed, list):
                    for item in parsed:
                        norm = normalize_mcq_item(item)
                        if norm:
                            results.append(norm)
                    if results:
                        return results
        except Exception:
            pass

        # ë³µìˆ˜ JSON ë¸”ë¡ì´ ì„ì—¬ ìˆëŠ” ê²½ìš°ë¥¼ íƒì§€
        try:
            decoder = json.JSONDecoder()
            idx = 0
            stripped = text.strip()
            while idx < len(stripped):
                if stripped[idx] not in "{[":
                    idx += 1
                    continue
                try:
                    obj, next_idx = decoder.raw_decode(stripped[idx:])
                    idx += next_idx
                    if isinstance(obj, dict):
                        obj = [obj]
                    if isinstance(obj, list):
                        for item in obj:
                            norm = normalize_mcq_item(item)
                            if norm:
                                results.append(norm)
                except Exception:
                    idx += 1
            if results:
                return results
        except Exception:
            pass

        # TSV ë˜ëŠ” '---' êµ¬ë¶„ìë¡œ ëœ MCQ íŒŒì‹±
        items = text.split("\n---\n")
        
        for item in items:
            item = item.strip()
            if not item or len(item) < 50:
                continue
            
            # TSV í˜•ì‹: problem_text\texplanation
            parts = item.split('\t')
            problem_part = parts[0].strip() if parts else ""
            explanation_part = parts[1].strip() if len(parts) > 1 else ""
            
            if not problem_part:
                continue
            
            # ì •ë‹µê³¼ ì„ ì§€ ì¶”ì¶œ
            parsed = extract_mcq_components(problem_part)
            if parsed:
                parsed["explanation"] = explanation_part
                results.append(parsed)
    elif mode == mode_cloze:
        # Cloze í˜•ì‹: í•œ ì¤„ì— í•˜ë‚˜ì”©
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if not line or '{{c1::' not in line:
                continue
            
            # í•´ì„¤ ë¶„ë¦¬
            explanation = ""
            if '\t' in line:
                line, explanation = line.split('\t', 1)
            
            # ì •ë‹µ ì¶”ì¶œ
            m = re.search(r'\{\{c1::(.+?)\}\}', line)
            if not m:
                continue
            
            answer = m.group(1).strip()
            front = re.sub(r'\{\{c1::.+?\}\}', '____', line)
            
            results.append({
                "type": "cloze",
                "response_type": "cloze",
                "front": front,
                "answer": answer,
                "explanation": explanation
            })
    elif mode == mode_short:
        results = parse_free_response_items(text, response_type="short")
    elif mode == mode_essay:
        results = parse_free_response_items(text, response_type="essay")
    
    return results


def extract_mcq_components(problem_text):
    """MCQ í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì œ, ì„ ì§€, ì •ë‹µì„ ì¶”ì¶œ
    
    Returns:
        {"type": "mcq", "problem": ..., "options": [...], "answer": ..., "explanation": ""}
        ë˜ëŠ” None (íŒŒì‹± ì‹¤íŒ¨ ì‹œ)
    """
    try:
        # ì •ë‹µ ì¶”ì¶œ
        ans_match = re.search(r"ì •ë‹µ:\s*\{\{c1::([1-5â‘ â‘¡â‘¢â‘£â‘¤]+)\}\}", problem_text)
        if not ans_match:
            return None
        
        ans_str = ans_match.group(1).strip()
        circ_to_num = {'â‘ ': '1', 'â‘¡': '2', 'â‘¢': '3', 'â‘£': '4', 'â‘¤': '5'}
        answer_num = int(circ_to_num.get(ans_str, ans_str))
        
        # ì„ ì§€ ì¶”ì¶œ: â‘  ... â‘¡ ... í˜•ì‹
        options = []
        opt_pattern = r'(?:â‘ |â‘¡|â‘¢|â‘£|â‘¤)\s*([^â‘ â‘¡â‘¢â‘£â‘¤\n]+?)(?=(?:â‘ |â‘¡|â‘¢|â‘£|â‘¤|$))'
        matches = re.findall(opt_pattern, problem_text)
        options = [opt.strip() for opt in matches if opt.strip()]
        
        if len(options) < 3:  # ìµœì†Œ 3ê°œ ì´ìƒ í•„ìš”
            return None
        
        # ì„ ì§€ë¥¼ 5ê°œë¡œ ì •ê·œí™” (ë¶€ì¡±í•˜ë©´ ì±„ìš°ê¸°)
        while len(options) < 5:
            options.append(f"ë³´ê¸° {len(options) + 1}")
        options = options[:5]  # 5ê°œ ì´ˆê³¼ë©´ ìë¥´ê¸°
        
        # ë¬¸ì œ í…ìŠ¤íŠ¸ ì •ì œ: ì •ë‹µ/ì„ ì§€ ì œê±° í›„ ìŠ¤í…œë§Œ ë‚¨ê¸°ê¸°
        problem_clean = re.sub(r'ì •ë‹µ:\s*\{\{c1::.+?\}\}', '', problem_text).strip()
        # ì„ ì§€ ì‹œì‘ ìœ„ì¹˜ ì´ì „ë§Œ ìŠ¤í…œìœ¼ë¡œ ì‚¬ìš©
        first_opt = re.search(r'(â‘ |â‘¡|â‘¢|â‘£|â‘¤)', problem_clean)
        if first_opt:
            stem = problem_clean[:first_opt.start()].strip()
        else:
            stem = problem_clean
        stem = re.sub(r'\s+', ' ', stem)
        if not stem:
            stem = problem_clean
        
        return {
            "type": "mcq",
            "problem": stem,
            "options": options,
            "answer": answer_num,
            "explanation": ""
        }
    except Exception as e:
        import sys
        print(f"[EXTRACT ERROR] {str(e)}", file=sys.stderr)
        return None

def parse_mcq_content(q_data: dict) -> dict:
    """ì €ì¥ëœ MCQ ë°ì´í„°ë¥¼ ì‹œí—˜ í‘œì‹œìš©ìœ¼ë¡œ ë³€í™˜
    
    Args:
        q_data: {"type": "mcq", "problem": ..., "options": [...], "answer": ..., "explanation": ...}
    
    Returns:
        {"type": "mcq", "front": ..., "problem": ..., "options": [...], "correct": ..., "explanation": ...}
    """
    stem = sanitize_mcq_problem_text(q_data.get("problem", ""))
    return {
        "type": "mcq",
        "raw": stem,
        "front": stem,
        "problem": stem,
        "options": q_data.get("options", []),
        "correct": q_data.get("answer"),  # ìˆ«ì í˜•ì‹: 1-5
        "explanation": q_data.get("explanation", ""),
        "subject": q_data.get("subject"),
        "unit": q_data.get("unit"),
        "difficulty": q_data.get("difficulty"),
        "id": q_data.get("id"),
        "fsrs": q_data.get("fsrs"),
        "note": q_data.get("note", ""),
        "images": q_data.get("images", []),
        "stats": q_data.get("stats", {}),
        "bookmarked": bool(q_data.get("bookmarked", False)),
    }

def sanitize_mcq_problem_text(problem_text):
    text = re.sub(r"\s+", " ", str(problem_text or "")).strip()
    if not text:
        return ""

    # ì¤‘ë³µ [ë¬¸ì œ] ë§ˆì»¤ê°€ ë¶™ëŠ” ê²½ìš° ì²« ë¬¸í•­ë§Œ ìœ ì§€
    second_marker = text.find("[ë¬¸ì œ]", len("[ë¬¸ì œ]"))
    if second_marker != -1:
        text = text[:second_marker].strip()

    # ë¬¼ìŒí‘œ ë’¤ì— ê³µë°± ì—†ì´ ë‹¤ë¥¸ ë¬¸í•­ì´ ë¶™ì€ ê²½ìš°(ì˜ˆ: "...ê²ƒì€?TPN)...") ì²« ë¬¸í•­ìœ¼ë¡œ ì ˆë‹¨
    hard_concat = re.search(r"\?[^\s\"'â€â€™)\]}]", text)
    if hard_concat:
        text = text[: hard_concat.start() + 1].strip()

    return text

def parse_cloze_content(q_data: dict) -> dict:
    """ì €ì¥ëœ Cloze ë°ì´í„°ë¥¼ ì‹œí—˜ í‘œì‹œìš©ìœ¼ë¡œ ë³€í™˜
    
    Args:
        q_data: {"type": "cloze", "front": ..., "answer": ..., "explanation": ...}
    
    Returns:
        {"type": "cloze", "front": ..., "raw": ..., "answer": ..., "explanation": ...}
    """
    return {
        "type": "cloze",
        "raw": q_data.get("front", ""),
        "front": q_data.get("front", ""),
        "answer": q_data.get("answer", ""),
        "response_type": q_data.get("response_type", "cloze"),
        "explanation": q_data.get("explanation", ""),
        "subject": q_data.get("subject"),
        "unit": q_data.get("unit"),
        "difficulty": q_data.get("difficulty"),
        "id": q_data.get("id"),
        "fsrs": q_data.get("fsrs"),
        "note": q_data.get("note", ""),
        "images": q_data.get("images", []),
        "stats": q_data.get("stats", {}),
        "bookmarked": bool(q_data.get("bookmarked", False)),
    }

def get_question_stats():
    """ì €ì¥ëœ ë¬¸ì œ í†µê³„"""
    bank = load_questions()
    return {
        "total_text": len(bank.get("text", [])),
        "total_cloze": len(bank.get("cloze", []))
    }

def fuzzy_match(user_answer, correct_answer, threshold=0.8):
    """Cloze ë‹µë³€ ìœ ì‚¬ë„ ë¹„êµ"""
    user_clean = re.sub(r'[^\wê°€-í£]', '', str(user_answer).lower())
    correct_clean = re.sub(r'[^\wê°€-í£]', '', correct_answer.lower())
    
    if user_clean == correct_clean:
        return True
    ratio = SequenceMatcher(None, user_clean, correct_clean).ratio()
    return ratio >= threshold

def calculate_quality_score(item_text, mode):
    """í•­ëª©ì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0~1.0)"""
    score = 0.4
    text = item_text.strip()
    text_len = len(text)
    
    # ê¸¸ì´ ì ìˆ˜
    if 80 < text_len < 500:
        score += 0.25
    elif 50 < text_len < 700:
        score += 0.15
    
    # í˜•ì‹ ì ìˆ˜
    if mode == "ğŸ“ ê°ê´€ì‹ ë¬¸ì œ (Case Study)":
        if "ì •ë‹µ:" in text:
            score += 0.15
        options = len(re.findall(r"â‘ |â‘¡|â‘¢|â‘£|â‘¤", text))
        if options >= 3:
            score += 0.15
    else:  # Cloze
        if "{{c1::" in text:
            score += 0.3
    
    # ì˜í•™ ìš©ì–´ ì ìˆ˜
    medical_keywords = ["ì¦ìƒ", "ì§„ë‹¨", "ì¹˜ë£Œ", "ì§ˆë³‘", "ê²€ì‚¬", "ìˆ˜ì¹˜", "ì§ˆí™˜", "ì¦í›„êµ°"]
    kw_count = sum(1 for kw in medical_keywords if kw in text)
    if kw_count >= 2:
        score += 0.15
    elif kw_count >= 1:
        score += 0.08
    
    if text.endswith((".", "ã€‚")):
        score += 0.08
    
    complex_chars = text.count(",") + text.count(";") + text.count("(")
    if 2 <= complex_chars <= 8:
        score += 0.05
    
    return min(max(score, 0.0), 1.0)

def auto_tag(item_text):
    """íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ë‚œì´ë„/ì¹´í…Œê³ ë¦¬ íƒœê¹…"""
    txt = item_text.lower()
    
    # ì¹´í…Œê³ ë¦¬
    categories = []
    if any(k in txt for k in ["ì‹¬ì¥", "ì‹¬ê·¼", "ë¶€ì •ë§¥", "í˜‘ì‹¬ì¦"]):
        categories.append("cardio")
    if any(k in txt for k in ["í", "í˜¸í¡", "ê¸°ê´€ì§€", "ì²œì‹"]):
        categories.append("pulmonary")
    if any(k in txt for k in ["ì‹ ê²½", "ë‡Œ", "ì²™ì¶”", "ì‹ ê²½ê³„"]):
        categories.append("neuro")
    if any(k in txt for k in ["ì•”", "ì¢…ì–‘", "ì‹ ìƒë¬¼"]):
        categories.append("oncology")
    if any(k in txt for k in ["ì‹ ì¥", "ì‹ ë¶€ì „", "ì‚¬êµ¬ì²´"]):
        categories.append("nephro")
    if not categories:
        categories.append("general")
    
    # ë‚œì´ë„
    length = len(item_text)
    complexity = item_text.count(";") + item_text.count(",")
    if length < 150 and complexity < 3:
        difficulty = "â­ ì‰¬ì›€"
    elif length < 350 and complexity < 6:
        difficulty = "â­â­ ì¤‘ê°„"
    else:
        difficulty = "â­â­â­ ì–´ë ¤ì›€"
    
    return difficulty, categories

def is_answer_correct(q, user_ans):
    if q.get("type") == "mcq":
        correct_choice = q.get("correct")
        return bool(correct_choice and user_ans == correct_choice)
    response_type = q.get("response_type", "cloze")
    if response_type == "essay":
        ai_grade = q.get("_ai_grade")
        return bool(isinstance(ai_grade, dict) and ai_grade.get("is_correct") is True)
    correct_text = q.get("answer")
    return bool(correct_text and isinstance(user_ans, str) and fuzzy_match(user_ans, correct_text))

def parse_iso_datetime(value):
    if not value:
        return None
    try:
        if isinstance(value, (int, float)):
            return datetime.fromtimestamp(value, tz=timezone.utc)
        if isinstance(value, str):
            v = value.replace("Z", "+00:00")
            return datetime.fromisoformat(v)
    except Exception:
        return None
    return None

def get_fsrs_report(questions, now=None):
    if not FSRS_AVAILABLE:
        return None
    check_time = now or datetime.now(timezone.utc)
    total = len(questions)
    stats = get_fsrs_stats(questions, now=check_time)
    review_count_7d = 0
    rating_counts = {"Again": 0, "Hard": 0, "Good": 0, "Easy": 0}
    intervals = []
    last_review = None
    for q in questions:
        fsrs = q.get("fsrs") or {}
        card_data = fsrs.get("card")
        if card_data:
            try:
                card = Card.from_json(card_data)
                if hasattr(card, "interval"):
                    intervals.append(float(card.interval))
            except Exception:
                pass
        # last_rating
        last_rating = fsrs.get("last_rating")
        if last_rating in rating_counts:
            rating_counts[last_rating] += 1

        # logs
        for log in fsrs.get("logs", []) or []:
            if isinstance(log, dict):
                for key in ("review_datetime", "reviewed_at", "time", "date", "review"):
                    dt = parse_iso_datetime(log.get(key))
                    if dt:
                        if dt.tzinfo is None:
                            dt = dt.replace(tzinfo=timezone.utc)
                        if (check_time - dt).days <= 7:
                            review_count_7d += 1
                        if last_review is None or dt > last_review:
                            last_review = dt
                        break
                rating = log.get("rating")
                if isinstance(rating, str) and rating in rating_counts:
                    rating_counts[rating] += 1
    avg_interval = sum(intervals) / len(intervals) if intervals else 0
    return {
        "total": total,
        "stats": stats,
        "review_count_7d": review_count_7d,
        "avg_interval": avg_interval,
        "last_review": last_review.isoformat() if last_review else None,
        "rating_counts": rating_counts,
    }

def update_question_stats(q_id, is_correct):
    bank = load_questions()
    now = datetime.now(timezone.utc).isoformat()
    for key in ("text", "cloze"):
        for item in bank.get(key, []):
            if item.get("id") == q_id:
                stats = item.get("stats") or {}
                stats["right"] = int(stats.get("right", 0))
                stats["wrong"] = int(stats.get("wrong", 0))
                if is_correct:
                    stats["right"] += 1
                else:
                    stats["wrong"] += 1
                stats["last_attempt"] = now
                history = stats.get("history") or []
                history.append({"time": now, "correct": bool(is_correct)})
                stats["history"] = history[-200:]
                item["stats"] = stats
                save_questions(bank)
                append_audit_log("grade.answer", {
                    "question_id": q_id,
                    "correct": bool(is_correct),
                    "score": 1 if is_correct else 0,
                    "grader_version": GRADER_VERSION,
                })
                return stats
    return None

def update_question_note(q_id, note_text):
    bank = load_questions()
    for key in ("text", "cloze"):
        for item in bank.get(key, []):
            if item.get("id") == q_id:
                item["note"] = note_text
                save_questions(bank)
                return True
    return False

def update_question_bookmark(q_id, bookmarked):
    bank = load_questions()
    for key in ("text", "cloze"):
        for item in bank.get(key, []):
            if item.get("id") == q_id:
                item["bookmarked"] = bool(bookmarked)
                save_questions(bank)
                return True
    return False

def update_question_by_id(q_id, patch):
    if not q_id or not isinstance(patch, dict):
        return False
    bank = load_questions()
    for key in ("text", "cloze"):
        for item in bank.get(key, []):
            if item.get("id") == q_id:
                allowed = {
                    "subject", "unit", "problem", "options", "answer", "front",
                    "explanation", "difficulty", "note", "image"
                }
                item.update({k: v for k, v in patch.items() if k in allowed})
                save_questions(bank)
                return True
    return False

def delete_mcq_by_ids(ids):
    if not ids:
        return 0
    data = load_questions()
    before = len(data.get("text", []))
    data["text"] = [q for q in data.get("text", []) if q.get("id") not in ids]
    save_questions(data)
    return before - len(data.get("text", []))

def delete_mcq_by_batch(batch_id):
    if not batch_id:
        return 0
    data = load_questions()
    before = len(data.get("text", []))
    data["text"] = [q for q in data.get("text", []) if (q.get("batch_id") or "legacy") != batch_id]
    save_questions(data)
    return before - len(data.get("text", []))

def get_mcq_batches(questions):
    batches = {}
    for q in questions:
        b = q.get("batch_id") or "legacy"
        batches[b] = batches.get(b, 0) + 1
    return batches

def get_wrong_note_stats(questions):
    wrong_items = []
    total_wrong = 0
    for q in questions:
        stats = q.get("stats") or {}
        wrong = int(stats.get("wrong", 0))
        if wrong > 0:
            wrong_items.append(q)
            total_wrong += wrong
    return wrong_items, total_wrong

def sort_wrong_first(questions, mode="ì˜¤ë‹µ íšŸìˆ˜", weight_recent=0.7, weight_count=0.3):
    def last_wrong_time(q):
        stats = q.get("stats") or {}
        hist = stats.get("history") or []
        latest = None
        for entry in hist:
            if not isinstance(entry, dict):
                continue
            if entry.get("correct") is True:
                continue
            dt = parse_iso_datetime(entry.get("time"))
            if dt:
                if latest is None or dt > latest:
                    latest = dt
        return latest or datetime.min.replace(tzinfo=timezone.utc)

    def score(q):
        stats = q.get("stats") or {}
        wrong = int(stats.get("wrong", 0))
        right = int(stats.get("right", 0))
        total = wrong + right
        rate = wrong / total if total > 0 else 0
        if mode == "ì˜¤ë‹µë¥ ":
            return (rate, wrong)
        if mode == "ìµœê·¼ ì˜¤ë‹µ":
            # ìµœê·¼ ì˜¤ë‹µì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            last_dt = last_wrong_time(q)
            days_since = (datetime.now(timezone.utc) - last_dt).days if last_dt else 9999
            recency_score = 1 / (1 + max(days_since, 0))
            combined = weight_recent * recency_score + weight_count * wrong
            return (combined, recency_score, wrong)
        return (wrong, rate)

    return sorted(questions, key=score, reverse=True)

def compute_recent_accuracy(questions, days=7, now=None):
    check_time = now or datetime.now(timezone.utc)
    cutoff = check_time - timedelta(days=days)
    correct = 0
    total = 0
    for q in questions:
        stats = q.get("stats") or {}
        hist = stats.get("history") or []
        for entry in hist:
            if not isinstance(entry, dict):
                continue
            dt = parse_iso_datetime(entry.get("time"))
            if not dt:
                continue
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            if dt >= cutoff:
                total += 1
                if entry.get("correct") is True:
                    correct += 1
    accuracy = (correct / total * 100) if total > 0 else None
    return {"correct": correct, "total": total, "accuracy": accuracy}

def compute_accuracy_trend(questions, days=14, now=None):
    check_time = now or datetime.now(timezone.utc)
    start = (check_time - timedelta(days=days - 1)).date()
    buckets = {}
    for i in range(days):
        d = start + timedelta(days=i)
        buckets[d.isoformat()] = {"correct": 0, "total": 0}
    for q in questions:
        stats = q.get("stats") or {}
        hist = stats.get("history") or []
        for entry in hist:
            if not isinstance(entry, dict):
                continue
            dt = parse_iso_datetime(entry.get("time"))
            if not dt:
                continue
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            dkey = dt.date().isoformat()
            if dkey in buckets:
                buckets[dkey]["total"] += 1
                if entry.get("correct") is True:
                    buckets[dkey]["correct"] += 1
    series = []
    for dkey in sorted(buckets.keys()):
        total = buckets[dkey]["total"]
        acc = (buckets[dkey]["correct"] / total * 100) if total > 0 else 0
        series.append({"date": dkey, "accuracy": acc})
    return series

def compute_overall_accuracy(questions):
    right = 0
    wrong = 0
    for q in questions:
        stats = q.get("stats") or {}
        right += int(stats.get("right", 0))
        wrong += int(stats.get("wrong", 0))
    total = right + wrong
    if total == 0:
        return None
    accuracy = right / total * 100
    return {"correct": right, "wrong": wrong, "total": total, "accuracy": accuracy}

def fsrs_group_report(questions, group_key, now=None):
    if not FSRS_AVAILABLE:
        return []
    check_time = now or datetime.now(timezone.utc)
    groups = {}
    for q in questions:
        key = (q.get(group_key) or "General")
        g = groups.setdefault(key, {"due": 0, "overdue": 0, "future": 0, "new": 0, "total": 0})
        g["total"] += 1
        fsrs = q.get("fsrs") or {}
        card_data = fsrs.get("card")
        if not card_data:
            g["new"] += 1
            g["due"] += 1
            continue
        try:
            card = Card.from_json(card_data)
            if card.due <= check_time:
                g["due"] += 1
                if card.due < check_time:
                    g["overdue"] += 1
            else:
                g["future"] += 1
        except Exception:
            g["due"] += 1
    rows = []
    for k, v in sorted(groups.items(), key=lambda x: x[0]):
        rows.append({"ê·¸ë£¹": k, **v})
    return rows

def apply_mcq_shortcut(idx):
    val = (st.session_state.get(f"shortcut_{idx}") or "").strip().upper()
    if not val:
        return
    letters = ["A", "B", "C", "D", "E"]
    sel = None
    if val in letters:
        sel = letters.index(val)
    elif val.isdigit():
        n = int(val)
        if 1 <= n <= 5:
            sel = n - 1
    labels = st.session_state.get(f"labels_real_{idx}") or []
    if sel is not None and 0 <= sel < len(labels):
        st.session_state[f"q_{idx}"] = labels[sel]

def goto_prev_question():
    st.session_state.current_question_idx = max(0, st.session_state.current_question_idx - 1)

def goto_next_question():
    total = len(st.session_state.get("exam_questions", []))
    if total:
        st.session_state.current_question_idx = min(total - 1, st.session_state.current_question_idx + 1)

def finish_exam_session():
    st.session_state.exam_finished = True

def get_unique_subjects(questions):
    subjects = sorted({(q.get("subject") or "General") for q in questions})
    return subjects

def get_unit_name(q):
    return q.get("unit") or q.get("chapter") or q.get("topic") or "ë¯¸ë¶„ë¥˜"

def get_units_by_subject(questions):
    mapping = {}
    for q in questions:
        subj = (q.get("subject") or "General")
        unit = get_unit_name(q)
        mapping.setdefault(subj, set()).add(unit)
    return {k: sorted(v) for k, v in mapping.items()}

def filter_questions_by_subject(questions, selected_subjects):
    if not selected_subjects:
        return questions
    return [q for q in questions if (q.get("subject") or "General") in selected_subjects]

def filter_questions_by_subject_unit(questions, selected_subjects, selected_units):
    if not selected_subjects and not selected_units:
        return questions
    filtered = []
    for q in questions:
        subj = q.get("subject") or "General"
        unit = get_unit_name(q)
        if selected_subjects and subj not in selected_subjects:
            continue
        if selected_units and unit not in selected_units:
            continue
        filtered.append(q)
    return filtered

def filter_questions_by_subject_unit_hierarchy(questions, selected_subjects, unit_filter_by_subject):
    """ë¶„ê³¼ ë‹¨ìœ„ ê³„ì¸µ í•„í„°(ê³¼ëª©ë³„ ë‹¨ì› ì„ íƒ)"""
    if not questions:
        return []
    if not selected_subjects:
        return []
    out = []
    for q in questions:
        subj = q.get("subject") or "General"
        if subj not in selected_subjects:
            continue
        unit = get_unit_name(q)
        allowed_units = unit_filter_by_subject.get(subj)
        if not allowed_units:
            continue
        if unit in allowed_units:
            out.append(q)
    return out

def collect_subject_unit_map(questions):
    """ë¶„ê³¼ë³„ ë‹¨ì› ëª©ë¡ ìƒì„±"""
    mapping = {}
    for q in questions:
        subj = q.get("subject") or "General"
        unit = get_unit_name(q)
        mapping.setdefault(subj, set()).add(unit)
    return {k: sorted(v) for k, v in mapping.items()}

def collect_export_questions(questions, selected_subjects, unit_filter_by_subject, include_all_units=True, randomize=False, random_seed=None):
    if include_all_units:
        if selected_subjects:
            items = filter_questions_by_subject(questions, selected_subjects)
        else:
            items = list(questions)
    else:
        items = filter_questions_by_subject_unit_hierarchy(questions, selected_subjects, unit_filter_by_subject)
    out = list(items)
    if randomize and len(out) > 1:
        rng = random.Random(random_seed)
        rng.shuffle(out)
    return out

def get_question_attempt_summary(question):
    stats = question.get("stats") or {}
    right = int(stats.get("right", 0))
    wrong = int(stats.get("wrong", 0))
    attempts = right + wrong
    history = stats.get("history") or []
    last = history[-1] if history else {}
    last_correct = bool(last.get("correct")) if isinstance(last, dict) and "correct" in last else None
    last_time = last.get("time") if isinstance(last, dict) else None
    return {
        "right": right,
        "wrong": wrong,
        "attempts": attempts,
        "last_correct": last_correct,
        "last_time": last_time,
    }

def select_learning_session_questions(questions, learning_mode="íƒìƒ‰í˜•", num_questions=10, random_seed=None):
    items = list(questions or [])
    if not items:
        return []
    if str(learning_mode).startswith("íƒìƒ‰í˜•"):
        return sorted(
            items,
            key=lambda q: (
                q.get("subject") or "General",
                get_unit_name(q),
                str(q.get("id") or ""),
                str(q.get("problem") or q.get("front") or ""),
            ),
        )
    n = min(max(1, int(num_questions or 1)), len(items))
    if n >= len(items):
        return items
    rng = random.Random(random_seed) if random_seed is not None else random
    return rng.sample(items, n)

def _exam_group_key(question, group_mode="ë¶„ê³¼+ë‹¨ì›"):
    subject = question.get("subject") or "General"
    if group_mode == "ë¶„ê³¼":
        return subject
    unit = get_unit_name(question)
    return f"{subject}::{unit}"

def select_exam_questions_balanced(
    questions,
    num_questions,
    distribution_mode="ë¹„ë¡€(ë³´ìœ  ë¬¸í•­ ê¸°ì¤€)",
    group_mode="ë¶„ê³¼+ë‹¨ì›",
    random_seed=None,
):
    items = list(questions or [])
    if not items:
        return []
    target_n = min(max(1, int(num_questions or 1)), len(items))
    rng = random.Random(random_seed) if random_seed is not None else random

    groups = {}
    for q in items:
        key = _exam_group_key(q, group_mode=group_mode)
        groups.setdefault(key, []).append(q)
    for key in groups:
        rng.shuffle(groups[key])

    keys = list(groups.keys())
    if not keys:
        return []
    available = {k: len(groups[k]) for k in keys}

    if distribution_mode == "ê· ë“±(ì„ íƒ ê·¸ë£¹ ê¸°ì¤€)":
        weights = {k: 1.0 for k in keys}
    else:
        weights = {k: float(available[k]) for k in keys}

    total_weight = sum(weights.values()) or 1.0
    raw_alloc = {k: (target_n * weights[k] / total_weight) for k in keys}
    alloc = {k: min(int(raw_alloc[k]), available[k]) for k in keys}
    remaining = target_n - sum(alloc.values())

    order = sorted(keys, key=lambda k: (raw_alloc[k] - int(raw_alloc[k]), available[k]), reverse=True)
    while remaining > 0:
        progressed = False
        for k in order:
            if alloc[k] < available[k]:
                alloc[k] += 1
                remaining -= 1
                progressed = True
                if remaining <= 0:
                    break
        if not progressed:
            break

    selected = []
    for k in keys:
        selected.extend(groups[k][: alloc[k]])

    if len(selected) < target_n:
        chosen = {id(x) for x in selected}
        leftovers = [q for q in items if id(q) not in chosen]
        need = target_n - len(selected)
        if leftovers:
            rng.shuffle(leftovers)
            selected.extend(leftovers[:need])
    return selected[:target_n]


def summarize_subject_review_status(questions):
    """ë¶„ê³¼ë³„ ë³µìŠµ ìƒíƒœ(ë³µìŠµëŒ€ìƒ/ì—°ì²´/ë‹¨ì› ìˆ˜) ìš”ì•½"""
    if not questions:
        return []
    now = datetime.now(timezone.utc)

    # ì˜¤ë‹µë¬¸í•­(í†µê³„ ê¸°ë°˜)
    wrong_by_subject = {}
    for q in questions:
        subj = q.get("subject") or "General"
        if int((q.get("stats") or {}).get("wrong", 0)) > 0:
            wrong_by_subject[subj] = wrong_by_subject.get(subj, 0) + 1

    if FSRS_AVAILABLE:
        rows = fsrs_group_report(questions, "subject", now=now)
        out = []
        for row in rows:
            subject_name = row.get("ê·¸ë£¹") or "General"
            out.append({
                "ë¶„ê³¼": subject_name,
                "ì´ë¬¸í•­": row.get("total", 0),
                "ë³µìŠµëŒ€ìƒ": row.get("due", 0),
                "ì—°ì²´": row.get("overdue", 0),
                "ë¯¸ë˜": row.get("future", 0),
                "ì‹ ê·œ": row.get("new", 0),
                "ì˜¤ë‹µë¬¸í•­": wrong_by_subject.get(subject_name, 0),
            })
        return sorted(out, key=lambda x: (x["ë³µìŠµëŒ€ìƒ"], x["ì´ë¬¸í•­"]), reverse=True)

    summary = {}
    for q in questions:
        subj = q.get("subject") or "General"
        row = summary.setdefault(subj, {"ë¶„ê³¼": subj, "ì´ë¬¸í•­": 0, "ë³µìŠµëŒ€ìƒ": 0, "ì—°ì²´": 0, "ë¯¸ë˜": 0, "ì‹ ê·œ": 0})
        row["ì´ë¬¸í•­"] += 1

        due_at = (q.get("srs") or {}).get("due")
        try:
            if due_at:
                due_dt = datetime.fromisoformat(str(due_at).replace("Z", "+00:00"))
                if due_dt.tzinfo is None:
                    due_dt = due_dt.replace(tzinfo=timezone.utc)
                if due_dt <= now:
                    row["ë³µìŠµëŒ€ìƒ"] += 1
            else:
                row["ë³µìŠµëŒ€ìƒ"] += 1
        except Exception:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ë³µìŠµ ëŒ€ìƒ ì²˜ë¦¬(ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œìš©ìœ¼ë¡œëŠ” ì•ˆì „í•œ ê¸°ë³¸ê°’)
            row["ë³µìŠµëŒ€ìƒ"] += 1

        row["ì˜¤ë‹µë¬¸í•­"] = wrong_by_subject.get(subj, row.get("ì˜¤ë‹µë¬¸í•­", 0))
    # ê¸°ë³¸ SRSëŠ” ì—°ì²´/ë¯¸ë˜/ì‹ ê·œë¥¼ ë”°ë¡œ ì¶”ì í•˜ì§€ ì•ŠìŒ
    return sorted(summary.values(), key=lambda x: (x["ë³µìŠµëŒ€ìƒ"], x["ì´ë¬¸í•­"]), reverse=True)

def build_exam_payload(raw_items, exam_type):
    """ë¬¸í•­ ëª©ë¡ì„ ì‹œí—˜ ì§„í–‰ìš© payloadë¡œ ë³€í™˜"""
    parsed = []
    for raw in raw_items:
        if exam_type == "ê°ê´€ì‹":
            parsed_item = parse_mcq_content(raw)
        else:
            parsed_item = parse_cloze_content(raw)
        if parsed_item:
            parsed.append(parsed_item)
    return parsed

def start_exam_session_from_items(raw_items, exam_type, mode):
    """ë¬¸í•­ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œí—˜/í•™ìŠµ ì„¸ì…˜ì„ ì¦‰ì‹œ ì‹œì‘"""
    parsed = build_exam_payload(raw_items, exam_type)
    if not parsed:
        return 0
    st.session_state.exam_questions = parsed
    st.session_state.current_question_idx = 0
    st.session_state.user_answers = {}
    st.session_state.exam_started = True
    st.session_state.exam_finished = False
    st.session_state.exam_mode = mode
    st.session_state.exam_type = exam_type
    st.session_state.auto_next = False
    st.session_state.auto_advance_guard = None
    st.session_state.revealed_answers = set()
    st.session_state.exam_stats_applied = False
    st.session_state.graded_questions = set()
    st.session_state.exam_history_saved = False
    st.session_state.current_exam_meta = {
        "mode": mode,
        "type": exam_type,
        "subjects": sorted({(q.get("subject") or "General") for q in raw_items}),
        "units": sorted({get_unit_name(q) for q in raw_items}),
        "num_questions": len(parsed),
        "started_at": datetime.now(timezone.utc).isoformat()
    }
    return len(parsed)

def normalize_mcq_item(item):
    if not isinstance(item, dict):
        return None
    if "content" in item and "problem" not in item:
        parsed = extract_mcq_components(item.get("content", ""))
        if parsed:
            parsed["explanation"] = item.get("explanation", "")
            parsed["subject"] = item.get("subject")
            parsed["unit"] = item.get("unit")
            parsed["difficulty"] = item.get("difficulty")
            parsed["id"] = item.get("id")
            parsed["fsrs"] = item.get("fsrs")
            return parsed
    problem = (item.get("problem") or "").strip()
    options = item.get("options") or []
    answer = item.get("answer", 1)
    explanation = item.get("explanation", "")
    if not problem or not isinstance(options, list):
        return None
    # ì˜µì…˜ ê¸¸ì´ 5ë¡œ ì •ê·œí™”
    options = [str(opt).strip() for opt in options if str(opt).strip()]
    while len(options) < 5:
        options.append(f"ë³´ê¸° {len(options) + 1}")
    options = options[:5]
    try:
        answer_num = int(answer)
    except Exception:
        answer_num = 1
    if answer_num < 1 or answer_num > 5:
        answer_num = 1
    return {
        "type": "mcq",
        "problem": problem,
        "options": options,
        "answer": answer_num,
        "explanation": explanation,
        "subject": item.get("subject"),
        "unit": item.get("unit"),
        "difficulty": item.get("difficulty"),
        "id": item.get("id"),
        "fsrs": item.get("fsrs"),
    }

def normalize_cloze_item(item):
    if not isinstance(item, dict):
        return None
    if "content" in item and "front" not in item:
        # êµ¬ë²„ì „ content í•„ë“œ
        content = item.get("content", "")
        if "{{c1::" in content:
            m = re.search(r'\{\{c1::(.+?)\}\}', content)
            if m:
                answer = m.group(1).strip()
                front = re.sub(r'\{\{c1::.+?\}\}', '____', content)
                return {
                    "type": "cloze",
                    "response_type": item.get("response_type", "cloze"),
                    "front": front,
                    "answer": answer,
                    "explanation": item.get("explanation", ""),
                    "subject": item.get("subject"),
                    "unit": item.get("unit"),
                    "difficulty": item.get("difficulty"),
                    "id": item.get("id"),
                    "fsrs": item.get("fsrs"),
                }
        return None
    front = (item.get("front") or "").strip()
    answer = (item.get("answer") or "").strip()
    explanation = item.get("explanation", "")
    response_type = item.get("response_type", "cloze")
    if response_type not in {"cloze", "short", "essay"}:
        response_type = "cloze"
    if not front or not answer:
        return None
    return {
        "type": "cloze",
        "response_type": response_type,
        "front": front,
        "answer": answer,
        "explanation": explanation,
        "subject": item.get("subject"),
        "unit": item.get("unit"),
        "difficulty": item.get("difficulty"),
        "id": item.get("id"),
        "fsrs": item.get("fsrs"),
    }

def format_explanation_text(text):
    if not text:
        return ""
    if "|" in text:
        parts = [p.strip() for p in re.split(r"\s*\|\s*", text) if p.strip()]
        if len(parts) > 1:
            return "\n".join([f"- {p}" for p in parts])
    return text

def _set_row_cant_split(row):
    tr_pr = row._tr.get_or_add_trPr()
    if not any(child.tag.endswith("cantSplit") for child in tr_pr):
        tr_pr.append(OxmlElement("w:cantSplit"))

def build_docx_question_sheet(items, title="Axioma Qbank ë¬¸ì œì§‘"):
    doc = Document()
    doc.add_heading(title, level=1)
    doc.add_paragraph("ì¢Œì¸¡: ë¬¸í•­ | ìš°ì¸¡: ì •ë‹µ ë° í•´ì„¤")
    table = doc.add_table(rows=1, cols=2)
    table.style = "Table Grid"
    table.autofit = True
    table.rows[0].cells[0].text = "ë¬¸í•­"
    table.rows[0].cells[1].text = "ì •ë‹µ & í•´ì„¤"

    letters = ["A", "B", "C", "D", "E"]
    for i, item in enumerate(items, 1):
        row = table.add_row()
        _set_row_cant_split(row)
        left = row.cells[0]
        right = row.cells[1]

        stem = (item.get("problem") or item.get("front") or item.get("raw") or "").strip()
        left.text = f"ë¬¸í•­ {i}\n{stem}"

        if item.get("type") == "mcq":
            opts = item.get("options") or []
            if opts:
                left.add_paragraph("")
            for j, opt in enumerate(opts[:5]):
                left.add_paragraph(f"{letters[j]}. {opt}")
            correct = item.get("answer") or item.get("correct")
            right.text = "ì •ë‹µ"
            if isinstance(correct, int) and 1 <= correct <= 5:
                right.add_paragraph(letters[correct - 1])
            else:
                right.add_paragraph(str(correct))
        else:
            right.text = "ì •ë‹µ"
            right.add_paragraph(str(item.get("answer", "")))

        explanation = (item.get("explanation") or "").strip()
        if explanation:
            right.add_paragraph("")
            right.add_paragraph("í•´ì„¤")
            for line in format_explanation_text(explanation).splitlines():
                right.add_paragraph(line)

    out = io.BytesIO()
    doc.save(out)
    out.seek(0)
    return out.getvalue()


def _to_markdown_table(rows):
    """pyarrow ì˜ì¡´ì„± ì—†ì´ ê°„ë‹¨í•œ í‘œ ë Œë”ë§."""
    if not rows:
        st.caption("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    if hasattr(rows, "to_dict"):
        try:
            rows = rows.to_dict(orient="records")
        except Exception:
            rows = list(rows)
    if not isinstance(rows, list):
        rows = list(rows)
    if not rows:
        st.caption("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    first = rows[0]
    if not isinstance(first, dict):
        try:
            rows = [dict(item) for item in rows]
        except Exception:
            st.caption("í‘œ í˜•ì‹ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return

    if not rows:
        st.caption("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    headers = list(rows[0].keys())

    def _fmt(v):
        if v is None:
            return ""
        if isinstance(v, (list, tuple)):
            return ", ".join([str(x) for x in v])
        return str(v).replace("|", "\\|").replace("\n", "<br>")

    header_line = "| " + " | ".join(headers) + " |\n"
    sep_line = "|" + "|".join([" --- " for _ in headers]) + "| \n"
    body_lines = []
    for row in rows:
        vals = [_fmt(row.get(h, "")) for h in headers]
        body_lines.append("| " + " | ".join(vals) + " |")
    table = header_line + sep_line + "\n".join(body_lines)
    st.markdown(table)


def safe_dataframe(data, fallback_to_markdown=True, *args, **kwargs):
    """Use st.dataframe when available, fallback to markdown table if it fails."""
    try:
        return st.dataframe(data, *args, **kwargs)
    except Exception:
        if not fallback_to_markdown:
            raise
        _to_markdown_table(data)

def _is_option_line(line):
    if re.match(r"^\s*[â‘ â‘¡â‘¢â‘£â‘¤]", line):
        return True
    if re.match(r"^\s*[1-5][).]", line):
        return True
    return False

def _answer_token_to_num(token):
    token = str(token).strip()
    circled = {"â‘ ": 1, "â‘¡": 2, "â‘¢": 3, "â‘£": 4, "â‘¤": 5}
    if token in circled:
        return circled[token]
    if token.isdigit():
        n = int(token)
        if 1 <= n <= 5:
            return n
    token = token.upper()
    if token in ["A", "B", "C", "D", "E"]:
        return ord(token) - ord("A") + 1
    return None

def preclean_exam_text(text):
    if not text:
        return ""
    lines = [l.rstrip() for l in text.splitlines()]

    # Find first probable question line
    q_re = re.compile(r"^\s*(?:ë¬¸í•­|ë¬¸ì œ|Question|Q)?\s*\d{1,3}\s*[).]")
    q_alt = re.compile(r"[â‘ â‘¡â‘¢â‘£â‘¤]")
    first_idx = None
    for i, line in enumerate(lines):
        if q_re.match(line.strip()) or q_alt.search(line):
            first_idx = i
            break
    if first_idx is not None:
        lines = lines[first_idx:]

    # Remove page-only lines like "- 3 -" or empty separators
    cleaned = []
    for line in lines:
        s = line.strip()
        if not s:
            cleaned.append("")
            continue
        if re.match(r"^[-â€“â€”]{2,}$", s):
            cleaned.append("")
            continue
        if re.match(r"^[-â€“â€”]?\s*\d+\s*[-â€“â€”]?$", s):
            # page number lines
            cleaned.append("")
            continue
        cleaned.append(line)

    # Merge standalone number lines with the following text line
    merged = []
    i = 0
    num_re = re.compile(r"^\s*\d{1,3}\s*[).]?\s*$")
    while i < len(cleaned):
        line = cleaned[i]
        if num_re.match(line.strip()):
            j = i + 1
            while j < len(cleaned) and not cleaned[j].strip():
                j += 1
            if j < len(cleaned):
                merged.append(f"{line.strip()} {cleaned[j].strip()}".strip())
                i = j + 1
                continue
        merged.append(line)
        i += 1

    # Normalize excessive spaces
    merged = [re.sub(r"[ \t]+", " ", l).strip() for l in merged]
    return "\n".join([l for l in merged if l is not None]).strip()

def parse_exam_text_fuzzy(text, preclean=True):
    """ê¸°ì¶œë¬¸ì œ ì›ë¬¸ì„ ìµœëŒ€í•œ íŒŒì‹±í•´ MCQ/Clozeë¡œ ë³€í™˜ (ë² íƒ€)"""
    if not text:
        return []
    if preclean:
        text = preclean_exam_text(text) or text

    def insert_breaks(raw):
        # Insert line breaks before common question markers to improve splitting
        raw = re.sub(r"(?<!\n)(Question\s*\d+\s*[).])", r"\n\1", raw, flags=re.IGNORECASE)
        raw = re.sub(r"(?<!\n)(ë¬¸í•­\s*\d+\s*[).])", r"\n\1", raw)
        raw = re.sub(r"(?<!\n)(ë¬¸ì œ\s*\d+\s*[).])", r"\n\1", raw)
        raw = re.sub(r"(?<!\n)(Q\s*\d+\s*[).])", r"\n\1", raw, flags=re.IGNORECASE)
        return raw

    def split_exam_blocks_simple(raw):
        raw = insert_breaks(raw)
        pattern = re.compile(r"(?m)^\s*(?:ë¬¸í•­|ë¬¸ì œ|Question|Q)?\s*(\d{1,3})\s*[).]\s*", re.IGNORECASE)
        matches = list(pattern.finditer(raw))
        if matches:
            blocks = []
            for i, m in enumerate(matches):
                start = m.start()
                end = matches[i + 1].start() if i + 1 < len(matches) else len(raw)
                blocks.append(raw[start:end].strip())
            return blocks
        blocks = [b.strip() for b in re.split(r"\n-{3,}\n", raw) if b.strip()]
        return blocks if blocks else [raw.strip()]

    def split_blocks(raw):
        raw = insert_breaks(raw)
        pattern = re.compile(r"(?m)^\s*(?:ë¬¸í•­|ë¬¸ì œ|Question|Q)?\s*(\d{1,3})\s*[).]\s*", re.IGNORECASE)
        matches = list(pattern.finditer(raw))
        if matches:
            blocks = []
            for i, m in enumerate(matches):
                start = m.start()
                end = matches[i + 1].start() if i + 1 < len(matches) else len(raw)
                blocks.append((raw[start:end].strip(), int(m.group(1))))
            return blocks
        # fallback: split by long dashes or blank lines
        blocks = [b.strip() for b in re.split(r"\n-{3,}\n", raw) if b.strip()]
        return [(b, None) for b in blocks] if blocks else [(raw.strip(), None)]

    def extract_answer_and_explanation(block):
        ans = None
        exp_lines = []
        capturing = False
        for line in block.splitlines():
            line = line.strip()
            if not line:
                continue
            if re.match(r"^\s*(?:ë¬¸í•­|ë¬¸ì œ|Question|Q)?\s*\d{1,3}\s*[).]\s*", line, re.IGNORECASE):
                if capturing:
                    break
            m = re.match(r"^(ì •ë‹µ|ë‹µ)\s*[:ï¼š]?\s*(.+)$", line)
            if m:
                ans = m.group(2).strip()
                capturing = True
                continue
            m2 = re.match(r"^(í•´ì„¤|ì„¤ëª…)\s*[:ï¼š]?\s*(.+)$", line)
            if m2:
                capturing = True
                exp_lines.append(m2.group(2).strip())
                continue
            if capturing:
                if _is_option_line(line):
                    continue
                exp_lines.append(line)
        exp = "\n".join([l for l in exp_lines if l]).strip()
        return ans, exp

    items = []
    for block, qnum in split_blocks(text):
        if not block:
            continue
        source_page = None
        for line in block.splitlines():
            m_page = re.match(r"^===\s*í˜ì´ì§€\s*(\d+)\s*===", line.strip())
            if m_page:
                source_page = int(m_page.group(1))
        ans_token, explanation = extract_answer_and_explanation(block)
        # remove answer/explanation lines for stem/options parsing
        cleaned = "\n".join(
            [ln for ln in block.splitlines() if not re.match(r"^\s*(ì •ë‹µ|ë‹µ|í•´ì„¤|ì„¤ëª…)\s*[:ï¼š]", ln.strip())]
        ).strip()

        # try circled options
        if "â‘ " in cleaned:
            parts = re.split(r"[â‘ â‘¡â‘¢â‘£â‘¤]", cleaned)
            stem = parts[0].strip()
            stem = re.sub(r"^\s*(?:ë¬¸í•­\s*)?\d+\s*[).]\s*", "", stem).strip()
            options = [p.strip() for p in parts[1:] if p.strip()]
            if len(options) >= 3:
                answer_num = _answer_token_to_num(ans_token) or 1
                items.append({
                    "type": "mcq",
                    "problem": stem,
                    "options": options[:5],
                    "answer": answer_num,
                    "explanation": explanation,
                    "page": source_page,
                    "qnum": qnum,
                })
                continue

        # try numbered options (1) 2) ...
        opt_lines = re.findall(r"(?m)^\s*[1-5][).]\s*(.+)$", cleaned)
        if len(opt_lines) >= 3:
            stem = re.split(r"(?m)^\s*[1-5][).]\s*", cleaned)[0].strip()
            stem = re.sub(r"^\s*(?:ë¬¸í•­\s*)?\d+\s*[).]\s*", "", stem).strip()
            answer_num = _answer_token_to_num(ans_token) or 1
            items.append({
                "type": "mcq",
                "problem": stem,
                "options": [o.strip() for o in opt_lines][:5],
                "answer": answer_num,
                "explanation": explanation,
                "page": source_page,
                "qnum": qnum,
            })
            continue

        # fallback to cloze if answer exists
        if ans_token:
            answer_text = str(ans_token).strip()
            stem = re.sub(r"^\s*(?:ë¬¸í•­\s*)?\d+\s*[).]\s*", "", cleaned).strip()
            if stem and answer_text:
                items.append({
                    "type": "cloze",
                    "front": stem,
                    "answer": answer_text,
                    "explanation": explanation,
                    "page": source_page,
                    "qnum": qnum,
                })
                continue
    return clean_parsed_items(items)

def split_exam_blocks(raw):
    if not raw:
        return []
    raw = re.sub(r"(?<!\n)(Question\s*\d+\s*[).])", r"\n\1", raw, flags=re.IGNORECASE)
    raw = re.sub(r"(?<!\n)(ë¬¸í•­\s*\d+\s*[).])", r"\n\1", raw)
    raw = re.sub(r"(?<!\n)(ë¬¸ì œ\s*\d+\s*[).])", r"\n\1", raw)
    raw = re.sub(r"(?<!\n)(Q\s*\d+\s*[).])", r"\n\1", raw, flags=re.IGNORECASE)
    pattern = re.compile(r"(?m)^\s*(?:ë¬¸í•­|ë¬¸ì œ|Question|Q)?\s*(\d{1,3})\s*[).]\s*", re.IGNORECASE)
    matches = list(pattern.finditer(raw))
    if matches:
        blocks = []
        for i, m in enumerate(matches):
            start = m.start()
            end = matches[i + 1].start() if i + 1 < len(matches) else len(raw)
            blocks.append(raw[start:end].strip())
        return blocks
    blocks = [b.strip() for b in re.split(r"\n-{3,}\n", raw) if b.strip()]
    return blocks if blocks else [raw.strip()]

def parse_answer_map_from_text(text):
    answer_map = {}
    for block in split_exam_blocks(text):
        if not block:
            continue
        m = re.match(r"^\s*(?:ë¬¸í•­|ë¬¸ì œ|Question|Q)?\s*(\d{1,3})\s*[).]", block.strip(), re.IGNORECASE)
        qnum = int(m.group(1)) if m else None
        ans = None
        exp_lines = []
        for line in block.splitlines():
            l = line.strip()
            if not l:
                continue
            m_ans = re.search(r"(ì •ë‹µ|ë‹µ)\s*[:ï¼š]?\s*([â‘ â‘¡â‘¢â‘£â‘¤1-5])", l)
            if m_ans:
                ans = m_ans.group(2)
                rest = l[m_ans.end():].strip()
                if rest:
                    exp_lines.append(rest)
                continue
            m_ans2 = re.search(r"â–¶\s*([â‘ â‘¡â‘¢â‘£â‘¤1-5])", l)
            if m_ans2 and ans is None:
                ans = m_ans2.group(1)
                rest = l[m_ans2.end():].strip()
                if rest:
                    exp_lines.append(rest)
                continue
            m_qans = re.match(r"^\s*\d{1,3}\s*[).]?\s*([â‘ â‘¡â‘¢â‘£â‘¤1-5])\b\s*(.*)$", l)
            if m_qans and ans is None:
                ans = m_qans.group(1)
                if m_qans.group(2).strip():
                    exp_lines.append(m_qans.group(2).strip())
                continue
            if ans is None and re.match(r"^[â‘ â‘¡â‘¢â‘£â‘¤1-5]$", l):
                ans = l
                continue
            if ans is not None:
                if re.match(r"^\s*(?:ë¬¸í•­|ë¬¸ì œ|Question|Q)?\s*\d{1,3}\s*[).]", l, re.IGNORECASE):
                    break
                exp_lines.append(l)
        if qnum and ans:
            answer_map[qnum] = {"answer": ans, "explanation": "\n".join(exp_lines).strip()}
    return answer_map

def parse_pdf_layout(pdf_bytes):
    items_all = []
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        for page_idx in range(doc.page_count):
            page = doc.load_page(page_idx)
            width = page.rect.width
            data = page.get_text("dict")
            lines = []
            for block in data.get("blocks", []):
                for line in block.get("lines", []):
                    text = "".join(span.get("text", "") for span in line.get("spans", []))
                    text = text.strip()
                    if not text:
                        continue
                    x0, y0, x1, y1 = line.get("bbox", [0, 0, 0, 0])
                    lines.append({"text": text, "x0": x0, "x1": x1, "y0": y0})

            if not lines:
                continue

            centers = [((l["x0"] + l["x1"]) / 2) for l in lines]
            left_lines = [l for l, c in zip(lines, centers) if c < width * 0.45]
            right_lines = [l for l, c in zip(lines, centers) if c > width * 0.55]
            middle_lines = [l for l, c in zip(lines, centers) if width * 0.45 <= c <= width * 0.55]
            marker_lines = [l for l in middle_lines if re.match(r"^\s*\d{1,3}\s*[).]?\s*$", l["text"])]
            two_col = len(left_lines) >= 5 and len(right_lines) >= 5

            def merge_number_lines(ls, tol=4.0):
                num_re = re.compile(r"^\s*\d{1,3}\s*[).]?\s*$")
                merged = set()
                for i, num_line in enumerate(ls):
                    if not num_re.match(num_line["text"]):
                        continue
                    # find closest non-number line within tolerance
                    candidates = []
                    for j, other in enumerate(ls):
                        if i == j or num_re.match(other["text"]):
                            continue
                        dy = abs(other["y0"] - num_line["y0"])
                        if dy <= tol:
                            candidates.append((dy, j, other))
                    if candidates:
                        _, j, target = min(candidates, key=lambda x: x[0])
                        prefix = num_line["text"].strip()
                        if not target["text"].strip().startswith(prefix):
                            target["text"] = f"{prefix} {target['text']}".strip()
                        merged.add(i)
                return [l for idx, l in enumerate(ls) if idx not in merged]

            def build_text(ls):
                ls_sorted = sorted(ls, key=lambda x: (x["y0"], x["x0"]))
                text = "\n".join([l["text"] for l in ls_sorted])
                return f"=== í˜ì´ì§€ {page_idx + 1} ===\n" + text

            if two_col:
                left_text = build_text(merge_number_lines(left_lines + marker_lines))
                right_text = build_text(merge_number_lines(right_lines + marker_lines))
                items = parse_exam_text_fuzzy(left_text)
                ans_map = parse_answer_map_from_text(right_text)
                for idx, it in enumerate(items):
                    if not it.get("page"):
                        it["page"] = page_idx + 1
                    qnum = it.get("qnum")
                    if qnum in ans_map:
                        ans_token = ans_map[qnum].get("answer")
                        exp = ans_map[qnum].get("explanation") or ""
                    else:
                        # fallback: ìˆœì„œ ê¸°ë°˜ ë§¤ì¹­
                        keys = sorted(ans_map.keys())
                        ans_token = ans_map.get(keys[idx], {}).get("answer") if idx < len(keys) else None
                        exp = ans_map.get(keys[idx], {}).get("explanation") if idx < len(keys) else ""
                    if it.get("type") == "mcq" and ans_token:
                        it["answer"] = _answer_token_to_num(ans_token) or it.get("answer")
                    elif it.get("type") == "cloze" and ans_token:
                        it["answer"] = it.get("answer") or ans_token
                    if exp and not it.get("explanation"):
                        it["explanation"] = exp
                items_all.extend(items)
            else:
                full_text = build_text(lines)
                items = parse_exam_text_fuzzy(full_text)
                for it in items:
                    if not it.get("page"):
                        it["page"] = page_idx + 1
                items_all.extend(items)
        doc.close()
    except Exception:
        return []
    return clean_parsed_items(items_all)

def parse_pdf_layout_ai(pdf_bytes, ai_model, api_key=None, openai_api_key=None, hint_text=""):
    items_all = []
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        for page_idx in range(doc.page_count):
            page = doc.load_page(page_idx)
            width = page.rect.width
            data = page.get_text("dict")
            lines = []
            for block in data.get("blocks", []):
                for line in block.get("lines", []):
                    text = "".join(span.get("text", "") for span in line.get("spans", []))
                    text = text.strip()
                    if not text:
                        continue
                    x0, y0, x1, y1 = line.get("bbox", [0, 0, 0, 0])
                    lines.append({"text": text, "x0": x0, "x1": x1, "y0": y0})
            if not lines:
                continue
            centers = [((l["x0"] + l["x1"]) / 2) for l in lines]
            left_lines = [l for l, c in zip(lines, centers) if c < width * 0.45]
            right_lines = [l for l, c in zip(lines, centers) if c > width * 0.55]
            middle_lines = [l for l, c in zip(lines, centers) if width * 0.45 <= c <= width * 0.55]
            marker_lines = [l for l in middle_lines if re.match(r"^\s*\d{1,3}\s*[).]?\s*$", l["text"])]

            def build_text(ls):
                ls_sorted = sorted(ls, key=lambda x: (x["y0"], x["x0"]))
                text = "\n".join([l["text"] for l in ls_sorted])
                return f"=== í˜ì´ì§€ {page_idx + 1} ===\n" + text

            left_text = build_text(left_lines + marker_lines)
            right_text = build_text(right_lines + marker_lines)
            ai_items = ai_parse_exam_layout(
                left_text,
                right_text,
                ai_model=ai_model,
                api_key=api_key,
                openai_api_key=openai_api_key,
                hint_text=hint_text
            )
            for it in ai_items:
                it["page"] = page_idx + 1
            items_all.extend(ai_items)
        doc.close()
    except Exception:
        return []
    return clean_parsed_items(items_all)

def extract_pdf_page_texts(pdf_bytes):
    texts = []
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        for i in range(doc.page_count):
            page = doc.load_page(i)
            page_text = page.get_text().strip()
            texts.append(page_text)
        doc.close()
    except Exception:
        return []
    return texts

def match_questions_to_pages(items, page_texts):
    scores = {}
    if not items or not page_texts:
        return scores
    page_tokens = [_tokenize_for_match(t) for t in page_texts]
    for idx, item in enumerate(items):
        stem = (item.get("problem") or item.get("front") or "")
        tokens = _tokenize_for_match(stem)
        if not tokens:
            continue
        best_page = None
        best_score = 0.0
        for p_idx, pt in enumerate(page_tokens):
            inter = tokens & pt
            score = len(inter) / max(1, len(tokens))
            if score > best_score:
                best_score = score
                best_page = p_idx + 1
        if best_page:
            scores[idx] = {"page": best_page, "score": best_score}
            item["page"] = best_page
    return scores

def parse_qa_to_cloze(text):
    """ì •ë‹µ: íŒ¨í„´ì„ ì´ìš©í•´ Q/Aë¥¼ Cloze í˜•íƒœë¡œ ë³€í™˜"""
    results = []
    lines = [l.strip() for l in text.splitlines()]
    buffer_lines = []
    last_item = None
    for line in lines:
        if not line:
            continue
        if re.match(r"^(í•´ì„¤|ì„¤ëª…)\s*[:ï¼š]", line):
            explanation = re.split(r"[:ï¼š]", line, 1)[1].strip()
            if last_item:
                last_item["explanation"] = explanation
            continue
        m = re.match(r"^(ì •ë‹µ|ë‹µ)\s*[:ï¼š]\s*(.+)$", line)
        if m:
            answer = m.group(2).strip()
            question = " ".join(buffer_lines).strip()
            if question and answer:
                last_item = {
                    "type": "cloze",
                    "front": question,
                    "answer": answer,
                    "explanation": ""
                }
                results.append(last_item)
            buffer_lines = []
        else:
            buffer_lines.append(line)
    return results

def apply_theme(theme_mode, bg_mode):
    color_scheme = "dark" if theme_mode == "Dark" else "light"
    if theme_mode == "Dark":
        base_bg = "#0f172a"
        surface = "#111827"
        surface_2 = "#0b1220"
        text = "#e5e7eb"
        subtext = "#94a3b8"
        accent = "#38bdf8"
        accent2 = "#22d3ee"
        border = "#1f2937"
    else:
        base_bg = "#f8fafc"
        surface = "#ffffff"
        surface_2 = "#f1f5f9"
        text = "#111827"
        subtext = "#4b5563"
        accent = "#0ea5a4"
        accent2 = "#14b8a6"
        border = "#e5e7eb"

    if bg_mode == "None":
        bg = "none"
    elif bg_mode == "Grid":
        bg = "radial-gradient(circle, rgba(148,163,184,0.2) 1px, transparent 1px)"
    else:
        if theme_mode == "Dark":
            bg = "radial-gradient(1200px 600px at 10% 0%, rgba(59,130,246,0.15), transparent 60%), linear-gradient(180deg, #0b1220 0%, #0f172a 100%)"
        else:
            bg = "radial-gradient(1200px 600px at 10% 0%, rgba(20,184,166,0.12), transparent 60%), linear-gradient(180deg, #f8fafc 0%, #eef2ff 100%)"

    st.markdown(
        f"""
        <style>
        :root {{
            --bg: {base_bg};
            --surface: {surface};
            --surface-2: {surface_2};
            --text: {text};
            --muted: {subtext};
            --accent: {accent};
            --accent-2: {accent2};
            --border: {border};
        }}
        html, body {{
            color: var(--text);
            color-scheme: {color_scheme};
        }}
        .stApp {{
            background-color: var(--bg);
            background-image: {bg};
            color: var(--text);
            color-scheme: {color_scheme};
        }}
        [data-testid="stAppViewContainer"] {{
            color: var(--text) !important;
        }}
        [data-testid="stAppViewContainer"] p,
        [data-testid="stAppViewContainer"] span,
        [data-testid="stAppViewContainer"] label,
        [data-testid="stAppViewContainer"] li,
        [data-testid="stAppViewContainer"] strong,
        [data-testid="stAppViewContainer"] h1,
        [data-testid="stAppViewContainer"] h2,
        [data-testid="stAppViewContainer"] h3,
        [data-testid="stAppViewContainer"] h4,
        [data-testid="stAppViewContainer"] h5,
        [data-testid="stAppViewContainer"] h6 {{
            color: var(--text) !important;
            opacity: 1 !important;
        }}
        [data-testid="stSidebar"] {{
            background: var(--surface);
            border-right: 1px solid var(--border);
        }}
        [data-testid="stSidebar"] * {{
            color: var(--text) !important;
            opacity: 1 !important;
        }}
        [data-testid="stHeader"] {{
            background: transparent;
        }}
        .stButton>button {{
            background: var(--accent);
            color: #ffffff !important;
            border: 1px solid var(--accent);
            border-radius: 10px;
        }}
        .stButton>button * {{
            color: #ffffff !important;
        }}
        .stButton>button:hover {{
            background: var(--accent-2);
            color: #ffffff !important;
        }}
        div[data-baseweb="input"] > div,
        div[data-baseweb="select"] > div,
        .stTextArea textarea {{
            background: var(--surface-2);
            border: 1px solid var(--border);
            color: var(--text) !important;
            -webkit-text-fill-color: var(--text) !important;
        }}
        input::placeholder,
        textarea::placeholder {{
            color: var(--muted) !important;
            opacity: 1 !important;
        }}
        .stTabs [data-baseweb="tab-list"] {{
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 10px;
        }}
        .stTabs [data-baseweb="tab"] {{
            background: transparent !important;
            border-radius: 8px;
            transition: color 0.22s ease, background-color 0.22s ease;
        }}
        .stTabs [data-baseweb="tab"]:hover {{
            background: var(--surface-2) !important;
        }}
        .stTabs [aria-selected="true"] {{
            background: transparent !important;
            color: var(--accent) !important;
            font-weight: 700;
        }}
        .stAlert, .stExpander, .stMetric {{
            background: var(--surface);
            border: 1px solid var(--border);
            color: var(--text);
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

def should_apply_custom_theme(theme_enabled, theme_mode):
    # Dark mode should be visible even when the custom-theme switch is off.
    return bool(theme_enabled) or str(theme_mode) == "Dark"

def apply_mobile_exam_styles():
    st.markdown(
        """
        <style>
        [data-testid="stRadio"] [role="radiogroup"] > label {
            padding: 0.55rem 0.6rem;
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 0.35rem;
            background: var(--surface);
        }
        [data-testid="stSelectbox"] label p,
        [data-testid="stRadio"] label p,
        [data-testid="stTextInput"] label p {
            font-size: 1rem !important;
        }
        .stButton > button {
            min-height: 44px;
            font-size: 1rem;
        }
        input[type="text"] {
            font-size: 16px !important;
        }
        .mobile-exam-caption {
            font-size: 0.95rem;
            color: var(--muted);
            margin-bottom: 0.3rem;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

def render_auth_landing_page():
    st.markdown(
        """
        <style>
        .auth-shell {
            max-width: 560px;
            margin: 1.5rem auto 0.5rem auto;
        }
        .auth-brand {
            text-align: center;
            font-size: 2rem;
            font-weight: 700;
            color: var(--text);
            letter-spacing: -0.02em;
            margin-bottom: 0.2rem;
        }
        .auth-subtitle {
            text-align: center;
            color: var(--muted);
            margin-bottom: 1rem;
        }
        .auth-card {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 16px;
            padding: 1rem 1rem 0.6rem 1rem;
            box-shadow: 0 10px 30px rgba(15, 23, 42, 0.08);
        }
        .auth-help {
            color: var(--muted);
            font-size: 0.9rem;
            text-align: center;
            margin-top: 0.5rem;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.markdown("<div class='auth-shell'>", unsafe_allow_html=True)
    st.markdown("<div class='auth-brand'>Axioma Qbank</div>", unsafe_allow_html=True)
    st.markdown("<div class='auth-subtitle'>ì´ë©”ì¼ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ê±°ë‚˜ ìƒˆ ê³„ì •ì„ ë§Œë“œì„¸ìš”.</div>", unsafe_allow_html=True)
    st.markdown("<div class='auth-card'>", unsafe_allow_html=True)

    if is_supabase_required() or is_supabase_enabled():
        tab_login, tab_signup = st.tabs(["Log in", "Create account"])
        with tab_login:
            with st.form("auth_login_form_main", clear_on_submit=False):
                login_email = st.text_input("EMAIL ADDRESS", key="auth_login_email_main")
                login_password = st.text_input("PASSWORD", type="password", key="auth_login_password_main")
                login_submit = st.form_submit_button("Log in", use_container_width=True)
            if login_submit:
                if not is_valid_email(login_email):
                    st.error("ì´ë©”ì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                else:
                    ok, result = authenticate_user_account(login_email, login_password)
                    if ok:
                        reset_runtime_state_for_auth_change()
                        st.session_state.auth_user_id = result
                        st.rerun()
                    else:
                        st.error(result)
        with tab_signup:
            with st.form("auth_signup_form_main", clear_on_submit=True):
                signup_email = st.text_input("EMAIL ADDRESS", key="auth_signup_email_main")
                signup_password = st.text_input("PASSWORD (6ì ì´ìƒ)", type="password", key="auth_signup_password_main")
                signup_password_confirm = st.text_input("CONFIRM PASSWORD", type="password", key="auth_signup_password_confirm_main")
                signup_submit = st.form_submit_button("Create account", use_container_width=True)
            if signup_submit:
                if not is_valid_email(signup_email):
                    st.error("ì´ë©”ì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                elif signup_password != signup_password_confirm:
                    st.error("ë¹„ë°€ë²ˆí˜¸ í™•ì¸ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                else:
                    ok, message = register_user_account(signup_email, signup_password)
                    if ok:
                        st.success(message)
                    else:
                        st.error(message)
        st.markdown("<div class='auth-help'>Supabase Auth ëª¨ë“œ: ì´ë©”ì¼/ë¹„ë°€ë²ˆí˜¸ ë¡œê·¸ì¸</div>", unsafe_allow_html=True)
    else:
        tab_login, tab_signup = st.tabs(["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"])
        with tab_login:
            with st.form("auth_login_form_main_local", clear_on_submit=False):
                login_user_id = st.text_input("ì•„ì´ë””", key="auth_login_user_id_main")
                login_password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="auth_login_password_main_local")
                login_submit = st.form_submit_button("ë¡œê·¸ì¸", use_container_width=True)
            if login_submit:
                ok, result = authenticate_user_account(login_user_id, login_password)
                if ok:
                    reset_runtime_state_for_auth_change()
                    st.session_state.auth_user_id = result
                    st.rerun()
                else:
                    st.error(result)
        with tab_signup:
            with st.form("auth_signup_form_main_local", clear_on_submit=True):
                signup_user_id = st.text_input("ìƒˆ ì•„ì´ë””", key="auth_signup_user_id_main")
                signup_password = st.text_input("ìƒˆ ë¹„ë°€ë²ˆí˜¸ (6ì ì´ìƒ)", type="password", key="auth_signup_password_main_local")
                signup_submit = st.form_submit_button("íšŒì›ê°€ì…", use_container_width=True)
            if signup_submit:
                ok, message = register_user_account(signup_user_id, signup_password)
                if ok:
                    st.success(message)
                else:
                    st.error(message)
        st.markdown("<div class='auth-help'>ë¡œì»¬ ê³„ì • ëª¨ë“œ</div>", unsafe_allow_html=True)

    st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)

def show_action_notice():
    msg = st.session_state.get("last_action_notice", "")
    if msg:
        st.success(msg)
        st.session_state.last_action_notice = ""

def render_copyright_ack(scope_key: str):
    st.info("ì—…ë¡œë“œ ìë£ŒëŠ” ê¶Œë¦¬ë¥¼ ë³´ìœ í•˜ê±°ë‚˜ ì‚¬ìš© í—ˆë½ì„ ë°›ì€ ìë£Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”. ì›ë¬¸ íŒŒì¼ì€ ì˜êµ¬ ì €ì¥í•˜ì§€ ì•Šê³  ì„¸ì…˜ ì²˜ë¦¬ í›„ íê¸°ë©ë‹ˆë‹¤.")
    ack_rights = st.checkbox(
        "ì—…ë¡œë“œ ìë£Œì— ëŒ€í•œ ì´ìš© ê¶Œë¦¬ë¥¼ ë³´ìœ /í—ˆë½ë°›ì•˜ìŒì„ í™•ì¸í•©ë‹ˆë‹¤.",
        key=f"copyright_ack_rights_{scope_key}",
    )
    ack_no_redistribute = st.checkbox(
        "íƒ€ì¸ì˜ ì €ì‘ë¬¼ì„ ë¬´ë‹¨ ì¬ë°°í¬í•˜ì§€ ì•Šê² ìŠµë‹ˆë‹¤.",
        key=f"copyright_ack_no_redistribute_{scope_key}",
    )
    return bool(ack_rights and ack_no_redistribute)

def render_generation_recovery_panel():
    if not st.session_state.get("generation_failure"):
        return
    with st.container():
        st.markdown("### âš ï¸ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")
        st.error(st.session_state.generation_failure)
        st.caption("ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ë°”ë¡œ ë³µêµ¬/ì´ˆê¸°í™”ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        colr1, colr2 = st.columns(2)
        with colr1:
            if st.button("ğŸ” ë™ì¼ ì¡°ê±´ ì¬ì‹¤í–‰", use_container_width=True, key="failure_retry_btn"):
                st.session_state.generation_failure = ""
                st.rerun()
        with colr2:
            if st.button("ğŸ§¹ ì•Œë¦¼ ì§€ìš°ê¸°", use_container_width=True, key="failure_clear_btn"):
                st.session_state.generation_failure = ""

def compute_activity_heatmap(questions, days=365, now=None):
    check_time = now or datetime.now(timezone.utc)
    start = (check_time - timedelta(days=days - 1)).date()
    buckets = {}
    for i in range(days):
        d = start + timedelta(days=i)
        buckets[d.isoformat()] = {"count": 0, "correct": 0, "total": 0}
    for q in questions:
        stats = q.get("stats") or {}
        hist = stats.get("history") or []
        for entry in hist:
            if not isinstance(entry, dict):
                continue
            dt = parse_iso_datetime(entry.get("time"))
            if not dt:
                continue
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            dkey = dt.date().isoformat()
            if dkey in buckets:
                buckets[dkey]["count"] += 1
                buckets[dkey]["total"] += 1
                if entry.get("correct") is True:
                    buckets[dkey]["correct"] += 1
    rows = []
    for dkey, val in buckets.items():
        d = datetime.fromisoformat(dkey).date()
        week_index = (d - start).days // 7
        rows.append({
            "date": d,
            "dow": d.weekday(),
            "week_index": week_index,
            "count": val["count"],
            "accuracy": (val["correct"] / val["total"] * 100) if val["total"] > 0 else 0
        })
    return rows

def fsrs_due(item, now=None):
    if not FSRS_AVAILABLE:
        return True
    try:
        fsrs = item.get("fsrs") or {}
        card_data = fsrs.get("card")
        if not card_data:
            return True
        card = Card.from_json(card_data)
        check_time = now or datetime.now(timezone.utc)
        return card.due <= check_time
    except Exception:
        return True

def simple_srs_due(item, now=None):
    check_time = now or datetime.now(timezone.utc)
    srs = item.get("srs") or {}
    due = parse_iso_datetime(srs.get("due"))
    return due is None or due <= check_time

def srs_due(item, now=None):
    if FSRS_AVAILABLE:
        return fsrs_due(item, now=now)
    return simple_srs_due(item, now=now)

def apply_simple_srs_rating(q_id, rating_label):
    bank = load_questions()
    now = datetime.now(timezone.utc)
    # base intervals in days
    base = {"Again": 1, "Hard": 2, "Good": 4, "Easy": 7}
    for key in ("text", "cloze"):
        for item in bank.get(key, []):
            if item.get("id") == q_id:
                srs = item.get("srs") or {}
                interval = int(srs.get("interval", 1))
                factor = {"Again": 0.5, "Hard": 1.2, "Good": 2.0, "Easy": 3.0}.get(rating_label, 2.0)
                new_interval = max(1, int(interval * factor))
                # if first time, use base
                if not srs:
                    new_interval = base.get(rating_label, 4)
                due = now + timedelta(days=new_interval)
                srs.update({
                    "interval": new_interval,
                    "due": due.isoformat(),
                    "last_rating": rating_label,
                    "last_review": now.isoformat(),
                })
                item["srs"] = srs
                save_questions(bank)
                return srs
    return None

def apply_srs_rating(q_id, rating):
    if FSRS_AVAILABLE:
        return apply_fsrs_rating(q_id, rating)
    # rating can be string label
    label = rating if isinstance(rating, str) else str(rating)
    return apply_simple_srs_rating(q_id, label)

def get_fsrs_queue(questions, now=None, limit=50):
    if not FSRS_AVAILABLE:
        return []
    check_time = now or datetime.now(timezone.utc)
    due_items = []
    for q in questions:
        fsrs = q.get("fsrs") or {}
        card_data = fsrs.get("card")
        if not card_data:
            due_items.append((q, check_time))
            continue
        try:
            card = Card.from_json(card_data)
            due_time = card.due
        except Exception:
            due_time = check_time
        if due_time <= check_time:
            due_items.append((q, due_time))
    due_items.sort(key=lambda x: x[1])
    return due_items[:limit]

def get_fsrs_stats(questions, now=None):
    if not FSRS_AVAILABLE:
        return None
    check_time = now or datetime.now(timezone.utc)
    due = 0
    overdue = 0
    future = 0
    new = 0
    for q in questions:
        fsrs = q.get("fsrs") or {}
        card_data = fsrs.get("card")
        if not card_data:
            new += 1
            due += 1
            continue
        try:
            card = Card.from_json(card_data)
            if card.due <= check_time:
                due += 1
                if card.due < check_time:
                    overdue += 1
            else:
                future += 1
        except Exception:
            due += 1
    return {
        "due": due,
        "overdue": overdue,
        "future": future,
        "new": new,
    }

def apply_fsrs_rating(q_id, rating):
    if not FSRS_AVAILABLE:
        return None
    bank = load_questions()
    now = datetime.now(timezone.utc)
    for key in ("text", "cloze"):
        for item in bank.get(key, []):
            if item.get("id") == q_id:
                card_data = (item.get("fsrs") or {}).get("card")
                if card_data:
                    try:
                        card = Card.from_json(card_data)
                    except Exception:
                        card = Card()
                else:
                    card = Card()
                scheduler = get_fsrs_scheduler() or Scheduler()
                card, log = scheduler.review_card(card, rating, now)
                fsrs = item.get("fsrs") or {}
                fsrs["card"] = card.to_json()
                fsrs["last_review"] = now.isoformat()
                fsrs["last_rating"] = rating.name if hasattr(rating, "name") else str(rating)
                fsrs["due"] = card.due.isoformat()
                logs = fsrs.get("logs", [])
                try:
                    logs.append(log.to_json())
                except Exception:
                    pass
                fsrs["logs"] = logs[-50:]
                item["fsrs"] = fsrs
                save_questions(bank)
                return fsrs
    return None

# ============================================================================
# í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
# ============================================================================
@st.cache_resource(show_spinner=False)
def get_easyocr_reader(langs):
    try:
        import easyocr
    except Exception:
        return None
    return easyocr.Reader(list(langs), gpu=False)

def available_ocr_engines():
    engines = []
    if importlib.util.find_spec("easyocr") is not None:
        engines.append("easyocr")
    return engines

def ocr_page_image_bytes(image_bytes, engine="easyocr", langs=("ko", "en")):
    if engine != "easyocr":
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” OCR ì—”ì§„: {engine}")
    reader = get_easyocr_reader(tuple(langs))
    if reader is None:
        raise ValueError("easyocr ë¯¸ì„¤ì¹˜")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp:
        tmp.write(image_bytes)
        tmp_path = tmp.name
    try:
        results = reader.readtext(tmp_path, detail=1, paragraph=False)
    finally:
        try:
            os.unlink(tmp_path)
        except Exception:
            pass
    if not results:
        return ""
    def bbox_key(item):
        bbox = item[0] if isinstance(item, (list, tuple)) and item else None
        if not bbox:
            return (0, 0)
        ys = [p[1] for p in bbox]
        xs = [p[0] for p in bbox]
        return (min(ys), min(xs))
    results = sorted(results, key=bbox_key)
    lines = [r[1].strip() for r in results if len(r) > 1 and str(r[1]).strip()]
    return "\n".join(lines)

def ocr_pdf_bytes(pdf_bytes, engine="easyocr", langs=("ko", "en"), max_pages=0, zoom=2.0):
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    texts = []
    total_pages = doc.page_count
    limit = total_pages if max_pages in (0, None) else min(total_pages, max_pages)
    for i in range(limit):
        page = doc.load_page(i)
        pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom), alpha=False)
        image_bytes = pix.tobytes("png")
        page_text = ocr_page_image_bytes(image_bytes, engine=engine, langs=langs)
        if page_text.strip():
            texts.append(f"=== í˜ì´ì§€ {i + 1} ===")
            texts.append(page_text)
            texts.append("")
    doc.close()
    return "\n".join(texts).strip()

def _ocr_pdf_page_with_ai(page_image_bytes, ai_model, api_key=None, openai_api_key=None):
    prompt = (
        "ì´ í˜ì´ì§€ì— ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë¥¼ ê°€ëŠ¥í•œ í•œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì„œ JSONì´ë‚˜ í•´ì„¤ ì—†ì´ \n"
        "ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¤„ë°”ê¿ˆ ìœ ì§€ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.\n"
        "í‘œ/ë¬¸í•­ ë²ˆí˜¸/ì„ ì§€ ë“±ì€ ëª¨ë‘ ì½ì„ ìˆ˜ ìˆëŠ” ê·¸ëŒ€ë¡œ ë³´ì¡´í•˜ì„¸ìš”."
    )
    try:
        if ai_model == "ğŸ”µ Google Gemini":
            if not api_key:
                return ""
            genai.configure(api_key=api_key)
            requested_model = get_gemini_model_id()
            model_candidates = [requested_model]
            if requested_model != "gemini-2.0-flash":
                model_candidates.append("gemini-2.0-flash")

            # google-generativeai ë²„ì „ë³„ í—ˆìš© ì…ë ¥ í¬ë§·ì´ ë‹¬ë¼ì„œ ìˆœì°¨ ì‹œë„
            img_pil = None
            try:
                img_pil = Image.open(io.BytesIO(page_image_bytes))
            except Exception:
                img_pil = None

            payloads = []
            if img_pil is not None:
                payloads.append([prompt, img_pil])
            payloads.append([prompt, {"mime_type": "image/png", "data": page_image_bytes}])
            payloads.append([prompt, page_image_bytes])

            for model_name in model_candidates:
                try:
                    model = genai.GenerativeModel(model_name)
                    for payload in payloads:
                        try:
                            response = model.generate_content(payload)
                            text = (getattr(response, "text", "") or "").strip()
                            if text:
                                return text
                        except Exception:
                            continue
                except Exception:
                    continue
            return ""
        if not openai_api_key:
            return ""
        client = OpenAI(api_key=openai_api_key)
        image_url = data_uri_from_bytes(page_image_bytes, ext="png")
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": image_url}},
                    ],
                }
            ],
            temperature=0,
        )
        return (response.choices[0].message.content or "").strip()
    except Exception:
        return ""


def ocr_pdf_bytes_with_ai(pdf_bytes, ai_model, api_key=None, openai_api_key=None, max_pages=0, zoom=2.0):
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    texts = []
    total_pages = doc.page_count
    limit = total_pages if max_pages in (0, None) else min(total_pages, max_pages)
    for i in range(limit):
        page = doc.load_page(i)
        pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom), alpha=False)
        image_bytes = pix.tobytes("png")
        page_text = _ocr_pdf_page_with_ai(image_bytes, ai_model, api_key=api_key, openai_api_key=openai_api_key)
        if page_text.strip():
            texts.append(f"=== í˜ì´ì§€ {i + 1} ===")
            texts.append(page_text)
            texts.append("")
    doc.close()
    return "\n".join(texts).strip()

def data_uri_from_bytes(data, ext):
    ext = ext.lower().replace(".", "")
    if ext in ("jpg", "jpeg"):
        mime = "image/jpeg"
    elif ext == "png":
        mime = "image/png"
    elif ext == "bmp":
        mime = "image/bmp"
    elif ext == "gif":
        mime = "image/gif"
    else:
        mime = "application/octet-stream"
    b64 = base64.b64encode(data).decode("utf-8")
    return f"data:{mime};base64,{b64}"

def data_uri_to_bytes(uri):
    if not uri:
        return b""
    m = re.match(r"^data:.*?;base64,(.*)$", uri)
    if not m:
        return b""
    try:
        return base64.b64decode(m.group(1))
    except Exception:
        return b""

def extract_images_from_pdf_bytes(pdf_bytes, max_images=80, min_kb=20):
    images = []
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        seen = set()
        for page_idx in range(doc.page_count):
            page = doc.load_page(page_idx)
            for img in page.get_images(full=True):
                xref = img[0]
                base = doc.extract_image(xref)
                if not base or "image" not in base:
                    continue
                data = base["image"]
                if len(data) < min_kb * 1024:
                    continue
                rect = None
                try:
                    rect = page.get_image_bbox(xref)
                except Exception:
                    rect = None
                h = hashlib.sha1(data).hexdigest()
                if h in seen:
                    continue
                seen.add(h)
                ext = base.get("ext", "png")
                images.append({
                    "data_uri": data_uri_from_bytes(data, ext),
                    "ext": ext,
                    "page": page_idx + 1,
                    "y": rect.y0 if rect else None,
                    "y1": rect.y1 if rect else None,
                })
                if len(images) >= max_images:
                    break
            if len(images) >= max_images:
                break
        doc.close()
    except Exception:
        return []
    return images

def extract_pdf_question_anchors(pdf_bytes):
    anchors = {}
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        q_pattern = re.compile(r"^\s*(?:ë¬¸í•­\s*)?(\d{1,3})\s*[).]")
        for page_idx in range(doc.page_count):
            page = doc.load_page(page_idx)
            page_anchors = []
            data = page.get_text("dict")
            for block in data.get("blocks", []):
                for line in block.get("lines", []):
                    line_text = "".join(span.get("text", "") for span in line.get("spans", []))
                    if not line_text:
                        continue
                    m = q_pattern.match(line_text.strip())
                    if m:
                        qnum = int(m.group(1))
                        y = line.get("bbox", [0, 0, 0, 0])[1]
                        page_anchors.append({"qnum": qnum, "y": y})
            if page_anchors:
                # de-duplicate by qnum, keep first occurrence
                seen = set()
                uniq = []
                for a in sorted(page_anchors, key=lambda x: x["y"]):
                    if a["qnum"] in seen:
                        continue
                    seen.add(a["qnum"])
                    uniq.append(a)
                anchors[page_idx + 1] = uniq
        doc.close()
    except Exception:
        return {}
    return anchors

def extract_images_from_hwp_bytes(hwp_bytes, max_images=80, min_kb=10):
    tmp_path = None
    odt_path = None
    images = []
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".hwp") as tmp:
            tmp.write(hwp_bytes)
            tmp_path = tmp.name
        with tempfile.NamedTemporaryFile(delete=False, suffix=".odt") as tmp_odt:
            odt_path = tmp_odt.name

        if shutil.which("hwp5odt"):
            result = subprocess.run(["hwp5odt", "--output", odt_path, tmp_path], capture_output=True, text=True)
            if result.returncode != 0:
                return []
        else:
            return []

        with zipfile.ZipFile(odt_path) as zf:
            for name in zf.namelist():
                if not name.startswith("bindata/"):
                    continue
                data = zf.read(name)
                if len(data) < min_kb * 1024:
                    continue
                ext = os.path.splitext(name)[1].lstrip(".") or "png"
                images.append({
                    "data_uri": data_uri_from_bytes(data, ext),
                    "ext": ext,
                    "page": None,
                })
                if len(images) >= max_images:
                    break
    except Exception:
        return []
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except Exception:
                pass
        if odt_path and os.path.exists(odt_path):
            try:
                os.unlink(odt_path)
            except Exception:
                pass
    return images

def _tokenize_for_match(text):
    if not text:
        return set()
    tokens = re.findall(r"[A-Za-zê°€-í£0-9]{2,}", text.lower())
    return set(tokens)

def clean_parsed_items(items, min_stem_len=15):
    cleaned = []
    for item in items or []:
        if not isinstance(item, dict):
            continue
        typ = item.get("type")
        if typ not in ("mcq", "cloze"):
            continue
        stem = (item.get("problem") if typ == "mcq" else item.get("front")) or ""
        stem = stem.strip()
        if not stem:
            continue
        if re.match(r"^(ì •ë‹µ|ë‹µ|í•´ì„¤|ì„¤ëª…)\b", stem):
            continue
        if len(stem) < min_stem_len:
            if typ == "mcq" and len(item.get("options") or []) >= 3:
                pass
            else:
                continue
        if typ == "mcq":
            if len(item.get("options") or []) < 3:
                continue
        if typ == "cloze" and not str(item.get("answer", "")).strip():
            continue
        cleaned.append(item)
    return cleaned

def ocr_images_for_matching(images, engine="easyocr", langs=("ko", "en"), max_images=30, min_len=3):
    if not images:
        return images
    count = 0
    for img in images:
        if count >= max_images:
            break
        if img.get("ocr_text"):
            continue
        data = data_uri_to_bytes(img.get("data_uri", ""))
        if not data:
            continue
        try:
            text = ocr_page_image_bytes(data, engine=engine, langs=langs)
        except Exception:
            text = ""
        if text and len(text.strip()) >= min_len:
            img["ocr_text"] = text
        else:
            img["ocr_text"] = ""
        count += 1
    return images

def ai_match_images_to_items(items, images, ai_model, api_key=None, openai_api_key=None, max_images=10):
    if not items or not images or max_images <= 0:
        return items
    # group items by page
    page_map = {}
    for idx, item in enumerate(items):
        page = item.get("page")
        page_map.setdefault(page, []).append((idx, item))

    processed = 0
    for img in images:
        if processed >= max_images:
            break
        if img.get("matched"):
            continue
        page = img.get("page")
        candidates = page_map.get(page) or []
        if not candidates:
            continue
        # build candidate list
        lines = []
        for idx, item in candidates:
            stem = item.get("problem") or item.get("front") or ""
            stem = stem.replace("\n", " ").strip()
            if len(stem) > 160:
                stem = stem[:160] + "..."
            lines.append(f"{idx}: {stem}")
        prompt = (
            "You are matching a medical exam image to the most relevant question stem. "
            "Choose the single best question index from the list below. "
            "If none match, return -1. Return ONLY the index number.\n\n"
            "Questions:\n" + "\n".join(lines)
        )
        matched_idx = None
        try:
            if ai_model == "ğŸ”µ Google Gemini":
                if not api_key:
                    continue
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(get_gemini_model_id())
                img_bytes = data_uri_to_bytes(img.get("data_uri", ""))
                response = model.generate_content([prompt, img_bytes])
                text = (response.text or "").strip()
            else:
                if not openai_api_key:
                    continue
                client = OpenAI(api_key=openai_api_key)
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "user", "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": img.get("data_uri", "")}},
                        ]}
                    ],
                    temperature=0
                )
                text = (response.choices[0].message.content or "").strip()
            m = re.search(r"-?\\d+", text)
            if m:
                matched_idx = int(m.group(0))
        except Exception:
            matched_idx = None

        if matched_idx is None or matched_idx < 0 or matched_idx >= len(items):
            processed += 1
            continue
        if items[matched_idx].get("images"):
            # avoid overwriting existing images
            processed += 1
            continue
        items[matched_idx].setdefault("images", [])
        items[matched_idx]["images"].append(img.get("data_uri"))
        img["matched"] = True
        processed += 1

    return items

def generate_explanations_ai(items, ai_model, api_key=None, openai_api_key=None, max_items=20):
    if not items or max_items <= 0:
        return items
    count = 0
    for item in items:
        if item.get("explanation"):
            continue
        if count >= max_items:
            break
        stem = item.get("problem") or item.get("front") or ""
        opts = item.get("options") or []
        answer = item.get("answer")
        if item.get("type") == "mcq":
            answer_text = None
            if isinstance(answer, int) and 1 <= answer <= len(opts):
                answer_text = opts[answer - 1]
            prompt = (
                "ë‹¤ìŒ ê°ê´€ì‹ ë¬¸ì œì˜ í•´ì„¤ì„ 2~4ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. "
                "ì •ë‹µ ê·¼ê±°ì™€ í•µì‹¬ í¬ì¸íŠ¸ë§Œ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.\n\n"
                f"ë¬¸í•­: {stem}\n"
                f"ì„ ì§€: {opts}\n"
                f"ì •ë‹µ: {answer}"
            )
        else:
            prompt = (
                "ë‹¤ìŒ ì£¼ê´€ì‹/ë¹ˆì¹¸ ë¬¸ì œì˜ í•´ì„¤ì„ 2~4ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. "
                "ì •ë‹µ ê·¼ê±°ì™€ í•µì‹¬ í¬ì¸íŠ¸ë§Œ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.\n\n"
                f"ë¬¸í•­: {stem}\n"
                f"ì •ë‹µ: {answer}"
            )
        try:
            if ai_model == "ğŸ”µ Google Gemini":
                if not api_key:
                    continue
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(get_gemini_model_id())
                generation_config = {
                    "temperature": LLM_TEMPERATURE,
                    "top_p": 1.0,
                }
                response = model.generate_content(prompt, generation_config=generation_config)
                text = (response.text or "").strip()
                append_audit_log("gen.explanation.batch", {
                    "model": get_gemini_model_id(),
                    "temperature": LLM_TEMPERATURE,
                    "seed": None,
                    "prompt_hash": _hash_text(prompt),
                    "prompt_text": prompt,
                    "output_text": text,
                    "usage_tokens": _gemini_usage_tokens(response),
                    "prompt_version": PROMPT_VERSION,
                })
            else:
                if not openai_api_key:
                    continue
                client = OpenAI(api_key=openai_api_key)
                openai_params = {
                    "model": "gpt-4o-mini",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": LLM_TEMPERATURE,
                    "max_tokens": 300,
                }
                if LLM_SEED is not None:
                    openai_params["seed"] = LLM_SEED
                response = client.chat.completions.create(**openai_params)
                text = (response.choices[0].message.content or "").strip()
                append_audit_log("gen.explanation.batch", {
                    "model": "gpt-4o-mini",
                    "temperature": LLM_TEMPERATURE,
                    "seed": LLM_SEED,
                    "prompt_hash": _hash_text(prompt),
                    "prompt_text": prompt,
                    "output_text": text,
                    "usage_tokens": _openai_usage_tokens(response),
                    "prompt_version": PROMPT_VERSION,
                })
            if text:
                item["explanation"] = text
                count += 1
        except Exception:
            continue
    return items

def generate_single_explanation_ai(item, ai_model, api_key=None, openai_api_key=None, return_error=False):
    if not item:
        return ("", "ë¹ˆ ë¬¸í•­") if return_error else ""
    stem = item.get("problem") or item.get("front") or item.get("raw") or ""
    opts = item.get("options") or item.get("choices") or []
    answer = item.get("answer")
    if answer is None:
        answer = item.get("correct")
    if item.get("type") == "mcq":
        prompt = (
            "ë‹¤ìŒ ê°ê´€ì‹ ë¬¸ì œì˜ í•´ì„¤ì„ 2~4ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. "
            "ì •ë‹µ ê·¼ê±°ì™€ í•µì‹¬ í¬ì¸íŠ¸ë§Œ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.\n\n"
            f"ë¬¸í•­: {stem}\n"
            f"ì„ ì§€: {opts}\n"
            f"ì •ë‹µ: {answer}"
        )
    else:
        prompt = (
            "ë‹¤ìŒ ì£¼ê´€ì‹/ë¹ˆì¹¸ ë¬¸ì œì˜ í•´ì„¤ì„ 2~4ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. "
            "ì •ë‹µ ê·¼ê±°ì™€ í•µì‹¬ í¬ì¸íŠ¸ë§Œ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.\n\n"
            f"ë¬¸í•­: {stem}\n"
            f"ì •ë‹µ: {answer}"
        )
    try:
        if ai_model == "ğŸ”µ Google Gemini":
            if not api_key:
                return ("", "Gemini API í‚¤ ì—†ìŒ") if return_error else ""
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(get_gemini_model_id())
            generation_config = {
                "temperature": LLM_TEMPERATURE,
                "top_p": 1.0,
            }
            response = model.generate_content(prompt, generation_config=generation_config)
            text = (response.text or "").strip()
            append_audit_log("gen.explanation.single", {
                "model": get_gemini_model_id(),
                "temperature": LLM_TEMPERATURE,
                "seed": None,
                "prompt_hash": _hash_text(prompt),
                "prompt_text": prompt,
                "output_text": text,
                "usage_tokens": _gemini_usage_tokens(response),
                "prompt_version": PROMPT_VERSION,
            })
            return (text, "") if return_error else text
        else:
            if not openai_api_key:
                return ("", "OpenAI API í‚¤ ì—†ìŒ") if return_error else ""
            client = OpenAI(api_key=openai_api_key)
            openai_params = {
                "model": "gpt-4o-mini",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": LLM_TEMPERATURE,
                "max_tokens": 300,
            }
            if LLM_SEED is not None:
                openai_params["seed"] = LLM_SEED
            response = client.chat.completions.create(**openai_params)
            text = (response.choices[0].message.content or "").strip()
            append_audit_log("gen.explanation.single", {
                "model": "gpt-4o-mini",
                "temperature": LLM_TEMPERATURE,
                "seed": LLM_SEED,
                "prompt_hash": _hash_text(prompt),
                "prompt_text": prompt,
                "output_text": text,
                "usage_tokens": _openai_usage_tokens(response),
                "prompt_version": PROMPT_VERSION,
            })
            return (text, "") if return_error else text
    except Exception as e:
        return ("", str(e)) if return_error else ""

def grade_essay_answer_ai(item, user_answer, ai_model, api_key=None, openai_api_key=None):
    question_text = (item.get("front") or item.get("problem") or "").strip()
    reference_answer = (item.get("answer") or "").strip()
    explanation = (item.get("explanation") or "").strip()
    if not question_text or not user_answer:
        return None, "ì§ˆë¬¸ ë˜ëŠ” ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
    prompt = (
        "ë‹¤ìŒ ì„œìˆ í˜• ë‹µì•ˆì„ ì±„ì í•˜ì„¸ìš”. ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”.\n"
        "JSON í˜•ì‹: {\"score\": 0-100, \"is_correct\": true/false, \"feedback\": \"...\", \"key_points\": [\"...\"]}\n"
        f"[ë¬¸í•­]\n{question_text}\n\n"
        f"[ëª¨ë²”ë‹µì•ˆ]\n{reference_answer}\n\n"
        f"[í•´ì„¤]\n{explanation}\n\n"
        f"[í•™ìƒë‹µì•ˆ]\n{user_answer}"
    )
    try:
        if ai_model == "ğŸ”µ Google Gemini":
            if not api_key:
                return None, "Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(get_gemini_model_id())
            response = model.generate_content(
                prompt,
                generation_config={"temperature": LLM_TEMPERATURE, "top_p": 1.0}
            )
            raw = response.text or ""
            usage_tokens = _gemini_usage_tokens(response)
            model_name = get_gemini_model_id()
        else:
            if not openai_api_key:
                return None, "OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            client = OpenAI(api_key=openai_api_key)
            params = {
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": "ì˜í•™êµìœ¡ ì±„ì ì ì—­í• ë¡œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt},
                ],
                "temperature": LLM_TEMPERATURE,
                "max_tokens": 700,
            }
            if LLM_SEED is not None:
                params["seed"] = LLM_SEED
            response = client.chat.completions.create(**params)
            raw = (response.choices[0].message.content or "").strip()
            usage_tokens = _openai_usage_tokens(response)
            model_name = "gpt-4o-mini"
        parsed = _parse_json_from_text(raw)
        if not isinstance(parsed, dict):
            return None, "ì±„ì  ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"
        score = parsed.get("score", 0)
        try:
            score = int(float(score))
        except Exception:
            score = 0
        score = max(0, min(100, score))
        result = {
            "score": score,
            "is_correct": bool(parsed.get("is_correct", False)),
            "feedback": str(parsed.get("feedback", "")).strip(),
            "key_points": parsed.get("key_points", []) if isinstance(parsed.get("key_points", []), list) else [],
        }
        append_audit_log("grade.essay", {
            "model": model_name,
            "temperature": LLM_TEMPERATURE,
            "seed": LLM_SEED if ai_model != "ğŸ”µ Google Gemini" else None,
            "prompt_hash": _hash_text(prompt),
            "prompt_text": prompt,
            "output_text": raw,
            "usage_tokens": usage_tokens,
            "grader_version": GRADER_VERSION,
        })
        return result, ""
    except Exception as e:
        return None, str(e)

def update_question_explanation(q_id, explanation_text):
    if not q_id:
        return False
    bank = load_questions()
    for key in ("text", "cloze"):
        for item in bank.get(key, []):
            if item.get("id") == q_id:
                item["explanation"] = explanation_text
                save_questions(bank)
                return True
    return False

def _extract_json_candidates(raw):
    if not raw:
        return []
    raw = raw.strip()
    candidates = []
    fence = re.search(r"```(?:json)?\s*([\s\S]+?)\s*```", raw)
    if fence:
        candidates.append(fence.group(1).strip())
    candidates.append(raw)
    arr = re.search(r"\[\s*\{[\s\S]+?\}\s*\]", raw)
    if arr:
        candidates.append(arr.group(0))
    obj = re.search(r"\{[\s\S]+\}", raw)
    if obj:
        candidates.append(obj.group(0))
    return candidates

def _parse_json_from_text(raw):
    for cand in _extract_json_candidates(raw):
        try:
            data = json.loads(cand)
            return data
        except Exception:
            continue
    return None

def ai_parse_exam_layout(left_text, right_text, ai_model, api_key=None, openai_api_key=None, hint_text=""):
    if not left_text or len(left_text.strip()) < 20:
        return []
    prompt = (
        "ì•„ë˜ LEFT/RIGHT í…ìŠ¤íŠ¸ì—ì„œ ì‹œí—˜ ë¬¸í•­ì„ JSON ë°°ì—´ë¡œ ì¶”ì¶œí•˜ì„¸ìš”. ì˜¤ì§ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        "LEFTì—ëŠ” ë¬¸í•­/ì„ ì§€ê°€ ìˆê³ , RIGHTì—ëŠ” ì •ë‹µ/í•´ì„¤(ë˜ëŠ” ìš”ì•½)ì´ ìˆìŠµë‹ˆë‹¤.\n"
        "RIGHTëŠ” 'â–¶ â‘¤' ë˜ëŠ” 'ì •ë‹µ: â‘¤' ê°™ì€ í˜•ì‹ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì´ë¥¼ ì •ë‹µìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
        "ë¬¸í•­ ë²ˆí˜¸ê°€ ë³´ì´ë©´ qnumì— ë„£ê³ , ì—†ìœ¼ë©´ ìˆœì„œëŒ€ë¡œ ë§¤ì¹­í•˜ì„¸ìš”.\n"
        "í˜•ì‹:\n"
        "{\n"
        "  \"type\": \"mcq\" ë˜ëŠ” \"cloze\",\n"
        "  \"problem\": (mcqìš© ì§ˆë¬¸ ë³¸ë¬¸),\n"
        "  \"front\": (clozeìš© ì§ˆë¬¸ ë³¸ë¬¸),\n"
        "  \"options\": [\"ì„ ì§€1\", \"ì„ ì§€2\", ...] (mcqì¼ ë•Œë§Œ),\n"
        "  \"answer\": ì •ë‹µ (mcqëŠ” 1-5 ì •ìˆ˜, clozeëŠ” ë¬¸ìì—´),\n"
        "  \"explanation\": í•´ì„¤(ì—†ìœ¼ë©´ \"\"),\n"
        "  \"qnum\": ë¬¸í•­ ë²ˆí˜¸(ìˆìœ¼ë©´ ìˆ«ì)\n"
        "}\n"
        "[LEFT]\n"
    )
    if hint_text:
        prompt = f"[ë¬¸ì„œ êµ¬ì¡° íŒíŠ¸]\n{hint_text}\n\n" + prompt
    prompt += left_text[:20000] + "\n\n[RIGHT]\n" + (right_text[:20000] if right_text else "")
    try:
        if ai_model == "ğŸ”µ Google Gemini":
            if not api_key:
                return []
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(get_gemini_model_id())
            response = model.generate_content(prompt)
            raw = response.text or ""
        else:
            if not openai_api_key:
                return []
            client = OpenAI(api_key=openai_api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=4000
            )
            raw = response.choices[0].message.content or ""
        data = _parse_json_from_text(raw)
        if isinstance(data, dict):
            data = data.get("items") or data.get("questions") or data.get("data") or []
        if not isinstance(data, list):
            return []
        return clean_parsed_items(data)
    except Exception:
        return []

def ai_parse_exam_text(text, ai_model, api_key=None, openai_api_key=None, max_items=60, hint_text="", return_raw=False):
    if not text or len(text.strip()) < 20:
        return ([], "") if return_raw else []
    prompt = (
        "ì•„ë˜ í…ìŠ¤íŠ¸ì—ì„œ ì‹œí—˜ ë¬¸í•­ì„ JSON ë°°ì—´ë¡œ ì¶”ì¶œí•˜ì„¸ìš”. ì˜¤ì§ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        "ê° í•­ëª© í˜•ì‹:\n"
        "{\n"
        "  \"type\": \"mcq\" ë˜ëŠ” \"cloze\",\n"
        "  \"problem\": (mcqìš© ì§ˆë¬¸ ë³¸ë¬¸),\n"
        "  \"front\": (clozeìš© ì§ˆë¬¸ ë³¸ë¬¸),\n"
        "  \"options\": [\"ì„ ì§€1\", \"ì„ ì§€2\", ...] (mcqì¼ ë•Œë§Œ),\n"
        "  \"answer\": ì •ë‹µ (mcqëŠ” 1-5 ì •ìˆ˜, clozeëŠ” ë¬¸ìì—´),\n"
        "  \"explanation\": í•´ì„¤(ì—†ìœ¼ë©´ \"\"),\n"
        "  \"page\": í˜ì´ì§€ ë²ˆí˜¸(í…ìŠ¤íŠ¸ì— '=== í˜ì´ì§€ N ===' í‘œê¸°ê°€ ìˆìœ¼ë©´ í™œìš©),\n"
        "  \"qnum\": ë¬¸í•­ ë²ˆí˜¸(ìˆìœ¼ë©´ ìˆ«ì)\n"
        "}\n"
        f"ìµœëŒ€ {max_items}ê°œê¹Œì§€ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        "ë¬¸í•­ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì •í™•íˆ ë¶„ë¦¬í•˜ì„¸ìš”.\n\n"
        "[ì›ë¬¸]\n"
    )
    if hint_text:
        prompt = f"[ë¬¸ì„œ êµ¬ì¡° íŒíŠ¸]\n{hint_text}\n\n" + prompt
    try:
        if ai_model == "ğŸ”µ Google Gemini":
            if not api_key:
                return ([], "") if return_raw else []
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(get_gemini_model_id())
            response = model.generate_content(prompt + text[:30000])
            raw = response.text or ""
        else:
            if not openai_api_key:
                return ([], "") if return_raw else []
            client = OpenAI(api_key=openai_api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt + text[:30000]}],
                temperature=0.2,
                max_tokens=4000
            )
            raw = response.choices[0].message.content or ""

        data = _parse_json_from_text(raw)
        if data is None:
            return ([], raw) if return_raw else []
        if isinstance(data, dict):
            data = data.get("items") or data.get("questions") or data.get("data") or []
        if not isinstance(data, list):
            return ([], raw) if return_raw else []
        items = clean_parsed_items(data)
        return (items, raw) if return_raw else items
    except Exception:
        return ([], "") if return_raw else []

def ai_parse_exam_block(block_text, ai_model, api_key=None, openai_api_key=None, hint_text="", return_raw=False):
    if not block_text or len(block_text.strip()) < 10:
        return (None, "") if return_raw else None
    prompt = (
        "ì•„ë˜ í…ìŠ¤íŠ¸ì—ì„œ ë¬¸í•­ 1ê°œë¥¼ JSON ê°ì²´ë¡œ ì¶”ì¶œí•˜ì„¸ìš”. ì˜¤ì§ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        "í˜•ì‹:\n"
        "{\n"
        "  \"type\": \"mcq\" ë˜ëŠ” \"cloze\",\n"
        "  \"problem\": (mcqìš© ì§ˆë¬¸ ë³¸ë¬¸),\n"
        "  \"front\": (clozeìš© ì§ˆë¬¸ ë³¸ë¬¸),\n"
        "  \"options\": [\"ì„ ì§€1\", \"ì„ ì§€2\", ...] (mcqì¼ ë•Œë§Œ),\n"
        "  \"answer\": ì •ë‹µ (mcqëŠ” 1-5 ì •ìˆ˜, clozeëŠ” ë¬¸ìì—´),\n"
        "  \"explanation\": í•´ì„¤(ì—†ìœ¼ë©´ \"\")\n"
        "}\n"
    )
    if hint_text:
        prompt += f"\n[ë¬¸ì„œ êµ¬ì¡° íŒíŠ¸]\n{hint_text}\n"
    prompt += "\n[ì›ë¬¸]\n"
    try:
        if ai_model == "ğŸ”µ Google Gemini":
            if not api_key:
                return (None, "") if return_raw else None
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(get_gemini_model_id())
            response = model.generate_content(prompt + block_text[:15000])
            raw = response.text or ""
        else:
            if not openai_api_key:
                return (None, "") if return_raw else None
            client = OpenAI(api_key=openai_api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt + block_text[:15000]}],
                temperature=0.2,
                max_tokens=1200
            )
            raw = response.choices[0].message.content or ""
        data = _parse_json_from_text(raw)
        if not isinstance(data, dict):
            return (None, raw) if return_raw else None
        items = clean_parsed_items([data])
        item = items[0] if items else None
        return (item, raw) if return_raw else item
    except Exception:
        return (None, "") if return_raw else None

def should_attach_image(item):
    text = (item.get("problem") or item.get("front") or "")
    text = text.lower()
    keywords = [
        "x-ray", "xray", "ct", "mri", "us", "ultrasound", "sonography", "radiograph",
        "ì˜ìƒ", "ì˜ìƒì†Œê²¬", "ì˜ìƒ ì†Œê²¬", "ì‚¬ì§„", "ê·¸ë¦¼", "figure", "fig.", "ì˜ìƒì—ì„œ", "ì‚¬ì§„ì„ ë³´ê³ ", "ì˜ìƒí•™ì "
    ]
    return any(k in text for k in keywords)

def auto_attach_images_to_items(items, images, strategy="page", max_per_question=1, anchors=None, min_score=0.2, only_if_keyword=False):
    if not items or not images:
        return items
    if max_per_question < 1:
        return items

    if strategy == "sequential":
        img_idx = 0
        for item in items:
            if item.get("images"):
                continue
            attach = []
            for _ in range(max_per_question):
                if img_idx >= len(images):
                    break
                attach.append(images[img_idx]["data_uri"])
                img_idx += 1
            if attach:
                item["images"] = attach
        return items

    if strategy == "layout" and anchors:
        # build intervals per page: [qnum, start_y, end_y)
        intervals = {}
        for page, arr in anchors.items():
            if not arr:
                continue
            arr_sorted = sorted(arr, key=lambda x: x["y"])
            page_intervals = []
            for idx, a in enumerate(arr_sorted):
                start = a["y"]
                end = arr_sorted[idx + 1]["y"] if idx + 1 < len(arr_sorted) else float("inf")
                page_intervals.append({"qnum": a["qnum"], "start": start, "end": end})
            intervals[page] = page_intervals

        image_map = {}
        for img in images:
            page = img.get("page")
            y = img.get("y")
            if page not in intervals or y is None:
                continue
            for seg in intervals[page]:
                if seg["start"] <= y < seg["end"]:
                    key = (page, seg["qnum"])
                    image_map.setdefault(key, []).append(img["data_uri"])
                    break

        for item in items:
            if item.get("images"):
                continue
            if only_if_keyword and not should_attach_image(item):
                continue
            page = item.get("page")
            qnum = item.get("qnum")
            if page is None or qnum is None:
                continue
            key = (page, qnum)
            imgs = image_map.get(key) or []
            if imgs:
                item["images"] = imgs[:max_per_question]
        return items

    if strategy == "page":
        page_to_images = {}
        for img in images:
            page = img.get("page")
            page_to_images.setdefault(page, []).append(img["data_uri"])
        for item in items:
            if item.get("images"):
                continue
            if only_if_keyword and not should_attach_image(item):
                continue
            page = item.get("page")
            candidates = page_to_images.get(page) or []
            if candidates:
                item["images"] = candidates[:max_per_question]
        return items

    if strategy == "ocr":
        # build token sets per item
        item_tokens = []
        for item in items:
            text = " ".join([
                item.get("problem") or item.get("front") or "",
                " ".join(item.get("options", []) or []),
                item.get("explanation") or ""
            ])
            item_tokens.append(_tokenize_for_match(text))

        def item_key(i):
            return f"{items[i].get('page')}_{items[i].get('qnum')}_{i}"

        attached = {}
        for i, item in enumerate(items):
            attached[item_key(i)] = list(item.get("images", [])) if item.get("images") else []

        for img in images:
            ocr_text = img.get("ocr_text", "") or ""
            tokens_img = _tokenize_for_match(ocr_text)
            if not tokens_img:
                continue
            best_idx = None
            best_score = 0.0
            for i, tokens in enumerate(item_tokens):
                if not tokens:
                    continue
                if only_if_keyword and not should_attach_image(items[i]):
                    continue
                # prefer same page if available
                if img.get("page") and items[i].get("page") and img.get("page") != items[i].get("page"):
                    continue
                overlap = len(tokens_img & tokens) / max(1, len(tokens_img))
                if overlap > best_score:
                    best_score = overlap
                    best_idx = i
            if best_idx is None or best_score < min_score:
                continue
            key = item_key(best_idx)
            if img["data_uri"] in attached[key]:
                continue
            if len(attached[key]) >= max_per_question:
                continue
            attached[key].append(img["data_uri"])

        for i, item in enumerate(items):
            key = item_key(i)
            if attached.get(key):
                item["images"] = attached[key]
        return items

    return items

def extract_text_from_pdf(
    uploaded_file,
    enable_ocr=True,
    ocr_engine="auto",
    ocr_langs=("ko", "en"),
    ocr_max_pages=0,
    min_text_len=40,
    include_page_markers=False,
    ai_fallback=False,
    ai_model="",
    api_key=None,
    openai_api_key=None,
):
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        pdf_bytes = uploaded_file.read()
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        text = ""
        for i, page in enumerate(doc):
            page_text = page.get_text()
            if include_page_markers:
                text += f"=== í˜ì´ì§€ {i + 1} ===\n"
            text += page_text
            if include_page_markers:
                text += "\n"
        doc.close()
        if len(text.strip()) >= min_text_len:
            return text
        # OCR fallback (ìŠ¤ìº” PDF ë“±)
        if not (enable_ocr or ai_fallback):
            return text
        if ai_fallback and ai_model:
            ai_text = ocr_pdf_bytes_with_ai(
                pdf_bytes,
                ai_model=ai_model,
                api_key=api_key,
                openai_api_key=openai_api_key,
                max_pages=ocr_max_pages,
                zoom=2.0,
            )
            if ai_text.strip():
                return ai_text
        engines = available_ocr_engines()
        if not engines:
            return text
        try:
            engine = engines[0] if ocr_engine == "auto" else ocr_engine
            ocr_text = ocr_pdf_bytes(pdf_bytes, engine=engine, langs=ocr_langs, max_pages=ocr_max_pages)
            return ocr_text if ocr_text.strip() else text
        except Exception:
            return text
    except Exception as e:
        raise ValueError(f"PDF ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

def extract_text_from_docx(uploaded_file):
    """Word (.docx)ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        doc = Document(uploaded_file)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    text += cell.text + "\n"
        return text
    except Exception as e:
        raise ValueError(f"Word ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

def extract_text_from_pptx(uploaded_file):
    """PowerPoint (.pptx)ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        prs = Presentation(uploaded_file)
        text = ""
        for slide_num, slide in enumerate(prs.slides, 1):
            text += f"\n=== ìŠ¬ë¼ì´ë“œ {slide_num} ===\n"
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    text += shape.text + "\n"
        return text
    except Exception as e:
        raise ValueError(f"PowerPoint ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

def extract_text_from_hwp(uploaded_file):
    """HWP (.hwp)ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (hwp5txt í•„ìš”)"""
    tmp_path = None
    try:
        if hasattr(uploaded_file, "read"):
            data = uploaded_file.read()
        else:
            data = uploaded_file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".hwp") as tmp:
            tmp.write(data)
            tmp_path = tmp.name

        def is_table_placeholder_text(text):
            if not text or not text.strip():
                return True
            placeholder_count = text.count("<í‘œ>")
            if placeholder_count >= 3:
                cleaned = re.sub(r"<í‘œ>", "", text)
                cleaned = re.sub(r"\s+", "", cleaned)
                if len(cleaned) < 80:
                    return True
                if not re.search(r"[â‘ â‘¡â‘¢â‘£â‘¤]|\\bì •ë‹µ\\b|\\bë‹µ\\b", text):
                    return True
            return False

        def extract_text_from_odt_content(xml_bytes):
            try:
                root = ET.fromstring(xml_bytes)
            except Exception:
                return ""
            ns = {
                "office": "urn:oasis:names:tc:opendocument:xmlns:office:1.0",
                "text": "urn:oasis:names:tc:opendocument:xmlns:text:1.0",
                "table": "urn:oasis:names:tc:opendocument:xmlns:table:1.0",
                "draw": "urn:oasis:names:tc:opendocument:xmlns:drawing:1.0",
            }
            body = root.find("office:body/office:text", ns)
            if body is None:
                return ""

            def normalize_line(line):
                line = line.replace("\u00a0", " ")
                line = re.sub(r"[ \t]+", " ", line).strip()
                return line

            def cell_lines(cell):
                lines = []
                for p in cell.findall(".//text:p", ns) + cell.findall(".//text:h", ns):
                    line = normalize_line("".join(p.itertext()))
                    if line:
                        lines.append(line)
                img_count = len(cell.findall(".//draw:image", ns))
                if img_count:
                    lines.append(f"[ì´ë¯¸ì§€ x{img_count}]")
                return lines

            out_lines = []
            for child in body:
                if child.tag == f"{{{ns['table']}}}table":
                    for row in child.findall("table:table-row", ns):
                        row_lines = []
                        for cell in row.findall("table:table-cell", ns):
                            lines = cell_lines(cell)
                            if lines:
                                row_lines.append("\n".join(lines))
                        if row_lines:
                            out_lines.append("\n".join(row_lines))
                            out_lines.append("")
                elif child.tag in (f"{{{ns['text']}}}p", f"{{{ns['text']}}}h"):
                    line = normalize_line("".join(child.itertext()))
                    if line:
                        out_lines.append(line)
            return "\n".join(out_lines).strip()

        def extract_text_from_hwp5odt(path):
            odt_path = None
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".odt") as tmp_odt:
                    odt_path = tmp_odt.name
                def run_odt(cmd):
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    if result.returncode != 0:
                        raise ValueError(result.stderr.strip() or "hwp5odt ë³€í™˜ ì‹¤íŒ¨")
                    if not os.path.exists(odt_path) or os.path.getsize(odt_path) == 0:
                        raise ValueError("ODT ë³€í™˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                if shutil.which("hwp5odt"):
                    run_odt(["hwp5odt", "--output", odt_path, path])
                else:
                    try:
                        import importlib.util
                        if importlib.util.find_spec("hwp5.hwp5odt") is not None:
                            run_odt([sys.executable, "-m", "hwp5.hwp5odt", "--output", odt_path, path])
                        else:
                            return ""
                    except Exception:
                        return ""
                with zipfile.ZipFile(odt_path) as zf:
                    xml_bytes = zf.read("content.xml")
                return extract_text_from_odt_content(xml_bytes)
            except Exception:
                # ODT ë³´ì¡° íŒŒì‹± ì‹¤íŒ¨ ì‹œ hwp5txt ì›ë¬¸ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ í´ë°±
                return ""
            finally:
                if odt_path and os.path.exists(odt_path):
                    try:
                        os.unlink(odt_path)
                    except Exception:
                        pass

        def run_hwp5txt(cmd):
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True
            )
            if result.returncode != 0:
                raise ValueError(result.stderr.strip() or "hwp5txt ë³€í™˜ ì‹¤íŒ¨")
            text = result.stdout
            if not text.strip():
                raise ValueError("HWP í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return text

        if shutil.which("hwp5txt"):
            text = run_hwp5txt(["hwp5txt", tmp_path])
            if not is_table_placeholder_text(text):
                return text
            odt_text = extract_text_from_hwp5odt(tmp_path)
            if odt_text:
                return odt_text
            return text

        # fallback: python -m hwp5.hwp5txt (pyhwp ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë‚˜ PATHì— ì—†ì„ ë•Œ)
        try:
            import importlib.util
            if importlib.util.find_spec("hwp5.hwp5txt") is not None:
                text = run_hwp5txt([sys.executable, "-m", "hwp5.hwp5txt", tmp_path])
                if not is_table_placeholder_text(text):
                    return text
                odt_text = extract_text_from_hwp5odt(tmp_path)
                if odt_text:
                    return odt_text
                return text
        except Exception:
            pass

        raise ValueError(
            "hwp5txt ì‹¤í–‰ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
            "pyhwp ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”. (ì˜ˆ: `python -m pip install pyhwp`)"
        )
    except Exception as e:
        raise ValueError(f"HWP ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    finally:
        if tmp_path and os.path.exists(tmp_path):
            os.unlink(tmp_path)

def extract_text_from_file(uploaded_file, **kwargs):
    """íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    file_ext = Path(uploaded_file.name).suffix.lower()
    
    if file_ext == ".pdf":
        return extract_text_from_pdf(uploaded_file, **kwargs)
    elif file_ext == ".docx":
        return extract_text_from_docx(uploaded_file)
    elif file_ext == ".pptx":
        return extract_text_from_pptx(uploaded_file)
    elif file_ext == ".hwp":
        return extract_text_from_hwp(uploaded_file)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")

def parse_uploaded_question_file(uploaded_file, mode_hint="auto"):
    """ì‚¬ìš©ì ì—…ë¡œë“œ ë¬¸í•­ íŒŒì¼ íŒŒì‹± (json/txt/tsv)"""
    ext = Path(uploaded_file.name).suffix.lower()
    content_bytes = uploaded_file.read()
    if ext == ".json":
        try:
            data = json.loads(content_bytes.decode("utf-8"))
        except Exception:
            data = json.loads(content_bytes.decode("utf-8-sig"))
        items = []
        if isinstance(data, dict) and ("text" in data or "cloze" in data):
            for it in data.get("text", []):
                norm = normalize_mcq_item(it)
                if norm:
                    items.append(norm)
            for it in data.get("cloze", []):
                norm = normalize_cloze_item(it)
                if norm:
                    items.append(norm)
        elif isinstance(data, list):
            for it in data:
                if isinstance(it, dict) and (it.get("type") == "cloze" or "front" in it or ("content" in it and "{{c1::" in str(it.get("content", "")))):
                    norm = normalize_cloze_item(it)
                else:
                    norm = normalize_mcq_item(it)
                if norm:
                    items.append(norm)
        elif isinstance(data, dict):
            if data.get("type") == "cloze" or "front" in data or ("content" in data and "{{c1::" in str(data.get("content", ""))):
                norm = normalize_cloze_item(data)
            else:
                norm = normalize_mcq_item(data)
            if norm:
                items.append(norm)
        return items

    # text/tsv/hwp
    if ext == ".hwp":
        text = extract_text_from_hwp(content_bytes)
    else:
        text = content_bytes.decode("utf-8", errors="ignore")
    if mode_hint == "auto":
        if "{{c1::" in text:
            mode_hint = MODE_CLOZE
        elif "ì •ë‹µ" in text and not re.search(r"â‘ |â‘¡|â‘¢|â‘£|â‘¤", text):
            mode_hint = MODE_CLOZE
        else:
            mode_hint = MODE_MCQ

    if mode_hint == MODE_CLOZE and "{{c1::" not in text:
        qa_parsed = parse_qa_to_cloze(text)
        if qa_parsed:
            return qa_parsed
    parsed = parse_generated_text_to_structured(text, mode_hint)
    if isinstance(parsed, list) and parsed:
        return parsed
    # fallback: fuzzy parser for messy past exam text
    fuzzy = parse_exam_text_fuzzy(text)
    return fuzzy if isinstance(fuzzy, list) else []

# ============================================================================
# AI ì½˜í…ì¸  ìƒì„±
# ============================================================================
PROMPT_MCQ = """
ë‹¹ì‹ ì€ ì˜ê³¼ëŒ€í•™ êµìˆ˜ì…ë‹ˆë‹¤. ê°•ì˜ë¡ì„ ë¶„ì„í•˜ì—¬ 'ì„ìƒ ì¦ë¡€í˜• ê°ê´€ì‹ ë¬¸ì œ(5ì§€ ì„ ë‹¤)'ë¥¼ 5ë¬¸ì œ ì¶œì œí•˜ì„¸ìš”.

[ì¶œì œ ì§€ì¹¨]
1. ë‹¨ìˆœ ì•”ê¸°ë³´ë‹¤ ì¦ìƒ, ê²€ì‚¬ ì†Œê²¬ì„ ë³´ê³  ì§„ë‹¨/ì¹˜ë£Œë¥¼ ê³ ë¥´ëŠ” ë¬¸ì œ ìœ„ì£¼.
2. ê° ë¬¸ì œë§ˆë‹¤ ëª…í™•í•œ ì¦ë¡€ ì œì‹œ.
3. ì„ ì§€ëŠ” ì •í™•íˆ 5ê°œë§Œ ì‘ì„±í•  ê²ƒ.
4. í•´ì„¤ì— ì •ë‹µ ì´ìœ ì™€ ì˜¤ë‹µ ì´ìœ ë¥¼ ëª…í™•íˆ ì„¤ëª…í•  ê²ƒ.
5. ì •í™•íˆ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•  ê²ƒ.

[í•„ìˆ˜ ì¶œë ¥ í˜•ì‹ - JSON ë°°ì—´]
[
  {
    "problem": "[ë¬¸ì œ] ì„ìƒ ì¦ë¡€... ì¦ìƒ + ê²€ì‚¬ ì†Œê²¬ + ì§„ë‹¨ ì§ˆë¬¸",
    "options": ["ì„ ì§€ 1", "ì„ ì§€ 2", "ì„ ì§€ 3", "ì„ ì§€ 4", "ì„ ì§€ 5"],
    "answer": 1,
    "explanation": "ì •ë‹µ(â‘ ) ì´ìœ : ... | â‘¡ë²ˆ ì˜¤ë‹µ ì´ìœ : ... | â‘¢ë²ˆ ì˜¤ë‹µ ì´ìœ : ... | â‘£ë²ˆ ì˜¤ë‹µ ì´ìœ : ... | â‘¤ë²ˆ ì˜¤ë‹µ ì´ìœ : ..."
  },
  {
    "problem": "[ë¬¸ì œ] ë‹¤ë¥¸ ì¦ë¡€...",
    "options": ["ì„ ì§€ 1", "ì„ ì§€ 2", "ì„ ì§€ 3", "ì„ ì§€ 4", "ì„ ì§€ 5"],
    "answer": 2,
    "explanation": "..."
  }
]

[ì¤‘ìš” ê·œì¹™]:
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON ë°°ì—´ë§Œ ì¶œë ¥
- answerëŠ” 1~5 ìˆ«ì (1 = â‘ , 2 = â‘¡, 3 = â‘¢, 4 = â‘£, 5 = â‘¤)
- ê° ë¬¸ì œëŠ” ë…ë¦½ì ì´ì–´ì•¼ í•¨
"""


PROMPT_CLOZE = """
ë‹¹ì‹ ì€ ì˜ëŒ€ìƒ íŠœí„°ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ ê°œë…, ë³‘ëª…, ì¦ìƒ, ìˆ˜ì¹˜ë¥¼ Anki Cloze(ë¹ˆì¹¸) í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

[ì‘ì„± ì§€ì¹¨]
1. ë¬¸ë§¥ìƒ í•µì‹¬ í‚¤ì›Œë“œë¥¼ `{{c1::ì •ë‹µ}}`ìœ¼ë¡œ ê°ì‹¸ì„¸ìš”.
2. í•œ ì¤„ì— í•˜ë‚˜ì˜ ì‚¬ì‹¤(Fact)ë§Œ ì‘ì„±í•˜ì„¸ìš”.
3. ì˜ˆì‹œ: "Î±-thalassemia due to a three gene deletion presents with {{c1::HbH}} disease."
4. ë¶ˆí•„ìš”í•œ ì„œë¡ /ê²°ë¡  ì—†ì´ ë³€í™˜ëœ ë¬¸ì¥ë§Œ ë‚˜ì—´í•˜ì„¸ìš”.
"""

PROMPT_SHORT = """
ë‹¹ì‹ ì€ ì˜ëŒ€ìƒ íŠœí„°ì…ë‹ˆë‹¤. ê°•ì˜ë¡ì—ì„œ ë‹¨ë‹µí˜• ë¬¸í•­ì„ ë§Œë“œì„¸ìš”.

[ì¶œë ¥ ê·œì¹™]
1. ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ì¶œë ¥.
2. ê° í•­ëª©ì€ front(ë¬¸í•­), answer(ì •ë‹µ), explanation(ì§§ì€ í•´ì„¤) í¬í•¨.
3. ë¬¸í•­ì€ ì§§ê³  ëª…í™•í•˜ê²Œ ì‘ì„±.

[JSON í˜•ì‹]
[
  {"front": "ë¬¸í•­", "answer": "ì •ë‹µ", "explanation": "í•´ì„¤"}
]
"""

PROMPT_ESSAY = """
ë‹¹ì‹ ì€ ì˜ëŒ€ìƒ íŠœí„°ì…ë‹ˆë‹¤. ê°•ì˜ë¡ì—ì„œ ì„œìˆ í˜• ë¬¸í•­ì„ ë§Œë“œì„¸ìš”.

[ì¶œë ¥ ê·œì¹™]
1. ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ì¶œë ¥.
2. ê° í•­ëª©ì€ front(ë¬¸í•­), answer(ëª¨ë²”ë‹µì•ˆ), explanation(ì±„ì  í¬ì¸íŠ¸) í¬í•¨.
3. ë¬¸í•­ì€ ì„ìƒ ì¶”ë¡ /ì„¤ëª…í˜•ìœ¼ë¡œ ì‘ì„±.

[JSON í˜•ì‹]
[
  {"front": "ë¬¸í•­", "answer": "ëª¨ë²”ë‹µì•ˆ", "explanation": "ì±„ì  í¬ì¸íŠ¸"}
]
"""

def detect_term_language_mode(style_text: str):
    """ê¸°ì¶œ ìŠ¤íƒ€ì¼ í…ìŠ¤íŠ¸ì—ì„œ 'ìš©ì–´ í‘œê¸°' í˜¼ìš©ì„ ì¶”ì •í•œë‹¤.

    Returns:
        (mode, pattern)
        - mode: "ko" | "en" | "mixed"
        - pattern: "ko(en)" | "en(ko)" | ""
    """
    s = str(style_text or "").strip()
    if not s:
        return ("mixed", "")

    # Pattern-based mixed style detection
    ko_en = len(re.findall(r"[ê°€-í£]{2,}\s*\([A-Za-z][^)]{2,}\)", s))
    en_ko = len(re.findall(r"[A-Za-z]{2,}(?:[ -][A-Za-z]{2,})*\s*\([ê°€-í£]{2,}[^)]*\)", s))
    if ko_en or en_ko:
        if ko_en >= en_ko and ko_en > 0:
            return ("mixed", "ko(en)")
        if en_ko > ko_en:
            return ("mixed", "en(ko)")
        return ("mixed", "")

    # Fallback: character ratio (Hangul vs Latin)
    hangul_chars = len(re.findall(r"[ê°€-í£]", s))
    latin_chars = len(re.findall(r"[A-Za-z]", s))
    denom = hangul_chars + latin_chars
    if denom == 0:
        return ("mixed", "")

    ratio_ko = hangul_chars / denom
    ratio_en = latin_chars / denom
    if ratio_ko >= 0.85:
        return ("ko", "")
    if ratio_en >= 0.85:
        return ("en", "")
    return ("mixed", "")

def detect_question_flavor_scores(text):
    s = str(text or "")
    if not s.strip():
        return {"basic": 0, "case": 0}
    case_patterns = [
        r"\d+\s*ì„¸",
        r"í™˜ì",
        r"ë‚´ì›",
        r"ì£¼í˜¸ì†Œ",
        r"ì¦ìƒ",
        r"ì§„ë‹¨",
        r"ì¹˜ë£Œ",
        r"ì²˜ì¹˜",
        r"ê²€ì‚¬",
        r"í˜ˆì••",
        r"ë§¥ë°•",
        r"í˜¸í¡ìˆ˜",
        r"ì²´ì˜¨",
        r"ì‘ê¸‰",
    ]
    basic_patterns = [
        r"ê¸°ì „",
        r"ì •ì˜",
        r"ë¶„ë¥˜",
        r"êµ¬ì¡°",
        r"ìœ„ì¹˜",
        r"ìœ ë˜",
        r"ë°œìƒ",
        r"ë§‰ì „ìœ„",
        r"ì´ì˜¨",
        r"íš¨ì†Œ",
        r"ëŒ€ì‚¬",
        r"ê²½ë¡œ",
        r"ìˆ˜ì†¡",
        r"ê³„ì‚°",
        r"equation",
        r"pathway",
        r"origin",
    ]
    case_score = sum(len(re.findall(p, s, flags=re.IGNORECASE)) for p in case_patterns)
    basic_score = sum(len(re.findall(p, s, flags=re.IGNORECASE)) for p in basic_patterns)
    return {"basic": basic_score, "case": case_score}

def resolve_generation_flavor(flavor_choice, raw_text="", style_text="", subject=""):
    choice = str(flavor_choice or "").strip().lower()
    if "basic" in choice:
        return "basic"
    if "case" in choice:
        return "case"
    if "mix" in choice:
        return "mix"

    subj = str(subject or "").lower()
    basic_subject_keywords = ["í•´ë¶€", "ìƒë¦¬", "ìƒí™”í•™", "ë©´ì—­", "ë°œìƒ", "ì¡°ì§", "ì•½ë¦¬", "ê¸°ì´ˆ", "anatom", "physio", "biochem", "immun"]
    case_subject_keywords = ["ë‚´ê³¼", "ì™¸ê³¼", "ì†Œì•„", "ì‚°ë¶€", "ì •ì‹ ", "ì‘ê¸‰", "ê°€ì •", "ì‹ ê²½ê³¼", "ì§„ë‹¨", "ì„ìƒ", "internal", "surgery", "pedi", "obgyn"]

    basic_subj = any(k in subj for k in basic_subject_keywords)
    case_subj = any(k in subj for k in case_subject_keywords)
    if basic_subj and not case_subj:
        return "basic"
    if case_subj and not basic_subj:
        return "case"

    style_scores = detect_question_flavor_scores(str(style_text or "")[:12000])
    raw_scores = detect_question_flavor_scores(str(raw_text or "")[:12000])
    basic_score = style_scores["basic"] * 2 + raw_scores["basic"]
    case_score = style_scores["case"] * 2 + raw_scores["case"]
    return "basic" if basic_score >= case_score else "case"

def build_flavor_instructions(selected_mode, resolved_flavor, mix_basic_ratio=70):
    flavor = str(resolved_flavor or "").lower()
    if flavor not in {"basic", "case", "mix"}:
        return ""
    basic_ratio = max(0, min(100, int(mix_basic_ratio or 70)))
    case_ratio = 100 - basic_ratio
    if flavor == "basic":
        return """
[ë¬¸í•­ ì„±ê²© ì§€ì‹œ: ê¸°ì´ˆì˜í•™í˜•]
- ì„ìƒ ì§„ë‹¨/ì²˜ë°© ì¤‘ì‹¬ ì¦ë¡€í˜•ì„ ë°°ì œí•˜ì„¸ìš”.
- ê¸°ì „(Mechanism), í•´ë¶€í•™ì  ìœ„ì¹˜/ì£¼í–‰, ë¶„ë¥˜, ì •ì˜, ê³„ì‚°(ê³µì‹/ìˆ˜ì¹˜ í•´ì„) ì¤‘ì‹¬ìœ¼ë¡œ ì¶œì œí•˜ì„¸ìš”.
- í•œêµ­ì–´ ì„¤ëª… + í•µì‹¬ ì˜í•™ ìš©ì–´ëŠ” ì˜ì–´(ë˜ëŠ” í•œì˜ ë³‘ê¸°)ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""
    if flavor == "case":
        return """
[ë¬¸í•­ ì„±ê²© ì§€ì‹œ: ì¼€ì´ìŠ¤í˜•]
- í™˜ì ì •ë³´(ì—°ë ¹/ì„±ë³„/ì¦ìƒ/ê²€ì‚¬ ì†Œê²¬)ë¥¼ í¬í•¨í•œ ì„ìƒ ì¦ë¡€í˜•ìœ¼ë¡œ ì¶œì œí•˜ì„¸ìš”.
- ì§„ë‹¨, ë‹¤ìŒ ê²€ì‚¬, ì¹˜ë£Œ ì„ íƒ/ê¸ˆê¸° íŒë‹¨ì„ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.
- ë‹¨ìˆœ ì •ì˜ ì•”ê¸°í˜• ë¬¸í•­ ë¹„ìœ¨ì„ ë‚®ì¶”ì„¸ìš”.
"""
    return f"""
[ë¬¸í•­ ì„±ê²© ì§€ì‹œ: í˜¼í•©í˜•]
- ì „ì²´ ë¬¸í•­ì„ ê¸°ì´ˆì˜í•™í˜• ì•½ {basic_ratio}%, ì¼€ì´ìŠ¤í˜• ì•½ {case_ratio}% ë¹„ìœ¨ë¡œ êµ¬ì„±í•˜ì„¸ìš”.
- ê¸°ì´ˆì˜í•™í˜•: ê¸°ì „/í•´ë¶€í•™/ë¶„ë¥˜/ê³„ì‚° ì¤‘ì‹¬
- ì¼€ì´ìŠ¤í˜•: ì„ìƒ ì¦ë¡€ ê¸°ë°˜ ì§„ë‹¨/ê²€ì‚¬/ì¹˜ë£Œ íŒë‹¨ ì¤‘ì‹¬
"""

def build_style_instructions(style_text):
    if not style_text:
        return ""
    excerpt = style_text[:8000]
    mode, pattern = detect_term_language_mode(style_text)
    if mode == "ko":
        term_rule = "- ìš©ì–´ í‘œê¸°: ê°€ëŠ¥í•œ í•œ í•œêµ­ì–´ ìš©ì–´ë¥¼ ì‚¬ìš©(í‘œì¤€ ì•½ì–´/ë‹¨ìœ„ëŠ” í—ˆìš©). ì˜ì–´ í’€ë„¤ì„ ë³‘ê¸°ëŠ” ìµœì†Œí™”."
    elif mode == "en":
        term_rule = "- ìš©ì–´ í‘œê¸°: í•µì‹¬ ì˜í•™ ìš©ì–´ëŠ” ì˜ì–´ë¡œ í‘œê¸°. ë¶ˆí•„ìš”í•œ í•œêµ­ì–´ ë²ˆì—­/ë³‘ê¸°ëŠ” ìµœì†Œí™”."
    else:
        if pattern == "ko(en)":
            term_rule = "- ìš©ì–´ í‘œê¸°: í•œêµ­ì–´ ìš©ì–´ ë’¤ì— (ì˜ì–´)ë¡œ ë³‘ê¸°í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ìœ ì§€. ì˜ˆ: ë…¸ì‹ ê²½(radial nerve)"
        elif pattern == "en(ko)":
            term_rule = "- ìš©ì–´ í‘œê¸°: ì˜ì–´ ìš©ì–´ ë’¤ì— (í•œêµ­ì–´)ë¡œ ë³‘ê¸°í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ìœ ì§€."
        else:
            term_rule = "- ìš©ì–´ í‘œê¸°: í•œêµ­ì–´/ì˜ì–´ í˜¼ìš© ìŠ¤íƒ€ì¼ì„ ìœ ì§€(ê¸°ì¶œë¬¸ì œ í‘œí˜„ ìš°ì„ )."
    return f"""
[ê¸°ì¶œë¬¸ì œ ìŠ¤íƒ€ì¼ ì°¸ê³ ]
{excerpt}

[ìŠ¤íƒ€ì¼ ì§€ì‹œ]
- ìœ„ ê¸°ì¶œë¬¸ì œì˜ ì§ˆë¬¸ êµ¬ì¡°, ë‚œì´ë„, ë¬¸ì¥ ê¸¸ì´, ì„ ì§€ í†¤/í‘œí˜„ì„ ìµœëŒ€í•œ ëª¨ì‚¬
- ë‚´ìš©ì€ ê°•ì˜ë¡ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
- ì¶œë ¥ í˜•ì‹ ê·œì¹™ì€ ë°˜ë“œì‹œ ìœ ì§€
{term_rule}
"""

def generate_content_gemini(
    text_content,
    selected_mode,
    num_items=5,
    api_key=None,
    style_text=None,
    gemini_model_id=None,
    audit_user_id=None,
    resolved_flavor=None,
    mix_basic_ratio=70,
):
    """Geminië¥¼ ì´ìš©í•´ ì½˜í…ì¸  ìƒì„±"""
    if not api_key:
        return "âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— Gemini API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    if not text_content or len(text_content.strip()) < 10:
        return "âš ï¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    mode_mcq = globals().get("MODE_MCQ", "ğŸ“ ê°ê´€ì‹ ë¬¸ì œ (Case Study)")
    mode_cloze = globals().get("MODE_CLOZE", "ğŸ§© ë¹ˆì¹¸ ëš«ê¸° (Anki Cloze)")
    mode_short = globals().get("MODE_SHORT", "ğŸ§  ë‹¨ë‹µí˜• ë¬¸ì œ")
    prompt_short = globals().get("PROMPT_SHORT", PROMPT_CLOZE)
    prompt_essay = globals().get("PROMPT_ESSAY", PROMPT_CLOZE)
    style_block = build_style_instructions(style_text)
    flavor_block = build_flavor_instructions(selected_mode, resolved_flavor, mix_basic_ratio=mix_basic_ratio)
    if selected_mode == mode_mcq:
        system_prompt = PROMPT_MCQ.replace("5ë¬¸ì œ", f"{num_items}ë¬¸ì œ") + style_block + flavor_block
    elif selected_mode == mode_cloze:
        system_prompt = PROMPT_CLOZE + style_block + flavor_block + f"\n\n[ìš”ì²­] ì´ {num_items}ê°œ í•­ëª©ì„ ì¶œë ¥í•˜ì„¸ìš”. í•œ ì¤„ì— í•˜ë‚˜ì˜ í•­ëª©ë§Œ ì‘ì„±í•˜ì„¸ìš”."
    elif selected_mode == mode_short:
        system_prompt = prompt_short + style_block + flavor_block + f"\n\n[ìš”ì²­] ì´ {num_items}ê°œ í•­ëª©ì„ ì¶œë ¥í•˜ì„¸ìš”."
    else:
        system_prompt = prompt_essay + style_block + flavor_block + f"\n\n[ìš”ì²­] ì´ {num_items}ê°œ í•­ëª©ì„ ì¶œë ¥í•˜ì„¸ìš”."
    
    try:
        model_name = gemini_model_id or get_gemini_model_id()
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        prompt_text = f"{system_prompt}\n\n[ê°•ì˜ë¡ ë‚´ìš©]:\n{text_content[:30000]}"
        generation_config = {
            "temperature": LLM_TEMPERATURE,
            "top_p": 1.0,
        }
        response = model.generate_content(prompt_text, generation_config=generation_config)
        result_text = response.text
        append_audit_log("gen.question", {
            "model": model_name,
            "temperature": LLM_TEMPERATURE,
            "seed": None,
            "prompt_hash": _hash_text(prompt_text),
            "prompt_text": prompt_text,
            "input_hash": _hash_text(text_content[:30000]),
            "output_text": result_text,
            "usage_tokens": _gemini_usage_tokens(response),
            "prompt_version": PROMPT_VERSION,
        }, user_id=audit_user_id)
        return result_text
    except Exception as e:
        return f"âŒ Gemini ìƒì„± ì‹¤íŒ¨: {str(e)}"

def generate_content_openai(
    text_content,
    selected_mode,
    num_items=5,
    openai_api_key=None,
    style_text=None,
    audit_user_id=None,
    resolved_flavor=None,
    mix_basic_ratio=70,
):
    """ChatGPTë¥¼ ì´ìš©í•´ ì½˜í…ì¸  ìƒì„±"""
    if not openai_api_key:
        return "âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— OpenAI API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    if not text_content or len(text_content.strip()) < 10:
        return "âš ï¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    mode_mcq = globals().get("MODE_MCQ", "ğŸ“ ê°ê´€ì‹ ë¬¸ì œ (Case Study)")
    mode_cloze = globals().get("MODE_CLOZE", "ğŸ§© ë¹ˆì¹¸ ëš«ê¸° (Anki Cloze)")
    mode_short = globals().get("MODE_SHORT", "ğŸ§  ë‹¨ë‹µí˜• ë¬¸ì œ")
    prompt_short = globals().get("PROMPT_SHORT", PROMPT_CLOZE)
    prompt_essay = globals().get("PROMPT_ESSAY", PROMPT_CLOZE)
    style_block = build_style_instructions(style_text)
    flavor_block = build_flavor_instructions(selected_mode, resolved_flavor, mix_basic_ratio=mix_basic_ratio)
    if selected_mode == mode_mcq:
        system_prompt = PROMPT_MCQ.replace("5ë¬¸ì œ", f"{num_items}ë¬¸ì œ") + style_block + flavor_block
    elif selected_mode == mode_cloze:
        system_prompt = PROMPT_CLOZE + style_block + flavor_block + f"\n\n[ìš”ì²­] ì´ {num_items}ê°œ í•­ëª©ì„ ì¶œë ¥í•˜ì„¸ìš”. í•œ ì¤„ì— í•˜ë‚˜ì˜ í•­ëª©ë§Œ ì‘ì„±í•˜ì„¸ìš”."
    elif selected_mode == mode_short:
        system_prompt = prompt_short + style_block + flavor_block + f"\n\n[ìš”ì²­] ì´ {num_items}ê°œ í•­ëª©ì„ ì¶œë ¥í•˜ì„¸ìš”."
    else:
        system_prompt = prompt_essay + style_block + flavor_block + f"\n\n[ìš”ì²­] ì´ {num_items}ê°œ í•­ëª©ì„ ì¶œë ¥í•˜ì„¸ìš”."
    
    try:
        import sys
        print(f"[OPENAI DEBUG] API í‚¤ ê¸¸ì´: {len(openai_api_key)}", file=sys.stderr)
        print(f"[OPENAI DEBUG] í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text_content[:30000])}", file=sys.stderr)
        
        openai_client = OpenAI(api_key=openai_api_key)
        print(f"[OPENAI DEBUG] OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ", file=sys.stderr)
        
        prompt_text = f"{system_prompt}\n\n[ê°•ì˜ë¡ ë‚´ìš©]:\n{text_content[:30000]}"
        openai_params = {
            "model": "gpt-4o-mini",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"[ê°•ì˜ë¡ ë‚´ìš©]:\n{text_content[:30000]}"}
            ],
            "temperature": LLM_TEMPERATURE,
            "max_tokens": 4000,
        }
        if LLM_SEED is not None:
            openai_params["seed"] = LLM_SEED
        response = openai_client.chat.completions.create(
            **openai_params
        )
        
        result = response.choices[0].message.content
        print(f"[OPENAI DEBUG] ì‘ë‹µ ê¸¸ì´: {len(result)}", file=sys.stderr)
        
        # MCQëŠ” JSONìœ¼ë¡œ íŒŒì‹±, ClozeëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜
        if selected_mode == mode_mcq:
            result = convert_json_mcq_to_text(result, num_items)
        
        append_audit_log("gen.question", {
            "model": "gpt-4o-mini",
            "temperature": LLM_TEMPERATURE,
            "seed": LLM_SEED,
            "prompt_hash": _hash_text(prompt_text),
            "prompt_text": prompt_text,
            "input_hash": _hash_text(text_content[:30000]),
            "output_text": result,
            "usage_tokens": _openai_usage_tokens(response),
            "prompt_version": PROMPT_VERSION,
        }, user_id=audit_user_id)
        return result
    except Exception as e:
        import traceback
        error_msg = f"âŒ ChatGPT ìƒì„± ì‹¤íŒ¨: {str(e)}\n\nìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}"
        print(error_msg, file=sys.stderr)
        return error_msg

def convert_json_mcq_to_text(json_text, num_items):
    """JSON í˜•ì‹ì˜ MCQë¥¼ ê¸°ì¡´ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    import json
    import sys
    
    try:
        # JSON íŒŒì‹±
        data = json.loads(json_text)
        if not isinstance(data, list):
            data = [data]
        
        print(f"[JSON PARSE] {len(data)}ê°œ MCQ íŒŒì‹± ì„±ê³µ", file=sys.stderr)
        
        # í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        result_lines = []
        for idx, item in enumerate(data[:num_items], 1):
            problem = item.get("problem", f"[ë¬¸ì œ] {idx}ë²ˆ")
            options = item.get("options", [])
            answer = item.get("answer", 1)  # 1~5 ìˆ«ì
            explanation = item.get("explanation", "")
            
            # problemì— [ë¬¸ì œ]ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            if "[ë¬¸ì œ]" not in problem:
                problem = f"[ë¬¸ì œ] {problem}"
            
            # MCQ ë¸”ë¡ êµ¬ì„±
            block = problem + "\n\n"
            circ = ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£', 'â‘¤']
            for i, opt in enumerate(options[:5]):
                block += f"{circ[i]} {opt}\n"
            
            # ì •ë‹µê³¼ ì„¤ëª… ì¶”ê°€
            ans_num = str(answer) if isinstance(answer, int) and 1 <= answer <= 5 else "1"
            block += f"\nì •ë‹µ: {{{{c1::{ans_num}}}}}\ní•´ì„¤: {explanation}"
            
            result_lines.append(block)
        
        # '---'ìœ¼ë¡œ êµ¬ë¶„
        final_result = "\n---\n".join(result_lines)
        print(f"[JSON CONVERT] {len(result_lines)}ê°œ MCQ ë³€í™˜ ì™„ë£Œ", file=sys.stderr)
        
        return final_result
    
    except json.JSONDecodeError as e:
        print(f"[JSON ERROR] JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}", file=sys.stderr)
        # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜ (ë‹¤ë¥¸ íŒŒì‹± ë¡œì§ì´ ì²˜ë¦¬í•  ê²ƒ)
        return json_text
    except Exception as e:
        print(f"[CONVERT ERROR] ë³€í™˜ ì‹¤íŒ¨: {str(e)}", file=sys.stderr)
        return json_text


def generate_content(
    text_content,
    selected_mode,
    ai_model,
    num_items=5,
    api_key=None,
    openai_api_key=None,
    style_text=None,
    gemini_model_id=None,
    audit_user_id=None,
    resolved_flavor=None,
    mix_basic_ratio=70,
):
    """ì„ íƒëœ AI ëª¨ë¸ì„ ì‚¬ìš©í•´ ì½˜í…ì¸  ìƒì„±"""
    if ai_model == "ğŸ”µ Google Gemini":
        return generate_content_gemini(
            text_content,
            selected_mode,
            num_items=num_items,
            api_key=api_key,
            style_text=style_text,
            gemini_model_id=gemini_model_id,
            audit_user_id=audit_user_id,
            resolved_flavor=resolved_flavor,
            mix_basic_ratio=mix_basic_ratio,
        )
    else:  # ChatGPT
        return generate_content_openai(
            text_content,
            selected_mode,
            num_items=num_items,
            openai_api_key=openai_api_key,
            style_text=style_text,
            audit_user_id=audit_user_id,
            resolved_flavor=resolved_flavor,
            mix_basic_ratio=mix_basic_ratio,
        )

def split_text_into_chunks(text, chunk_size=8000, overlap=500):
    """ë¬¸ì ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í•  (ì¤‘ì²© í¬í•¨)"""
    if chunk_size <= 0:
        return [text]
    chunks = []
    start = 0
    text_len = len(text)
    while start < text_len:
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        if end >= text_len:
            break
        start = end - overlap if end - overlap > start else end
    return chunks

def generate_content_in_chunks(
    text_content,
    selected_mode,
    ai_model,
    num_items=5,
    chunk_size=8000,
    overlap=500,
    api_key=None,
    openai_api_key=None,
    style_text=None,
    show_progress=True,
    gemini_model_id=None,
    audit_user_id=None,
    resolved_flavor=None,
    mix_basic_ratio=70,
):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ëª¨ë¸ í˜¸ì¶œì„ ì—¬ëŸ¬ ë²ˆ ìˆ˜í–‰
    
    Returns:
        - ê°ê´€ì‹: êµ¬ì¡°í™”ëœ dict ë¦¬ìŠ¤íŠ¸ (ê° dictëŠ” {type, problem, options, answer, explanation})
        - ë¹ˆì¹¸/ë‹¨ë‹µ/ì„œìˆ : êµ¬ì¡°í™”ëœ dict ë¦¬ìŠ¤íŠ¸ (ê° dictëŠ” {type, response_type, front, answer, explanation})
    """
    import sys
    chunks = split_text_into_chunks(text_content, chunk_size=chunk_size, overlap=overlap)
    total_chunks = len(chunks)
    
    print(f"[CHUNKS DEBUG] ì´ ì²­í¬ ìˆ˜: {total_chunks}", file=sys.stderr)
    
    if total_chunks == 0:
        return []
    
    base = num_items // total_chunks
    rem = num_items % total_chunks
    items_per_chunk = [base + (1 if i < rem else 0) for i in range(total_chunks)]

    results = [None] * total_chunks
    progress_bar = st.progress(0) if show_progress else None

    with concurrent.futures.ThreadPoolExecutor(max_workers=min(4, total_chunks)) as ex:
        futures = {}
        for idx, chunk in enumerate(chunks):
            n = items_per_chunk[idx]
            if n <= 0:
                results[idx] = ""
                continue
            futures[
                ex.submit(
                    generate_content,
                    chunk,
                    selected_mode,
                    ai_model,
                    n,
                    api_key,
                    openai_api_key,
                    style_text,
                    gemini_model_id,
                    audit_user_id,
                    resolved_flavor,
                    mix_basic_ratio,
                )
            ] = idx

        completed = 0
        for fut in concurrent.futures.as_completed(futures):
            idx = futures[fut]
            try:
                res = fut.result()
            except Exception as e:
                res = f"âŒ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            results[idx] = res if isinstance(res, str) else str(res)
            completed += 1
            if progress_bar is not None:
                progress_bar.progress(int(completed / total_chunks * 100))

    # ëª¨ë“  ì²­í¬ ê²°ê³¼ ê²°í•©
    combined = "\n".join([r for r in results if r])
    
    print(f"[COMBINED DEBUG] ì²­í¬ ê²°ê³¼ ê°œìˆ˜: {len([r for r in results if r])}/{total_chunks}, ì´ ê¸¸ì´: {len(combined)}", file=sys.stderr)

    # ê²°í•©ëœ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ íŒŒì‹±
    structured_list = parse_generated_text_to_structured(combined, selected_mode)
    
    # ì¤‘ë³µ ì œê±°
    seen = set()
    deduped = []
    for item in structured_list:
        key = str(item)  # ë˜ëŠ” ë” ì •êµí•œ í‚¤ ìƒì„±
        if key not in seen:
            seen.add(key)
            deduped.append(item)
    
    # í•„ìš”í•œ ê°œìˆ˜ë§Œ ë°˜í™˜
    return deduped[:num_items]

# ============================================================================
# ì‚¬ì´ë“œë°” ì„¤ì •
# ============================================================================
with st.sidebar:
    render_generation_recovery_panel()
    st.header("ğŸ‘¤ ê³„ì •")
    if st.session_state.auth_user_id:
        who = st.session_state.get("auth_email") or st.session_state.auth_user_id
        st.success(f"ë¡œê·¸ì¸ë¨: {who}")
        if is_admin_user():
            st.caption("ìš´ì˜ì ê¶Œí•œ: í™œì„±")
        if st.button("ë¡œê·¸ì•„ì›ƒ", key="auth_logout_btn"):
            reset_runtime_state_for_auth_change()
            st.session_state.auth_user_id = ""
            st.session_state.auth_access_token = ""
            st.session_state.auth_email = ""
            st.rerun()
    else:
        st.info("ë©”ì¸ í™”ë©´ì—ì„œ ë¡œê·¸ì¸ ë˜ëŠ” íšŒì›ê°€ì…ì„ ì§„í–‰í•˜ì„¸ìš”.")
    if not get_configured_admin_users():
        st.caption("ìš´ì˜ì ê³„ì • ì„¤ì •: AXIOMA_ADMIN_USERS=admin_id1,admin2")

    st.markdown("---")
    st.header("âš™ï¸ ì„¤ì • & ëª¨ë“œ")
    if st.session_state.auth_user_id:
        st.session_state.ai_model = st.radio(
            "ğŸ¤– AI ëª¨ë¸ ì„ íƒ",
            ["ğŸ”µ Google Gemini", "ğŸŸ¢ OpenAI ChatGPT"]
        )

        st.markdown("---")

        if st.session_state.ai_model == "ğŸ”µ Google Gemini":
            st.session_state.api_key = st.text_input("Gemini API Key ì…ë ¥", type="password")
            st.session_state.gemini_model_id = st.text_input(
                "Gemini ëª¨ë¸ ID",
                value=st.session_state.gemini_model_id,
                help="ì˜ˆ: gemini-2.0-flash, gemini-2.0-flash-lite"
            )
            st.session_state.openai_api_key = None
        else:
            st.session_state.api_key = None
            st.session_state.openai_api_key = st.text_input("OpenAI API Key ì…ë ¥", type="password")

        st.markdown("---")
        st.session_state.chunk_size = st.slider("ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)", 2000, 30000, 8000, 500)
        st.session_state.overlap = st.slider("ì²­í¬ ì¤‘ì²© (ë¬¸ì ìˆ˜)", 0, 5000, 500, 100)

        st.markdown("---")
        st.subheader("âš™ï¸ í•„í„°ë§ ì˜µì…˜")
        st.session_state.enable_filter = st.checkbox("í’ˆì§ˆ í•„í„° ì‚¬ìš©", value=True)
        st.session_state.min_length = st.slider("ìµœì†Œ ë¬¸ì ìˆ˜", 10, 200, 30)
        st.session_state.auto_tag_enabled = st.checkbox("ìë™ ë‚œì´ë„/ì¹´í…Œê³ ë¦¬ íƒœê¹…", value=True)
        st.session_state.explanation_default = st.checkbox("í•´ì„¤ ê¸°ë³¸ ì—´ê¸°", value=st.session_state.explanation_default)
    else:
        st.caption("ë¡œê·¸ì¸ í›„ AI í‚¤ ë° ìƒì„± ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.session_state.theme_enabled = False if LOCK_SAFE else True
    st.session_state.theme_mode = resolved_theme_mode
    st.session_state.theme_bg = "Gradient"

# ë¸”ë¡ ì™¸ì—ì„œë„ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ë¡œì»¬ ë³€ìˆ˜ì— í• ë‹¹
ai_model = st.session_state.get("ai_model", "ğŸ”µ Google Gemini")
api_key = st.session_state.get("api_key")
openai_api_key = st.session_state.get("openai_api_key")
chunk_size = st.session_state.get("chunk_size", 8000)
overlap = st.session_state.get("overlap", 500)
enable_filter = st.session_state.get("enable_filter", True)
min_length = st.session_state.get("min_length", 30)
auto_tag_enabled = st.session_state.get("auto_tag_enabled", True)

# Apply theme (skip if disabled)
THEME_ENABLED = should_apply_custom_theme(
    st.session_state.get("theme_enabled"),
    st.session_state.get("theme_mode"),
)
if THEME_ENABLED:
    apply_theme(st.session_state.theme_mode, st.session_state.theme_bg)
if MOBILE_CLIENT:
    apply_mobile_exam_styles()

if not st.session_state.get("auth_user_id"):
    render_auth_landing_page()
    st.stop()

def get_main_page_config(admin_mode):
    pages = [
        ("home", "ğŸ  í™ˆ"),
        ("generate", "ğŸ“š ë¬¸ì œ ìƒì„±"),
        ("convert", "ğŸ§¾ ê¸°ì¶œë¬¸ì œ ë³€í™˜"),
        ("exam", "ğŸ¯ ì‹¤ì „ ì‹œí—˜"),
    ]
    if admin_mode:
        pages.append(("admin", "ğŸ› ï¸ ìš´ì˜"))
    return pages

# ============================================================================
# ë©”ì¸ UI: ë¼ìš°íŒ… êµ¬ì¡° (ì„ íƒí•œ í˜ì´ì§€ë§Œ ë Œë”ë§)
# ============================================================================
admin_mode = is_admin_user()
main_pages = get_main_page_config(admin_mode)
main_labels = [label for _, label in main_pages]
label_to_page = {label: page for page, label in main_pages}
if "main_nav_label" not in st.session_state or st.session_state.main_nav_label not in main_labels:
    st.session_state.main_nav_label = main_labels[0]
active_label = st.radio("í˜ì´ì§€", main_labels, horizontal=True, key="main_nav_label")
active_page = label_to_page.get(active_label, "home")

# ============================================================================
# PAGE: í™ˆ
# ============================================================================
if active_page == "home":
    st.title("ğŸ  í™ˆ")
    show_action_notice()

    stats = get_question_stats()
    bank = load_questions()
    all_questions = bank.get("text", []) + bank.get("cloze", [])
    acc = compute_overall_accuracy(all_questions)
    acc_text = f"{acc['accuracy']:.1f}%" if acc else "â€”"

    if not st.session_state.get("theme_enabled"):
        st.info("Safe modeì—ì„œ í…Œë§ˆê°€ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    st.header("Axioma Qbank")
    st.write("ê°•ì˜ë¡ê³¼ ê¸°ì¶œë¬¸ì œë¥¼ ì—°ê²°í•´ í•™ìŠµ-ì‹œí—˜-ë³µìŠµ íë¦„ì„ ë§Œë“­ë‹ˆë‹¤.")
    st.write(f"ì „ì²´ ì •ë‹µë¥ : {acc_text}")
    st.write(f"ì €ì¥ëœ ê°ê´€ì‹: {stats['total_text']} Â· ì €ì¥ëœ ë¹ˆì¹¸: {stats['total_cloze']}")

    with st.expander("ğŸ” ì´ˆê¸° ì´ìš©ììš©: API í‚¤ ë°œê¸‰ ê°€ì´ë“œ", expanded=False):
        st.caption("ë¬¸í•­ ìƒì„±/ë³€í™˜/AI ë³´ì¡° ê¸°ëŠ¥ì€ ì•„ë˜ ëª¨ë¸ í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        key_tabs = st.tabs(["Google Gemini", "OpenAI"])
        with key_tabs[0]:
            st.markdown(
                """
                1. [Google AI Studio](https://aistudio.google.com/app/apikey) ì ‘ì†
                2. Google ê³„ì • ë¡œê·¸ì¸ í›„ **Create API key** í´ë¦­
                3. API í‚¤ ë³µì‚¬ í›„ ì•± ì‚¬ì´ë“œë°”ì˜ **Gemini API Key ì…ë ¥**ì— ë¶™ì—¬ë„£ê¸°
                4. ëª¨ë¸ì€ `gemini-2.0-flash` ë˜ëŠ” `gemini-2.5-flash` ì‚¬ìš©
                """
            )
            st.info("íŒ: í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜/ì‹œí¬ë¦¿ ê´€ë¦¬ ë„êµ¬ ëŒ€ì‹  ì•± ì„¸ì…˜ì—ë§Œ ì„ì‹œ ì €ì¥ë©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¸ì…˜ì´ ë°”ë€Œë©´ ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        with key_tabs[1]:
            st.markdown(
                """
                1. [OpenAI API keys](https://platform.openai.com/api-keys) ì ‘ì†
                2. ê³„ì • ë¡œê·¸ì¸ í›„ **Create new secret key** í´ë¦­
                3. keyë¥¼ ë³µì‚¬í•´ ì‚¬ì´ë“œë°”ì˜ **OpenAI API Key ì…ë ¥**ì— ë¶™ì—¬ë„£ê¸°
                4. ëª¨ë¸ì€ ê¸°ë³¸ `gpt-4o-mini`(ê¶Œì¥) ë˜ëŠ” í”„ë¡œì íŠ¸ì—ì„œ ì§€ì •í•œ ëª¨ë¸ê³¼ ì¼ì¹˜í•˜ë„ë¡ ì„¤ì •
                """
            )
            st.info("OpenAI í‚¤ëŠ” ì‚¬ìš©ëŸ‰ ê³¼ê¸ˆì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë‹ˆ í”„ë¡œì íŠ¸ ë‹¨ê°€/í• ë‹¹ëŸ‰ì„ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”.")

    # í™ˆì—ì„œ ë°”ë¡œ ì‹œí—˜/í•™ìŠµ ì„¸ì…˜ ì¤€ë¹„
    st.markdown("---")
    st.subheader("ë¹ ë¥¸ ì‹œì‘ (ë¶„ê³¼/ë‹¨ì›)")
    if all_questions:
        quick_subject_unit_map = collect_subject_unit_map(all_questions)
        quick_subjects_all = sorted(quick_subject_unit_map.keys())
        quick_subjects = st.multiselect(
            "í•™ìŠµí•  ë¶„ê³¼",
            quick_subjects_all,
            default=quick_subjects_all[:1],
            key="home_quick_subjects",
        )

        quick_unit_filter = {}
        if quick_subjects:
            with st.expander("ë‹¨ì› ì„ íƒ", expanded=True):
                for subj in quick_subjects:
                    units = quick_subject_unit_map.get(subj, ["ë¯¸ë¶„ë¥˜"])
                    if not units:
                        units = ["ë¯¸ë¶„ë¥˜"]
                    key_name = f"home_unit_filter_{subj}"
                    prev_units = st.session_state.get(key_name, units)
                    selected_units = st.multiselect(
                        f"{subj} ë‹¨ì›",
                        options=units,
                        default=prev_units if set(prev_units) <= set(units) else units,
                        key=key_name,
                    )
                    if not selected_units:
                        selected_units = list(units)
                    quick_unit_filter[subj] = selected_units
        else:
            st.caption("ë¶„ê³¼ë¥¼ ë¨¼ì € ì„ íƒí•˜ë©´ ë‹¨ì› ì²´í¬ë°•ìŠ¤ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")

        quick_mode = st.radio("ëª¨ë“œ", ["ì‹œí—˜ëª¨ë“œ", "í•™ìŠµëª¨ë“œ"], horizontal=True, key="home_quick_mode")
        quick_type = st.selectbox("ë¬¸í•­ ìœ í˜•", ["ê°ê´€ì‹", "ë¹ˆì¹¸"], key="home_quick_type")

        filtered = filter_questions_by_subject_unit_hierarchy(all_questions, quick_subjects, quick_unit_filter)
        if filtered:
            quick_max = min(50, len(filtered))
            quick_min = 1 if quick_max < 5 else 5
            quick_num = st.slider("ë¬¸í•­ ìˆ˜", quick_min, quick_max, min(10, quick_max), key="home_quick_num")
            if st.button("ì„ íƒ ì¡°ê±´ìœ¼ë¡œ ì„¸ì…˜ ì¤€ë¹„", use_container_width=True, key="home_quick_prepare"):
                started = start_exam_session_from_items(filtered[:quick_num], quick_type, quick_mode)
                if started:
                    st.session_state.exam_mode_entry_anchor = "home"
                    st.session_state.last_action_notice = f"í™ˆì—ì„œ {started}ê°œ ë¬¸í•­ìœ¼ë¡œ {quick_mode}ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì‹¤ì „ ì‹œí—˜ íƒ­ìœ¼ë¡œ ì´ë™í•´ ì‹œì‘í•˜ì„¸ìš”."
                    st.rerun()
                else:
                    st.warning("ì„ íƒí•œ íƒ€ì…ì— ë§ëŠ” ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ë¬¸í•­ ìœ í˜•(ê°ê´€ì‹/ë¹ˆì¹¸)ì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        else:
            st.info("ì„ íƒí•œ ë¶„ê³¼/ë‹¨ì›ì— í•´ë‹¹í•˜ëŠ” ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì œë¥¼ ìƒì„±/ë³€í™˜í•´ ì €ì¥í•´ ì£¼ì„¸ìš”.")

    # í†µê³„
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì €ì¥ëœ ê°ê´€ì‹", stats["total_text"])
    with col2:
        st.metric("ì €ì¥ëœ ë¹ˆì¹¸", stats["total_cloze"])
    with col3:
        st.metric("ì „ì²´ ë¬¸í•­ ì •ë‹µë¥ ", acc_text)

    st.markdown("---")
    st.subheader("ë¶„ê³¼/ë‹¨ì› í•œëˆˆì— ë³´ê¸°")
    if all_questions:
        subject_overview = summarize_subject_review_status(all_questions)
        subject_unit_map = collect_subject_unit_map(all_questions)
        subject_rows = []
        for row in subject_overview:
            subj = row.get("ë¶„ê³¼", "General")
            units = subject_unit_map.get(subj, [])
            unit_text = ", ".join(units[:3]) + (" ..." if len(units) > 3 else "")
            subject_rows.append({
                "ë¶„ê³¼": subj,
                "ì´ë¬¸í•­": row.get("ì´ë¬¸í•­", 0),
                "ë³µìŠµëŒ€ìƒ": row.get("ë³µìŠµëŒ€ìƒ", 0),
                "ì˜¤ë‹µë¬¸í•­": row.get("ì˜¤ë‹µë¬¸í•­", 0),
                "ì—°ê´€ ë‹¨ì›": unit_text,
            })
        safe_dataframe(subject_rows, use_container_width=True, hide_index=True)
    else:
        st.info("ì €ì¥ëœ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì œë¥¼ ìƒì„±/ë³€í™˜í•´ë³´ì„¸ìš”.")

    st.markdown("---")
    st.subheader("í•™ìŠµ ëŒ€ì‹œë³´ë“œ")
    wrong_items, total_wrong = get_wrong_note_stats(all_questions)
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì˜¤ë‹µ ëˆ„ì  ë¬¸í•­", len(wrong_items))
    with col2:
        st.metric("ì˜¤ë‹µ ëˆ„ì  íšŸìˆ˜", total_wrong)
    with col3:
        st.metric("ì „ì²´ ë¬¸í•­", len(all_questions))

    # ì˜¤ë‹µë…¸íŠ¸ í•„í„°
    subjects_all = sorted({(q.get("subject") or "General") for q in all_questions}) if all_questions else []
    diffs_all = sorted({(q.get("difficulty") or "ë¯¸ì§€ì •") for q in all_questions}) if all_questions else []
    sel_subjects = st.multiselect("ì˜¤ë‹µë…¸íŠ¸ ë¶„ê³¼ í•„í„°", subjects_all, default=subjects_all)
    sel_diffs = st.multiselect("ì˜¤ë‹µë…¸íŠ¸ ë‚œì´ë„ í•„í„°", diffs_all, default=diffs_all)
    st.session_state.wrong_priority = st.selectbox(
        "ì˜¤ë‹µë…¸íŠ¸ ìš°ì„ ìˆœìœ„",
        ["ì˜¤ë‹µ íšŸìˆ˜", "ì˜¤ë‹µë¥ ", "ìµœê·¼ ì˜¤ë‹µ"],
        index=["ì˜¤ë‹µ íšŸìˆ˜", "ì˜¤ë‹µë¥ ", "ìµœê·¼ ì˜¤ë‹µ"].index(st.session_state.wrong_priority)
    )
    if st.session_state.wrong_priority == "ìµœê·¼ ì˜¤ë‹µ":
        st.session_state.wrong_weight_recent = st.slider(
            "ê°€ì¤‘ì¹˜: ìµœê·¼ ì˜¤ë‹µ",
            0.0, 1.0, st.session_state.wrong_weight_recent, 0.05
        )
        st.session_state.wrong_weight_count = 1.0 - st.session_state.wrong_weight_recent
        st.caption(f"ì˜¤ë‹µ íšŸìˆ˜ ê°€ì¤‘ì¹˜: {st.session_state.wrong_weight_count:.2f}")
    filtered_wrong = [
        q for q in wrong_items
        if (q.get("subject") or "General") in sel_subjects
        and (q.get("difficulty") or "ë¯¸ì§€ì •") in sel_diffs
    ]

    if filtered_wrong:
        if st.button("ğŸ“Œ ì˜¤ë‹µë…¸íŠ¸ ì„¸ì…˜ ì¤€ë¹„", use_container_width=True, key="prepare_wrong_session"):
            # ì˜¤ë‹µ ë¬¸í•­ìœ¼ë¡œ í•™ìŠµ ì„¸ì…˜ ì¤€ë¹„ (ì‹¤ì „ ì‹œí—˜ íƒ­ì—ì„œ ì§„í–‰)
            parsed_selected = []
            for raw in sort_wrong_first(
                filtered_wrong,
                mode=st.session_state.wrong_priority,
                weight_recent=st.session_state.wrong_weight_recent,
                weight_count=st.session_state.wrong_weight_count
            ):
                if raw.get("type") == "cloze":
                    parsed_selected.append(parse_cloze_content(raw))
                else:
                    parsed_selected.append(parse_mcq_content(raw))
            st.session_state.exam_questions = parsed_selected[:50]
            st.session_state.current_question_idx = 0
            st.session_state.user_answers = {}
            st.session_state.exam_started = True
            st.session_state.exam_finished = False
            st.session_state.exam_mode = "í•™ìŠµëª¨ë“œ"
            st.session_state.revealed_answers = set()
            st.session_state.auto_advance_guard = None
            st.session_state.exam_stats_applied = False
            st.session_state.graded_questions = set()
            st.success("ì˜¤ë‹µë…¸íŠ¸ ì„¸ì…˜ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ¯ ì‹¤ì „ ì‹œí—˜ íƒ­ìœ¼ë¡œ ì´ë™í•´ ì‹œì‘í•˜ì„¸ìš”.")
    else:
        st.info("ì„ íƒí•œ í•„í„°ì— í•´ë‹¹í•˜ëŠ” ì˜¤ë‹µ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

    # FSRS / SRS ìƒíƒœ
    st.caption(f"ë³µìŠµ ì—”ì§„: {'FSRS' if FSRS_AVAILABLE else 'ê¸°ë³¸ SRS'}")

    if all_questions:
        with st.expander("ğŸ“Š ë¶„ê³¼ë³„ ë³µìŠµ í(ê¸°ë³¸ í™”ë©´)", expanded=False):
            subject_rows = summarize_subject_review_status(all_questions)
            if subject_rows:
                safe_dataframe(subject_rows, use_container_width=True, hide_index=True)
    elif not FSRS_AVAILABLE:
        st.info("FSRS ë¯¸ì„¤ì¹˜: ê¸°ë³¸ SRSë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("ğŸ§¾ ì‹œí—˜ ê¸°ë¡")
    history = load_exam_history()
    if not history:
        st.info("ì €ì¥ëœ ì‹œí—˜ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        labels = []
        for idx, h in enumerate(history):
            ts = h.get("finished_at", "")
            acc = h.get("accuracy", 0)
            labels.append(f"{idx + 1}. {ts} | {h.get('type')} | {acc}%")
        sel = st.selectbox("ê¸°ë¡ ì„ íƒ", labels, index=0)
        sel_idx = labels.index(sel)
        h = history[sel_idx]
        st.write(f"ë¬¸í•­ ìˆ˜: {h.get('num_questions')} / ì •ë‹µ: {h.get('correct')} / ì •í™•ë„: {h.get('accuracy')}%")
        if h.get("subjects"):
            st.caption(f"ë¶„ê³¼: {', '.join(h.get('subjects'))}")
        if h.get("units"):
            st.caption(f"ë‹¨ì›: {', '.join(h.get('units'))}")

        for i, item in enumerate(h.get("items", []), 1):
            status_icon = "âœ…" if item.get("is_correct") else "âŒ"
            title = f"{status_icon} ë¬¸ì œ {i}"
            with st.expander(title, expanded=False):
                st.markdown(item.get("front") or "")
                if item.get("type") == "mcq":
                    opts = item.get("options") or []
                    letters = ["A", "B", "C", "D", "E"]
                    for idx_opt, opt in enumerate(opts[:5]):
                        st.write(f"{letters[idx_opt]}. {opt}")
                    user = item.get("user")
                    correct_num = item.get("correct")
                    user_display = letters[user - 1] if isinstance(user, int) and 1 <= user <= 5 else "ì‘ë‹µ ì—†ìŒ"
                    correct_display = letters[correct_num - 1] if isinstance(correct_num, int) and 1 <= correct_num <= 5 else "?"
                else:
                    user_display = item.get("user") or "ì‘ë‹µ ì—†ìŒ"
                    correct_display = item.get("answer") or ""

                st.divider()
                st.write(f"**ë‹¹ì‹ ì˜ ë‹µ:** {user_display}")
                st.write(f"**ì •ë‹µ:** {correct_display}")
                if item.get("explanation"):
                    show_exp = st.checkbox("í•´ì„¤ ë³´ê¸°", value=st.session_state.explanation_default, key=f"hist_exp_{sel_idx}_{i}")
                    if show_exp:
                        st.markdown(format_explanation_text(item.get("explanation")))
                if item.get("id"):
                    note_key = f"hist_note_{sel_idx}_{i}"
                    st.text_area("ë©”ëª¨", value=item.get("note", ""), key=note_key, height=80)
                    if st.button("ë©”ëª¨ ì €ì¥", key=f"save_hist_note_{sel_idx}_{i}"):
                        saved = update_question_note(item["id"], st.session_state.get(note_key, ""))
                        if saved:
                            st.success("ë©”ëª¨ ì €ì¥ë¨")

    with st.expander("ğŸ§¹ ë°ì´í„° ê´€ë¦¬", expanded=False):
        st.caption("ì£¼ì˜: ì‚­ì œ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        confirm = st.checkbox("ì‚­ì œ ì‘ì—…ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤.")
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("ê°ê´€ì‹ ì „ì²´ ì‚­ì œ", use_container_width=True, disabled=not confirm):
                with st.spinner("ê°ê´€ì‹ ë¬¸í•­ ì‚­ì œ ì¤‘..."):
                    clear_question_bank(mode="mcq")
                st.session_state.last_action_notice = "ê°ê´€ì‹ ë¬¸í•­ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤."
                st.session_state.exam_started = False
                st.session_state.exam_questions = []
                st.session_state.user_answers = {}
                st.rerun()
        with col2:
            if st.button("ë¹ˆì¹¸ ì „ì²´ ì‚­ì œ", use_container_width=True, disabled=not confirm):
                with st.spinner("ë¹ˆì¹¸ ë¬¸í•­ ì‚­ì œ ì¤‘..."):
                    clear_question_bank(mode="cloze")
                st.session_state.last_action_notice = "ë¹ˆì¹¸ ë¬¸í•­ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤."
                st.session_state.exam_started = False
                st.session_state.exam_questions = []
                st.session_state.user_answers = {}
                st.rerun()
        with col3:
            if st.button("ì „ì²´ ë¬¸í•­ ì‚­ì œ", use_container_width=True, disabled=not confirm):
                with st.spinner("ì „ì²´ ë¬¸í•­ ì‚­ì œ ì¤‘..."):
                    clear_question_bank(mode="all")
                st.session_state.last_action_notice = "ëª¨ë“  ë¬¸í•­ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤."
                st.session_state.exam_started = False
                st.session_state.exam_questions = []
                st.session_state.user_answers = {}
                st.rerun()
        if st.button("ì‹œí—˜ ê¸°ë¡ ì‚­ì œ", use_container_width=True, disabled=not confirm):
            clear_exam_history()
            st.session_state.last_action_notice = "ì‹œí—˜ ê¸°ë¡ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤."
            st.rerun()

        st.markdown("---")
        subjects = sorted({(q.get("subject") or "General") for q in all_questions}) if all_questions else []
        sel_subjects_del = st.multiselect("ë¶„ê³¼ë³„ ì‚­ì œ", subjects)
        if sel_subjects_del:
            if st.button("ì„ íƒ ë¶„ê³¼ ì‚­ì œ", use_container_width=True, disabled=not confirm):
                data = load_questions()
                before_text = len(data.get("text", []))
                before_cloze = len(data.get("cloze", []))
                data["text"] = [q for q in data.get("text", []) if (q.get("subject") or "General") not in sel_subjects_del]
                data["cloze"] = [q for q in data.get("cloze", []) if (q.get("subject") or "General") not in sel_subjects_del]
                save_questions(data)
                deleted = (before_text - len(data.get("text", []))) + (before_cloze - len(data.get("cloze", [])))
                st.session_state.last_action_notice = f"{deleted}ê°œ ë¬¸í•­ ì‚­ì œë¨ (ë¶„ê³¼: {', '.join(sel_subjects_del)})"
                st.rerun()

    with st.expander("ğŸ—‘ï¸ ê°ê´€ì‹ ì„ íƒ ì‚­ì œ", expanded=False):
        bank_now = load_questions()
        mcq_list = bank_now.get("text", [])
        if not mcq_list:
            st.info("ê°ê´€ì‹ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.caption("ê°œë³„ ë¬¸í•­ì„ ì„ íƒí•´ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.markdown("---")
            subj = st.selectbox(
                "ë¶„ê³¼ í•„í„°",
                ["ì „ì²´"] + sorted({(q.get("subject") or "General") for q in mcq_list})
            )
            search = st.text_input("ë¬¸í•­ ê²€ìƒ‰", value="")
            filtered = []
            for q in mcq_list:
                if subj != "ì „ì²´" and (q.get("subject") or "General") != subj:
                    continue
                text = q.get("problem", "")
                if search and search.lower() not in text.lower():
                    continue
                filtered.append(q)
            filtered = filtered[:200]

            def _fallback_mcq_multiselect():
                id_to_q = {q.get("id"): q for q in filtered if q.get("id")}
                options = list(id_to_q.keys())

                def format_item(qid):
                    q = id_to_q.get(qid) or {}
                    subj_name = q.get("subject") or "General"
                    title = (q.get("problem") or "")[:80]
                    return f"{qid[:8]} | {subj_name} | {title}"

                selected_ids = st.multiselect("ê°œë³„ ë¬¸í•­ ì„ íƒ", options, format_func=format_item)
                return selected_ids

            selected_ids = []
            if hasattr(st, "data_editor"):
                rows = []
                for q in filtered:
                    qid = q.get("id")
                    if not qid:
                        continue
                    rows.append({
                        "ì„ íƒ": False,
                        "id": qid,
                        "ë¶„ê³¼": q.get("subject") or "General",
                        "ë¬¸í•­": (q.get("problem") or "")[:120],
                    })
                try:
                    edited = st.data_editor(
                        rows,
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "id": st.column_config.TextColumn("ID", width="small"),
                            "ë¶„ê³¼": st.column_config.TextColumn("ë¶„ê³¼", width="small"),
                            "ë¬¸í•­": st.column_config.TextColumn("ë¬¸í•­", width="large"),
                        },
                        disabled=["id", "ë¶„ê³¼", "ë¬¸í•­"],
                        key="mcq_delete_editor"
                    )
                    selected_ids = [r["id"] for r in edited if r.get("ì„ íƒ")]
                except Exception:
                    st.warning("ë°ì´í„° ì—ë””í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ëª©ë¡ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                    selected_ids = _fallback_mcq_multiselect()
            else:
                selected_ids = _fallback_mcq_multiselect()

            confirm_sel = st.checkbox("ê°œë³„ ì‚­ì œ í™•ì¸", key="confirm_item_delete")
            if selected_ids:
                if st.button("ì„ íƒ ë¬¸í•­ ì‚­ì œ", disabled=not confirm_sel):
                    deleted = delete_mcq_by_ids(selected_ids)
                    st.session_state.last_action_notice = f"{deleted}ê°œ ë¬¸í•­ ì‚­ì œë¨"
                    st.rerun()

            st.markdown("---")
            st.caption("ì„¸íŠ¸(ë°°ì¹˜) ë‹¨ìœ„ ì‚­ì œ")
            batches = get_mcq_batches(mcq_list)
            if batches:
                batch_labels = []
                for b, cnt in sorted(batches.items(), key=lambda x: x[0]):
                    batch_labels.append(f"{b} ({cnt}ê°œ)")
                sel_batch = st.selectbox("ì„¸íŠ¸ ì„ íƒ", ["ì„ íƒ ì—†ìŒ"] + batch_labels)
                confirm_batch = st.checkbox("ì„¸íŠ¸ ì‚­ì œ í™•ì¸", key="confirm_batch_delete")
                if sel_batch != "ì„ íƒ ì—†ìŒ":
                    batch_id = sel_batch.split(" (")[0]
                    if st.button("ì„¸íŠ¸ ì‚­ì œ", disabled=not confirm_batch):
                        deleted = delete_mcq_by_batch(batch_id)
                        st.session_state.last_action_notice = f"{deleted}ê°œ ë¬¸í•­ ì‚­ì œë¨ (ì„¸íŠ¸: {batch_id})"
                        st.rerun()
            else:
                st.caption("ì„¸íŠ¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with st.expander("ğŸ› ï¸ ë¬¸í•­ ê°œë³„ ìˆ˜ì •", expanded=False):
        bank_edit = load_questions()
        edit_type = st.radio(
            "ë¬¸í•­ ìœ í˜•",
            ["ê°ê´€ì‹", "ë¹ˆì¹¸"],
            horizontal=True,
            key="edit_question_type",
        )
        source = bank_edit["text"] if edit_type == "ê°ê´€ì‹" else bank_edit["cloze"]
        if not source:
            st.info("ìˆ˜ì • ê°€ëŠ¥í•œ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            subjects = sorted({(q.get("subject") or "General") for q in source})
            subject_filter = st.selectbox("ë¶„ê³¼ í•„í„°", ["ì „ì²´"] + subjects, key="edit_subject_filter")
            unit_filter = st.selectbox(
                "ë‹¨ì› í•„í„°",
                ["ì „ì²´"] + sorted({(q.get("unit") or "ë¯¸ë¶„ë¥˜") for q in source if (q.get("subject") or "General") == subject_filter or subject_filter == "ì „ì²´"}),
                key="edit_unit_filter"
            )
            keyword = st.text_input("ë¬¸í•­ ê²€ìƒ‰", value="", key="edit_keyword")

            candidates = []
            for q in source:
                if subject_filter != "ì „ì²´" and (q.get("subject") or "General") != subject_filter:
                    continue
                if unit_filter != "ì „ì²´" and (q.get("unit") or "ë¯¸ë¶„ë¥˜") != unit_filter:
                    continue
                text = q.get("problem") if edit_type == "ê°ê´€ì‹" else q.get("front", "")
                if keyword and keyword.lower() not in (text or "").lower():
                    continue
                candidates.append(q)

            if not candidates:
                st.info("í•„í„° ì¡°ê±´ì— ë§ëŠ” ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                id_to_q = {q.get("id"): q for q in candidates if q.get("id")}

                def _format_question(qid):
                    q = id_to_q.get(qid) or {}
                    stem = (q.get("problem") if edit_type == "ê°ê´€ì‹" else q.get("front", "")) or ""
                    return f"{qid[:8]} | {(q.get('subject') or 'General')} | {(q.get('unit') or 'ë¯¸ë¶„ë¥˜')} | {stem[:60]}"

                selected_id = st.selectbox(
                    "ìˆ˜ì •í•  ë¬¸í•­",
                    options=list(id_to_q.keys()),
                    format_func=_format_question,
                    key="selected_question_to_edit"
                )
                selected = id_to_q.get(selected_id)
                if selected:
                    st.markdown(f"**ë¬¸í•­ ID:** `{selected_id}`")
                    edited_subject = st.text_input("ê³¼ëª©", value=selected.get("subject") or "General", key=f"edit_subject_{selected_id}")
                    edited_unit = st.text_input("ë‹¨ì›", value=selected.get("unit") or "ë¯¸ë¶„ë¥˜", key=f"edit_unit_{selected_id}")
                    edited_difficulty = st.text_input("ë‚œì´ë„", value=selected.get("difficulty") or "", key=f"edit_difficulty_{selected_id}")
                    if edit_type == "ê°ê´€ì‹":
                        edited_problem = st.text_area("ë¬¸í•­", value=selected.get("problem", ""), height=180, key=f"edit_problem_{selected_id}")
                        edited_options_raw = st.text_area(
                            "ì„ ì§€ (ì¤„ë°”ê¿ˆ êµ¬ë¶„)",
                            value="\n".join(selected.get("options") or []),
                            height=160,
                            key=f"edit_options_{selected_id}"
                        )
                        edited_answer = st.number_input(
                            "ì •ë‹µ ë²ˆí˜¸(1~5)",
                            min_value=1,
                            max_value=max(1, len([l for l in (selected.get('options') or [])])),
                            value=int(selected.get("answer") or 1),
                            step=1,
                            key=f"edit_answer_{selected_id}"
                        )
                    else:
                        edited_problem = st.text_area("ë¬¸í•­", value=selected.get("front", ""), height=180, key=f"edit_front_{selected_id}")
                        edited_answer = st.text_area("ì •ë‹µ", value=selected.get("answer", ""), height=80, key=f"edit_answer_cloze_{selected_id}")
                    edited_explanation = st.text_area(
                        "í•´ì„¤",
                        value=selected.get("explanation", ""),
                        height=120,
                        key=f"edit_explanation_{selected_id}"
                    )
                    edited_note = st.text_area(
                        "ë©”ëª¨",
                        value=selected.get("note", ""),
                        height=80,
                        key=f"edit_note_{selected_id}"
                    )

                    if st.button("ë¬¸í•­ ìˆ˜ì • ì €ì¥", use_container_width=True, key="save_question_edit"):
                        patch = {
                            "subject": edited_subject,
                            "unit": edited_unit,
                            "difficulty": edited_difficulty,
                            "explanation": edited_explanation,
                            "note": edited_note
                        }
                        if edit_type == "ê°ê´€ì‹":
                            options_lines = [s.strip() for s in edited_options_raw.splitlines() if s.strip()]
                            patch["problem"] = edited_problem
                            patch["options"] = options_lines
                            patch["answer"] = int(edited_answer)
                        else:
                            patch["front"] = edited_problem
                            patch["answer"] = edited_answer
                        if update_question_by_id(selected_id, patch):
                            st.success("ë¬¸í•­ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()
                        else:
                            st.error("ë¬¸í•­ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("í•™ìŠµ ì‹œê°í™”")
    colv1, colv2 = st.columns([1, 1])
    with colv1:
        if st.button("í•™ìŠµ ì‹œê°í™” ë¶ˆëŸ¬ì˜¤ê¸°", key="load_home_visuals", use_container_width=True):
            st.session_state.home_visual_loaded = True
            st.rerun()
    with colv2:
        if st.session_state.home_visual_loaded:
            if st.button("í•™ìŠµ ì‹œê°í™” ìˆ¨ê¸°ê¸°", key="hide_home_visuals", use_container_width=True):
                st.session_state.home_visual_loaded = False
                st.rerun()

    if not st.session_state.home_visual_loaded:
        st.caption("ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ì‹œê°í™”ëŠ” ê¸°ë³¸ ìˆ¨ê¹€ ìƒíƒœì…ë‹ˆë‹¤. í•„ìš”í•  ë•Œë§Œ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")
    else:
        colp1, colp2, colp3 = st.columns([1, 1, 1])
        with colp1:
            st.session_state.profile_name = st.text_input(
                "ì„¤ì • í”„ë¦¬ì…‹ ì´ë¦„",
                value=st.session_state.profile_name,
                help="íˆíŠ¸ë§µ êµ¬ê°„/ìƒ‰ìƒ ë“± ê°œì¸ ì„¤ì •ì„ ì €ì¥í•´ë‘ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.",
            )
        with colp2:
            if st.button("í”„ë¦¬ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°"):
                profile_name = (st.session_state.profile_name or "").strip()
                loaded = apply_profile_settings(profile_name)
                st.session_state.last_action_notice = "í”„ë¡œí•„ ì„¤ì •ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤." if loaded else "í•´ë‹¹ í”„ë¡œí•„ì´ ì—†ìŠµë‹ˆë‹¤."
        with colp3:
            if st.button("í”„ë¦¬ì…‹ ì €ì¥"):
                profile_name = (st.session_state.profile_name or "").strip()
                if not profile_name:
                    profile_name = "default"
                    st.session_state.profile_name = profile_name
                persist_profile_settings(profile_name)
                st.session_state.last_action_notice = "í”„ë¡œí•„ ì„¤ì •ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤."

        st.caption("í”„ë¦¬ì…‹ì€ íˆíŠ¸ë§µ êµ¬ê°„/ìƒ‰ìƒ ë“± ê°œì¸ ì„¤ì •ì„ ì €ì¥í•´ë‘ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.")
        acc = compute_overall_accuracy(all_questions)
        heat = compute_activity_heatmap(all_questions, days=365)
        with st.expander("íˆíŠ¸ë§µ êµ¬ê°„/ìƒ‰ìƒ ì„¤ì •", expanded=False):
            st.caption("ë¬¸í•­ ìˆ˜ êµ¬ê°„ì„ ì¡°ì •í•˜ë©´ ìƒ‰ ë†ë„ê°€ ë°”ë€ë‹ˆë‹¤.")
            b1 = st.number_input("êµ¬ê°„ 1 (1íšŒ)", min_value=1, value=1)
            b2 = st.number_input("êµ¬ê°„ 2 (2~)", min_value=2, value=3)
            b3 = st.number_input("êµ¬ê°„ 3 (4~)", min_value=3, value=6)
            b4 = st.number_input("êµ¬ê°„ 4 (7~)", min_value=4, value=10)
            st.session_state.heatmap_bins = [0, b1, b2, b3, b4]
            st.session_state.heatmap_colors = [
                "#ffffff",
                st.color_picker("ìƒ‰ìƒ 1", value=st.session_state.heatmap_colors[1]),
                st.color_picker("ìƒ‰ìƒ 2", value=st.session_state.heatmap_colors[2]),
                st.color_picker("ìƒ‰ìƒ 3", value=st.session_state.heatmap_colors[3]),
                st.color_picker("ìƒ‰ìƒ 4", value=st.session_state.heatmap_colors[4]),
                st.color_picker("ìƒ‰ìƒ 5", value=st.session_state.heatmap_colors[5]),
            ]
        col_left, col_right = st.columns([1, 2])
        with col_left:
            st.markdown("**ì „ì²´ ì •ë‹µë¥ **")
            if acc:
                try:
                    import pandas as pd
                    import altair as alt

                    df = pd.DataFrame([
                        {"label": "Correct", "value": acc["correct"]},
                        {"label": "Wrong", "value": acc["wrong"]},
                    ])
                    base = alt.Chart(df).mark_arc(innerRadius=60, outerRadius=100).encode(
                        theta=alt.Theta("value:Q"),
                        color=alt.Color("label:N", scale=alt.Scale(range=["#34d399", "#f87171"]), legend=None),
                        tooltip=["label:N", "value:Q"]
                    )
                    text = alt.Chart(pd.DataFrame([{"text": f"{acc['accuracy']:.1f}%"}])).mark_text(
                        size=26, font="IBM Plex Sans", fontWeight="600"
                    ).encode(text="text:N")
                    st.altair_chart((base + text).properties(width=220, height=220), use_container_width=False)
                    st.caption(f"{acc['correct']}/{acc['total']} ì •ë‹µ")
                except Exception:
                    st.metric("ì „ì²´ ì •ë‹µë¥ ", f"{acc['accuracy']:.1f}%")
            else:
                st.info("ì•„ì§ í’€ì´ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

        with col_right:
            st.markdown("**í•™ìŠµ í™œë™ íˆíŠ¸ë§µ (ìµœê·¼ 365ì¼)**")
            if heat:
                try:
                    import pandas as pd
                    import altair as alt

                    df = pd.DataFrame(heat)
                    df["dow_label"] = df["dow"].map({0: "Mon", 1: "Tue", 2: "Wed", 3: "Thu", 4: "Fri", 5: "Sat", 6: "Sun"})
                    df["week_index"] = df["week_index"].astype(str)
                    b = st.session_state.heatmap_bins
                    labels = ["0", f"1-{b[1]}", f"{b[1] + 1}-{b[2]}", f"{b[2] + 1}-{b[3]}", f"{b[3] + 1}-{b[4]}", f"{b[4] + 1}+"]
                    df["bucket"] = pd.cut(
                        df["count"],
                        bins=[-0.1, 0, b[1], b[2], b[3], b[4], 9999],
                        labels=labels
                    )
                    heatmap = (
                        alt.Chart(df)
                        .mark_rect(cornerRadius=0)
                        .encode(
                            x=alt.X("week_index:O", axis=None),
                            y=alt.Y("dow_label:O", sort=["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"], axis=None),
                            color=alt.Color(
                                "bucket:N",
                                scale=alt.Scale(
                                    domain=labels,
                                    range=st.session_state.heatmap_colors
                                ),
                                legend=None
                            ),
                            tooltip=["date:T", "count:Q", "accuracy:Q"]
                        )
                        .properties(width=alt.Step(12), height=alt.Step(12))
                    )
                    st.altair_chart(heatmap, use_container_width=True)
                except Exception:
                    safe_dataframe(heat, use_container_width=True, hide_index=True)

if active_page == "admin" and admin_mode:
        st.title("ğŸ› ï¸ ìš´ì˜ì ì½˜ì†”")
        st.caption("ì‚¬ìš©ìë³„ API ì‚¬ìš©ëŸ‰, í˜¸ì¶œ ê±´ìˆ˜, ì¶”ì • ë¹„ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.")

        all_users = list_local_user_ids()
        if not all_users:
            st.info("ë¡œì»¬ ì‚¬ìš©ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            selected = st.selectbox("ëŒ€ìƒ ì‚¬ìš©ì", ["ì „ì²´"] + all_users, index=0, key="admin_user_filter")
            days = st.slider("ì¡°íšŒ ê¸°ê°„(ì¼)", 1, 365, 30, 1, key="admin_days_filter")
            cutoff = datetime.now(timezone.utc) - timedelta(days=days)

            rows = []
            target_users = all_users if selected == "ì „ì²´" else [selected]
            for uid in target_users:
                for row in read_audit_rows_for_user(uid):
                    ts_raw = str(row.get("timestamp") or "")
                    try:
                        ts = datetime.fromisoformat(ts_raw.replace("Z", "+00:00"))
                        if ts.tzinfo is None:
                            ts = ts.replace(tzinfo=timezone.utc)
                    except Exception:
                        continue
                    if ts < cutoff:
                        continue
                    enriched = dict(row)
                    enriched["user_id"] = uid
                    rows.append(enriched)

            if not rows:
                st.warning("ì„ íƒí•œ ì¡°ê±´ì—ì„œ ì¡°íšŒëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                summary = summarize_usage_rows(rows)
                total_est, breakdown = estimate_cost_usd_from_summary(summary)
                total_calls = sum(x.get("calls", 0) for x in summary.values())
                total_tokens = sum(x.get("tokens", 0) for x in summary.values())

                m1, m2, m3 = st.columns(3)
                m1.metric("ì´ API í˜¸ì¶œ", f"{total_calls:,}")
                m2.metric("ì´ í† í°", f"{total_tokens:,}")
                m3.metric("ì¶”ì • ë¹„ìš©(USD)", f"${total_est:.4f}")

                st.markdown("### ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰")
                safe_dataframe(breakdown, use_container_width=True, hide_index=True)

                st.markdown("### ìµœê·¼ ë¡œê·¸")
                latest = sorted(rows, key=lambda x: str(x.get("timestamp") or ""), reverse=True)[:50]
                latest_view = [
                    {
                        "timestamp": r.get("timestamp"),
                        "user_id": r.get("user_id"),
                        "event": r.get("event"),
                        "model": r.get("model"),
                        "usage_tokens": r.get("usage_tokens"),
                    }
                    for r in latest
                ]
                safe_dataframe(latest_view, use_container_width=True, hide_index=True)

# ============================================================================
# PAGE: ë¬¸ì œ ìƒì„±
# ============================================================================
if active_page == "generate":
    st.title("ğŸ“š ë¬¸ì œ ìƒì„± & ì €ì¥")

    st.subheader("âš¡ ë¹ ë¥¸ ì‹œì‘")
    st.markdown("### 3ë‹¨ê³„ë¡œ ì‹œì‘í•˜ê¸°")
    st.markdown("1) ìë£Œ ì—…ë¡œë“œ â†’ 2) ëª¨ë“œ/ë¬¸í•­ ìˆ˜ ì„¤ì • â†’ 3) ë¬¸ì œ ìƒì„± ì‹œì‘")
    st.markdown("API í‚¤ê°€ ì—†ë‹¤ë©´ ì‚¬ì´ë“œë°” ì…ë ¥ í›„ ë‹¤ì‹œ ì§„í–‰í•˜ì„¸ìš”.")

    ai_model_key_ready = bool(api_key) if ai_model == "ğŸ”µ Google Gemini" else bool(openai_api_key)
    if not ai_model_key_ready:
        st.warning("í˜„ì¬ AI ëª¨ë¸ í‚¤ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ë©´ ë°”ë¡œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader(
        "ê°•ì˜ ìë£Œ ì—…ë¡œë“œ",
        type=["pdf", "docx", "pptx", "hwp"],
        accept_multiple_files=True,
        key="gen_upload_files",
    )
    uploaded_file = uploaded_files[0] if uploaded_files else None
    style_file = st.file_uploader(
        "ê¸°ì¶œë¬¸ì œ ìŠ¤íƒ€ì¼ ì—…ë¡œë“œ (ì„ íƒ)",
        type=["pdf", "docx", "pptx", "hwp", "txt", "tsv", "json"],
        key="style_upload",
    )
    gen_copyright_ok = render_copyright_ack("gen")
    if (uploaded_files or style_file) and not gen_copyright_ok:
        st.warning("íŒŒì¼ ë¶„ì„/ë¬¸ì œ ìƒì„±ì„ ì‹œì‘í•˜ë ¤ë©´ ì €ì‘ê¶Œ í™•ì¸ ì²´í¬ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")

    mode = MODE_MCQ
    num_items = 10
    subject_input = "General"
    unit_input = "ë¯¸ë¶„ë¥˜"
    flavor_choice = "ì„ íƒí•˜ì„¸ìš”"
    mix_basic_ratio = 70

    raw_text_cached = None
    style_text = None
    uploaded_bytes = uploaded_file.getvalue() if uploaded_file else b""
    uploaded_signature = build_upload_signature(uploaded_file.name, uploaded_bytes) if uploaded_file else ""
    style_bytes = style_file.getvalue() if style_file else b""
    style_signature = build_upload_signature(style_file.name, style_bytes) if style_file else ""

    if uploaded_file and gen_copyright_ok:
        raw_text_cached = get_generation_prewarm_text("raw", uploaded_signature)
        raw_error = get_generation_prewarm_error("raw", uploaded_signature)
        if raw_text_cached is None and not raw_error:
            try:
                with st.spinner("ì‚¬ì „ ì¤€ë¹„ ì¤‘: ê°•ì˜ìë£Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"):
                    raw_text_cached = extract_text_from_file(
                        make_uploaded_file_from_bytes(uploaded_file.name, uploaded_bytes),
                        ai_model=ai_model,
                        ai_fallback=True,
                        api_key=api_key,
                        openai_api_key=openai_api_key,
                    )
                set_generation_prewarm_text("raw", uploaded_signature, raw_text_cached)
            except Exception as e:
                set_generation_prewarm_error("raw", uploaded_signature, str(e))
                raw_error = str(e)
        if raw_text_cached:
            est_chunks = len(split_text_into_chunks(raw_text_cached, chunk_size=chunk_size, overlap=overlap))
            st.caption(f"ì‚¬ì „ ì¤€ë¹„ ì™„ë£Œ(ì²« íŒŒì¼): ë³¸ë¬¸ {len(raw_text_cached):,}ì | ì˜ˆìƒ ì²­í¬ {est_chunks}ê°œ")
        elif raw_error:
            st.warning(f"ì‚¬ì „ ì¤€ë¹„ ì‹¤íŒ¨(ì²« íŒŒì¼): {raw_error}")

    if style_file and gen_copyright_ok:
        style_text = get_generation_prewarm_text("style", style_signature)
        style_error = get_generation_prewarm_error("style", style_signature)
        if style_text is None and not style_error:
            try:
                ext = Path(style_file.name).suffix.lower()
                if ext in [".txt", ".tsv", ".json"]:
                    style_text = style_bytes.decode("utf-8", errors="ignore")
                else:
                    style_text = extract_text_from_file(
                        make_uploaded_file_from_bytes(style_file.name, style_bytes)
                    )
                set_generation_prewarm_text("style", style_signature, style_text)
            except Exception as e:
                set_generation_prewarm_error("style", style_signature, str(e))
                style_error = str(e)
        if style_error:
            st.warning(f"ê¸°ì¶œë¬¸ì œ ìŠ¤íƒ€ì¼ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {style_error}")
    elif style_file and not gen_copyright_ok:
        st.caption("ê¶Œë¦¬ í™•ì¸ ì²´í¬ ì „ì—ëŠ” ìŠ¤íƒ€ì¼ íŒŒì¼ì„ ë¶„ì„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    if style_text:
        detected_mode, pattern = detect_term_language_mode(style_text)
        label = "í˜¼ìš©"
        if detected_mode == "ko":
            label = "í•œêµ­ì–´ ìš©ì–´ ì¤‘ì‹¬"
        elif detected_mode == "en":
            label = "ì˜ì–´ ìš©ì–´ ì¤‘ì‹¬"
        elif pattern:
            label = f"í˜¼ìš© ({pattern})"
        st.caption(f"ìŠ¤íƒ€ì¼ ìë™ ê°ì§€: ìš©ì–´ í‘œê¸° = {label}")

    runtime_context = get_generation_runtime_context() if ai_model_key_ready else {}

    if uploaded_files:
        if len(uploaded_files) == 1:
            st.info(f"ğŸ“„ **{uploaded_files[0].name}** ({uploaded_files[0].size:,} bytes)")
        else:
            st.info(f"ğŸ“„ ì„ íƒ íŒŒì¼: {len(uploaded_files)}ê°œ (ì²« íŒŒì¼: {uploaded_files[0].name})")

        st.markdown("### ì„¤ì •")
        col1, col2 = st.columns(2)
        with col1:
            mode = st.radio("ëª¨ë“œ", [MODE_MCQ, MODE_CLOZE, MODE_SHORT, MODE_ESSAY])
        with col2:
            num_items = st.slider("ìƒì„± ê°œìˆ˜", 1, 50, 10)

        flavor_choice = st.selectbox(
            "ë¬¸í•­ ì„±ê²©",
            ["ì„ íƒí•˜ì„¸ìš”", "ìë™ íŒë³„(Auto)", "ê¸°ì´ˆì˜í•™í˜•(Basic)", "ì¼€ì´ìŠ¤í˜•(Case)", "í˜¼í•©(Mix)"],
            index=0,
            key="generation_flavor_choice",
        )
        if flavor_choice == "í˜¼í•©(Mix)":
            st.caption("í˜¼í•© ë¹„ìœ¨: Basic 70% / Case 30%")

        col_subj, col_unit = st.columns(2)
        with col_subj:
            subject_input = st.text_input("ê³¼ëª©ëª… (ì˜ˆ: ìˆœí™˜ê¸°ë‚´ê³¼)", value="General")
        with col_unit:
            unit_input = st.text_input("ë‹¨ì›ëª… (ì„ íƒ)", value="ë¯¸ë¶„ë¥˜")
        if flavor_choice == "ìë™ íŒë³„(Auto)" and uploaded_file:
            preview_flavor = resolve_generation_flavor(
                flavor_choice,
                raw_text=raw_text_cached or "",
                style_text=style_text or "",
                subject=subject_input,
            )
            st.caption(f"ìë™ íŒë³„ ì˜ˆìƒ: `{preview_flavor}`")

        if gen_copyright_ok:
            col_p1, col_p2 = st.columns([1, 1])
            with col_p1:
                if uploaded_file and st.button("ì‚¬ì „ ì¤€ë¹„ ë‹¤ì‹œ ì‹¤í–‰(ì²« íŒŒì¼)", use_container_width=True, key="regen_prewarm_main"):
                    clear_generation_prewarm_error("raw", uploaded_signature)
                    cache_map = st.session_state.get("generation_prewarm_cache", {})
                    cache_key = _prewarm_cache_key("raw", uploaded_signature)
                    if cache_key in cache_map:
                        del cache_map[cache_key]
                    st.session_state["generation_prewarm_cache"] = cache_map
                    st.rerun()
            with col_p2:
                if style_file and st.button("ìŠ¤íƒ€ì¼ ì‚¬ì „ ì¤€ë¹„ ë‹¤ì‹œ ì‹¤í–‰", use_container_width=True, key="regen_prewarm_style"):
                    clear_generation_prewarm_error("style", style_signature)
                    cache_map = st.session_state.get("generation_prewarm_cache", {})
                    cache_key = _prewarm_cache_key("style", style_signature)
                    if cache_key in cache_map:
                        del cache_map[cache_key]
                    st.session_state["generation_prewarm_cache"] = cache_map
                    st.rerun()

        if not ai_model_key_ready:
            st.button("ğŸš€ ì—…ë¡œë“œ íŒŒì¼ë“¤ì„ ëŒ€ê¸°ì—´ì— ì¶”ê°€", use_container_width=True, disabled=True, help="API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif not gen_copyright_ok:
            st.button("ğŸš€ ì—…ë¡œë“œ íŒŒì¼ë“¤ì„ ëŒ€ê¸°ì—´ì— ì¶”ê°€", use_container_width=True, disabled=True, help="ì €ì‘ê¶Œ í™•ì¸ ì²´í¬ë¥¼ ì™„ë£Œí•´ ì£¼ì„¸ìš”.")
        elif flavor_choice == "ì„ íƒí•˜ì„¸ìš”":
            st.button("ğŸš€ ì—…ë¡œë“œ íŒŒì¼ë“¤ì„ ëŒ€ê¸°ì—´ì— ì¶”ê°€", use_container_width=True, disabled=True, help="ë¬¸í•­ ì„±ê²©ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        elif st.button("ğŸš€ ì—…ë¡œë“œ íŒŒì¼ë“¤ì„ ëŒ€ê¸°ì—´ì— ì¶”ê°€", use_container_width=True):
            try:
                queue_items = load_generation_queue_items()
                added = 0
                skipped = 0
                skipped_short = 0
                skipped_duplicate = 0

                style_text_for_queue = style_text
                if style_file and not style_text_for_queue:
                    ext = Path(style_file.name).suffix.lower()
                    if ext in [".txt", ".tsv", ".json"]:
                        style_text_for_queue = style_bytes.decode("utf-8", errors="ignore")
                    else:
                        style_text_for_queue = extract_text_from_file(
                            make_uploaded_file_from_bytes(style_file.name, style_bytes)
                        )
                    set_generation_prewarm_text("style", style_signature, style_text_for_queue)

                with st.spinner("ì—…ë¡œë“œ íŒŒì¼ì„ ëŒ€ê¸°ì—´ìš©ìœ¼ë¡œ ì¤€ë¹„ ì¤‘..."):
                    file_payloads = []
                    for uf in uploaded_files:
                        file_bytes = uf.getvalue()
                        file_sig = build_upload_signature(uf.name, file_bytes)
                        file_payloads.append((uf.name, file_sig, file_bytes))

                    extracted_texts = {}
                    pending = []
                    for file_name, file_sig, file_bytes in file_payloads:
                        raw_text = get_generation_prewarm_text("raw", file_sig)
                        if raw_text:
                            extracted_texts[file_sig] = raw_text
                        else:
                            pending.append((file_name, file_sig, file_bytes))

                    if pending:
                        with concurrent.futures.ThreadPoolExecutor(max_workers=min(4, len(pending))) as ex:
                            futures = {}
                            for file_name, file_sig, file_bytes in pending:
                                fut = ex.submit(
                                    extract_text_from_file,
                                    make_uploaded_file_from_bytes(file_name, file_bytes),
                                    ai_model=ai_model,
                                    ai_fallback=True,
                                    api_key=api_key,
                                    openai_api_key=openai_api_key,
                                )
                                futures[fut] = (file_name, file_sig)
                            for fut in concurrent.futures.as_completed(futures):
                                file_name, file_sig = futures[fut]
                                try:
                                    raw_text = fut.result()
                                    extracted_texts[file_sig] = raw_text
                                    set_generation_prewarm_text("raw", file_sig, raw_text)
                                except Exception as e:
                                    set_generation_prewarm_error("raw", file_sig, str(e))
                                    st.warning(f"{file_name}: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ({str(e)})")

                    for file_name, file_sig, _ in file_payloads:
                        raw_text = extracted_texts.get(file_sig) or get_generation_prewarm_text("raw", file_sig)
                        raw_text = (raw_text or "").strip()
                        if not raw_text:
                            skipped += 1
                            continue
                        if len(raw_text) < 20:
                            skipped += 1
                            skipped_short += 1
                            continue
                        resolved_flavor = resolve_generation_flavor(
                            flavor_choice,
                            raw_text=raw_text,
                            style_text=style_text_for_queue,
                            subject=subject_input,
                        )
                        if is_duplicate_generation_queue_item(
                            queue_items,
                            source_signature=file_sig,
                            flavor_choice=flavor_choice,
                            mode=mode,
                            num_items=num_items,
                            subject=subject_input,
                            unit=unit_input,
                        ):
                            skipped_duplicate += 1
                            continue
                        queue_items.append(
                            build_generation_queue_item(
                                source_name=file_name,
                                source_signature=file_sig,
                                raw_text=raw_text,
                                style_text=style_text_for_queue,
                                flavor_choice=flavor_choice,
                                resolved_flavor=resolved_flavor,
                                mix_basic_ratio=mix_basic_ratio,
                                mode=mode,
                                num_items=num_items,
                                subject=subject_input,
                                unit=unit_input,
                                ai_model=ai_model,
                                chunk_size=chunk_size,
                                overlap=overlap,
                                quality_filter=enable_filter,
                                min_length=min_length,
                            )
                        )
                        added += 1

                if added <= 0:
                    if skipped_short:
                        st.warning(f"ëŒ€ê¸°ì—´ì— ì¶”ê°€í•  í…ìŠ¤íŠ¸ ë¬¸ì„œëŠ” ì¶”ì¶œë˜ì—ˆì§€ë§Œ, ìœ íš¨ ë¶„ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. PDF(ê°•ì˜ë¡)ì€ AI í´ë°±ì„ ì¼œê³  ì¬ì‹œë„í•˜ì„¸ìš”. ê±´ë„ˆëœ€: {skipped}ê°œ")
                    else:
                        st.warning(
                            "ëŒ€ê¸°ì—´ì— ì¶”ê°€í•  í…ìŠ¤íŠ¸ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. "
                            f"(ë¶„ì„ íŒŒì¼ {len(uploaded_files)}ê°œ, ê±´ë„ˆëœ€ {skipped}ê°œ, ì¤‘ë³µ {skipped_duplicate}ê°œ)"
                        )
                elif not save_generation_queue_items(queue_items):
                    st.error("ëŒ€ê¸°ì—´ ì €ì¥ ì‹¤íŒ¨: ì‚¬ìš©ì ì„¤ì • ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                else:
                    queue_items, _ = start_next_generation_queue_job_if_idle(
                        queue_items,
                        api_key=api_key,
                        openai_api_key=openai_api_key,
                        runtime_context=runtime_context,
                    )
                    save_generation_queue_items(queue_items)
                    st.session_state.generation_failure = ""
                    msg = f"ëŒ€ê¸°ì—´ ì¶”ê°€ ì™„ë£Œ: {added}ê°œ"
                    if skipped:
                        msg += f" (ê±´ë„ˆëœ€ {skipped}ê°œ)"
                    if skipped_duplicate:
                        msg += f" (ì¤‘ë³µ ì œì™¸ {skipped_duplicate}ê°œ)"
                    st.session_state.last_action_notice = msg
                    st.rerun()
            except Exception as e:
                import traceback
                err_msg = f"âŒ ì˜¤ë¥˜: {str(e)}"
                st.error(err_msg)
                st.error(f"ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
                st.session_state.generation_failure = err_msg

    queue_items = load_generation_queue_items()
    queue_items, revived = revive_stale_running_queue_items(queue_items)
    queue_items, queue_notices = reconcile_generation_queue_with_async(
        queue_items,
        default_quality_filter=enable_filter,
        default_min_length=min_length,
    )
    for notice in queue_notices:
        st.success(notice)
    queue_items, auto_started = start_next_generation_queue_job_if_idle(
        queue_items,
        api_key=api_key,
        openai_api_key=openai_api_key,
        runtime_context=runtime_context,
    )
    if revived or queue_notices or auto_started:
        save_generation_queue_items(queue_items)
    if auto_started:
        st.rerun()

    st.markdown("### ğŸ§¾ ìƒì„± ëŒ€ê¸°ì—´")
    if not queue_items:
        st.info("í˜„ì¬ ëŒ€ê¸°ì—´ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        status_label = {
            "queued": "ëŒ€ê¸°",
            "running": "ìƒì„±ì¤‘",
            "done": "ì™„ë£Œ",
            "failed": "ì‹¤íŒ¨",
            "cancelled": "ì·¨ì†Œ",
        }
        for idx, item in enumerate(queue_items, 1):
            jid = str(item.get("id"))
            left, right = st.columns([4, 1])
            with left:
                st.markdown(
                    f"**{idx}. {item.get('source_name', 'unknown')}**  \n"
                    f"- ìƒíƒœ: `{status_label.get(item.get('status'), item.get('status'))}` | "
                    f"ë¬¸í•­ì„±ê²©: `{item.get('resolved_flavor') or item.get('flavor_choice') or '-'}` | "
                    f"ëª¨ë“œ: `{item.get('mode', '')}` | ë¬¸í•­ìˆ˜: `{item.get('num_items', 0)}` | "
                    f"ê³¼ëª©/ë‹¨ì›: `{item.get('subject', 'General')} / {item.get('unit', 'ë¯¸ë¶„ë¥˜')}`"
                )
                if item.get("status") == "done":
                    st.caption(f"ìë™ ì €ì¥: {int(item.get('saved_count', 0))}ê°œ")
                if item.get("status") in {"failed", "cancelled"} and item.get("error"):
                    st.caption(f"ì‚¬ìœ : {item.get('error')}")
            with right:
                if item.get("status") == "queued":
                    if st.button("ëŒ€ê¸° ì·¨ì†Œ", key=f"queue_cancel_{jid}", use_container_width=True):
                        changed, queue_items = remove_generation_queue_job(queue_items, jid)
                        if changed and save_generation_queue_items(queue_items):
                            st.rerun()
                elif item.get("status") == "running":
                    if st.button("ì‹¤í–‰ ì·¨ì†Œ", key=f"queue_stop_{jid}", use_container_width=True):
                        async_job = st.session_state.get("generation_async_job")
                        if isinstance(async_job, dict) and str(async_job.get("queue_id")) == jid:
                            future = async_job.get("future")
                            cancelled = False
                            if future is not None:
                                try:
                                    cancelled = future.cancel()
                                except Exception:
                                    cancelled = False
                            async_job["status"] = "cancelled" if cancelled else "error"
                            async_job["error"] = "ì‚¬ìš©ì ì·¨ì†Œ" if cancelled else "ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…ì€ ì·¨ì†Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            st.session_state["generation_async_job"] = async_job
                            st.rerun()
                else:
                    if st.button("ëª©ë¡ ì‚­ì œ", key=f"queue_remove_{jid}", use_container_width=True):
                        changed, queue_items = remove_generation_queue_job(queue_items, jid)
                        if changed and save_generation_queue_items(queue_items):
                            st.rerun()
        if st.button("ì™„ë£Œ/ì·¨ì†Œ/ì‹¤íŒ¨ í•­ëª© ì •ë¦¬", key="queue_prune_finished", use_container_width=True):
            before = len(queue_items)
            queue_items = [x for x in queue_items if x.get("status") in {"queued", "running"}]
            if len(queue_items) != before and save_generation_queue_items(queue_items):
                st.rerun()

    st.markdown("---")
    st.info("ê¸°ì¶œë¬¸ì œ íŒŒì¼ ë³€í™˜ì€ **ğŸ§¾ ê¸°ì¶œë¬¸ì œ ë³€í™˜** íƒ­ì—ì„œ ì§„í–‰í•©ë‹ˆë‹¤.")

# ============================================================================
# PAGE: ê¸°ì¶œë¬¸ì œ ë³€í™˜
# ============================================================================
if active_page == "convert":
    st.title("ğŸ§¾ ê¸°ì¶œë¬¸ì œ ì „ìš© ë³€í™˜")
    st.caption("HWP/PDF/DOCX/PPTX/TXT/TSV íŒŒì¼ì„ ê¸°ì¶œë¬¸ì œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.")
    convert_copyright_ok = render_copyright_ack("convert")
    if not convert_copyright_ok:
        st.warning("ì €ì‘ê¶Œ í™•ì¸ ì²´í¬ë¥¼ ì™„ë£Œí•´ì•¼ íŒŒì¼ ë³€í™˜ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    with st.expander("ğŸ§© HWP+PDF ë“€ì–¼ ì—…ë¡œë“œ(ìˆ˜ë™ ìµœì†Œí™”)", expanded=False):
        st.caption("HWPì—ì„œ ë¬¸í•­ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ , PDFì—ì„œ ì´ë¯¸ì§€/í˜ì´ì§€ ì •ë³´ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.")
        col_dual1, col_dual2 = st.columns(2)
        with col_dual1:
            dual_hwp = st.file_uploader("HWP ì—…ë¡œë“œ (ë¬¸í•­ í…ìŠ¤íŠ¸)", type=["hwp"], key="dual_hwp_upload")
        with col_dual2:
            dual_pdf = st.file_uploader("PDF ì—…ë¡œë“œ (ì´ë¯¸ì§€/ë ˆì´ì•„ì›ƒ)", type=["pdf"], key="dual_pdf_upload")

        dual_subject = st.text_input("ê¸°ë³¸ ê³¼ëª©ëª…", value="General", key="dual_subject")
        dual_unit = st.text_input("ê¸°ë³¸ ë‹¨ì›ëª… (ì„ íƒ)", value="DualUpload", key="dual_unit")

        dual_threshold = st.slider("ìë™ ë§¤ì¹­ ì‹ ë¢°ë„ ê¸°ì¤€", 0.05, 0.6, 0.2, step=0.05, key="dual_threshold")

        if st.button("ğŸ”— ë“€ì–¼ ìë™ ë§¤ì¹­ ì‹¤í–‰", use_container_width=True, key="dual_run", disabled=not convert_copyright_ok):
            if not dual_hwp or not dual_pdf:
                st.error("HWPì™€ PDFë¥¼ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            else:
                try:
                    dual_hwp.seek(0)
                    dual_pdf.seek(0)
                    hwp_text = extract_text_from_hwp(dual_hwp)
                    pdf_bytes = dual_pdf.getvalue()
                    page_texts = extract_pdf_page_texts(pdf_bytes)
                    images = extract_images_from_pdf_bytes(pdf_bytes)
                    anchors = extract_pdf_question_anchors(pdf_bytes)

                    # 1) HWP í…ìŠ¤íŠ¸ë¡œ ë¬¸í•­ íŒŒì‹±
                    items = parse_exam_text_fuzzy(hwp_text)
                    items = clean_parsed_items(items)

                    # 2) ë¬¸í•­-í˜ì´ì§€ ë§¤ì¹­
                    scores = match_questions_to_pages(items, page_texts)

                    # 3) ì´ë¯¸ì§€ ì—°ê²° (í˜ì´ì§€ ê¸°ë°˜)
                    items = auto_attach_images_to_items(
                        items,
                        images,
                        strategy="page",
                        max_per_question=1,
                        anchors=anchors,
                        min_score=0.2,
                        only_if_keyword=False
                    )

                    st.session_state.past_exam_items = items
                    st.session_state.past_exam_images = images
                    st.session_state.past_exam_anchors = anchors
                    st.session_state.dual_exam_text = hwp_text
                    st.session_state.dual_exam_images = images
                    st.session_state.dual_exam_page_text = page_texts
                    st.session_state.dual_match_scores = scores

                    st.success(f"ë“€ì–¼ ë§¤ì¹­ ì™„ë£Œ: {len(items)}ê°œ ë¬¸í•­")
                    st.rerun()
                except Exception as e:
                    st.error(f"ë“€ì–¼ ë§¤ì¹­ ì‹¤íŒ¨: {str(e)}")

        if st.session_state.dual_match_scores:
            weak = [i for i, v in st.session_state.dual_match_scores.items() if v.get("score", 0) < dual_threshold]
            st.caption(f"ìë™ ë§¤ì¹­ ì‹ ë¢°ë„ ë‚®ìŒ: {len(weak)}ê°œ ë¬¸í•­ â†’ ì•„ë˜ í¸ì§‘ íƒ­ì—ì„œ ìˆ˜ë™ ë³´ì •í•˜ì„¸ìš”.")

        if st.button("ğŸ“ HWP í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ", use_container_width=True, key="dual_text_only", disabled=not convert_copyright_ok):
            if not dual_hwp:
                st.error("HWP íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            else:
                try:
                    dual_hwp.seek(0)
                    hwp_text = extract_text_from_hwp(dual_hwp)
                    hwp_text = preclean_exam_text(hwp_text)
                    items = parse_exam_text_fuzzy(hwp_text)
                    items = clean_parsed_items(items)
                    st.session_state.past_exam_items = items
                    st.session_state.past_exam_images = []
                    st.session_state.past_exam_anchors = {}
                    st.session_state.dual_exam_text = hwp_text
                    st.success(f"HWP í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(items)}ê°œ ë¬¸í•­")
                    st.rerun()
                except Exception as e:
                    st.error(f"HWP í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

    uploaded_exam = st.file_uploader(
        "ê¸°ì¶œë¬¸ì œ íŒŒì¼ ì—…ë¡œë“œ",
        type=["hwp", "pdf", "docx", "pptx", "txt", "tsv"],
        key="past_exam_upload"
    )

    if uploaded_exam and not convert_copyright_ok:
        st.warning("ì €ì‘ê¶Œ í™•ì¸ ì²´í¬ë¥¼ ì™„ë£Œí•˜ë©´ ì—…ë¡œë“œ íŒŒì¼ì„ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    elif uploaded_exam:
        file_ext = Path(uploaded_exam.name).suffix.lower()
        ocr_enabled = True
        ocr_engine = "auto"
        ocr_langs = ("ko", "en")
        ocr_max_pages = 0
        uploaded_bytes = uploaded_exam.getvalue()

        if file_ext == ".pdf":
            with st.expander("ğŸ§  OCR ì„¤ì • (ìŠ¤ìº” PDFìš©)", expanded=False):
                ocr_enabled = st.checkbox(
                    "í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•˜ë©´ OCR ìë™ ì‹¤í–‰",
                    value=True,
                    key="past_exam_ocr_enable"
                )
                ocr_engine = st.selectbox(
                    "OCR ì—”ì§„",
                    ["auto", "easyocr"],
                    index=0,
                    key="past_exam_ocr_engine"
                )
                lang_choice = st.selectbox(
                    "ì–¸ì–´",
                    ["í•œêµ­ì–´+ì˜ì–´", "ì˜ì–´"],
                    index=0,
                    key="past_exam_ocr_lang"
                )
                ocr_langs = ("ko", "en") if lang_choice == "í•œêµ­ì–´+ì˜ì–´" else ("en",)
                ocr_max_pages = st.number_input(
                    "OCR í˜ì´ì§€ ì œí•œ (0=ì „ì²´)",
                    min_value=0,
                    max_value=500,
                    value=0,
                    step=1,
                    key="past_exam_ocr_pages"
                )

        if st.session_state.past_exam_file != uploaded_exam.name:
            st.session_state.past_exam_file = uploaded_exam.name
            st.session_state.past_exam_text = ""
            st.session_state.past_exam_items = []
            st.session_state.past_exam_images = []
            st.session_state.past_exam_anchors = {}
            st.session_state.ai_parse_raw = ""

        if not st.session_state.past_exam_text:
            try:
                if hasattr(uploaded_exam, "seek"):
                    uploaded_exam.seek(0)
                st.session_state.past_exam_text = extract_text_from_file(
                    uploaded_exam,
                    enable_ocr=ocr_enabled,
                    ocr_engine=ocr_engine,
                    ocr_langs=ocr_langs,
                    ocr_max_pages=ocr_max_pages,
                    include_page_markers=(file_ext == ".pdf")
                )
            except Exception as e:
                st.error(f"âŒ ê¸°ì¶œë¬¸ì œ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

        if not st.session_state.past_exam_images and uploaded_bytes:
            try:
                if file_ext == ".pdf":
                    st.session_state.past_exam_images = extract_images_from_pdf_bytes(uploaded_bytes)
                    st.session_state.past_exam_anchors = extract_pdf_question_anchors(uploaded_bytes)
                elif file_ext == ".hwp":
                    st.session_state.past_exam_images = extract_images_from_hwp_bytes(uploaded_bytes)
            except Exception:
                st.session_state.past_exam_images = []

        if file_ext == ".pdf":
            engines = available_ocr_engines()
            if len(st.session_state.past_exam_text.strip()) < 200 and not engines:
                st.warning("PDFì—ì„œ í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OCRì´ í•„ìš”í•©ë‹ˆë‹¤. `python -m pip install easyocr` ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            if st.button("ğŸ” ì›ë¬¸ ë‹¤ì‹œ ì¶”ì¶œ", use_container_width=True, key="past_exam_reextract"):
                try:
                    if hasattr(uploaded_exam, "seek"):
                        uploaded_exam.seek(0)
                    st.session_state.past_exam_text = extract_text_from_file(
                        uploaded_exam,
                        enable_ocr=ocr_enabled,
                        ocr_engine=ocr_engine,
                        ocr_langs=ocr_langs,
                        ocr_max_pages=ocr_max_pages,
                        include_page_markers=True
                    )
                    st.session_state.past_exam_items = []
                    st.session_state.past_exam_images = extract_images_from_pdf_bytes(uploaded_bytes)
                    st.session_state.past_exam_anchors = extract_pdf_question_anchors(uploaded_bytes)
                except Exception as e:
                    st.error(f"âŒ ì›ë¬¸ ì¬ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

        col1, col2 = st.columns(2)
        with col1:
            exam_subject = st.text_input("ê¸°ë³¸ ê³¼ëª©ëª…", value="General", key="past_exam_subject")
        with col2:
            default_unit = Path(uploaded_exam.name).stem[:50] if uploaded_exam else "ë¯¸ë¶„ë¥˜"
            exam_unit = st.text_input("ê¸°ë³¸ ë‹¨ì›ëª… (ì„ íƒ)", value=default_unit, key="past_exam_unit")

        parse_mode = st.radio(
            "ë³€í™˜ ë°©ì‹",
            ["ìë™(ê¸°ì¶œ íŒŒì„œ)", "Cloze(ì •ë‹µ: ê¸°ë°˜)", "ê°ê´€ì‹(ì„ ì§€ ê¸°ì¤€)"],
            horizontal=True,
            key="past_exam_mode"
        )

        st.markdown("**ì´ë¯¸ì§€ ìë™ ì—°ê²°**")
        auto_attach = st.checkbox("ë¬¸í•­ì— ì´ë¯¸ì§€ ìë™ ì—°ê²°", value=True, key="auto_attach_images")
        max_imgs = st.slider("ë¬¸í•­ë‹¹ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜", 0, 3, 1, key="auto_attach_max_images")
        only_attach_keyword = st.checkbox("ì´ë¯¸ì§€ í‚¤ì›Œë“œê°€ ìˆëŠ” ë¬¸í•­ë§Œ ì—°ê²°", value=True, key="auto_attach_keyword_only")

        if file_ext == ".pdf":
            attach_label = st.selectbox(
                "ìë™ ì—°ê²° ë°©ì‹",
                ["ë ˆì´ì•„ì›ƒ ê¸°ë°˜(ê¶Œì¥)", "OCR ê¸°ë°˜(í…ìŠ¤íŠ¸ í¬í•¨ ì´ë¯¸ì§€)", "í˜ì´ì§€ ê¸°ë°˜"],
                index=0,
                key="auto_attach_mode"
            )
            if attach_label.startswith("OCR"):
                attach_strategy = "ocr"
                ocr_img_limit = st.slider("OCR ì´ë¯¸ì§€ ê°œìˆ˜ ì œí•œ", 5, 80, 20, key="ocr_img_limit")
                ocr_min_score = st.slider("ë§¤ì¹­ ê¸°ì¤€(0~1)", 0.05, 0.6, 0.2, step=0.05, key="ocr_min_score")
            elif attach_label.startswith("í˜ì´ì§€"):
                attach_strategy = "page"
            else:
                attach_strategy = "layout" if st.session_state.past_exam_anchors else "page"
            use_ai_match = st.checkbox("AI ì´ë¯¸ì§€ ë§¤ì¹­(ë³´ì •)", value=False, key="ai_match_images")
            ai_match_limit = st.slider("AI ë§¤ì¹­ ì´ë¯¸ì§€ ìˆ˜", 1, 30, 8, key="ai_match_limit")
        else:
            attach_strategy = "sequential"

        st.text_area(
            "ì¶”ì¶œëœ ì›ë¬¸ (í•„ìš”ì‹œ ìˆ˜ì • ê°€ëŠ¥)",
            value=st.session_state.past_exam_text,
            height=240,
            key="past_exam_text_area"
        )

        with st.expander("ğŸ¤– AI íŒŒì„œ (ë¬¸í•­ ë¶„ë¦¬/ì •ì œ)", expanded=False):
            st.caption("ê²¹ì³ì§„ ë¬¸í•­ì„ ë¶„ë¦¬í•˜ê±°ë‚˜ ì£¼ê´€ì‹ ë¬¸í•­ì„ êµ¬ì¡°í™”í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            ai_parse_limit = st.slider("ìµœëŒ€ ë¬¸í•­ ìˆ˜", 10, 200, 60, step=10, key="ai_parse_limit")
            parse_mode_ai = st.radio("AI íŒŒì„œ ë°©ì‹", ["ì „ì²´ í…ìŠ¤íŠ¸", "ë¸”ë¡ ë¶„í• "], horizontal=True, key="ai_parse_mode")
            hint_text = st.text_area(
                "ë¬¸ì„œ êµ¬ì¡° íŒíŠ¸ (ì„ íƒ)",
                value="",
                placeholder="ì˜ˆ: 2ì—´ í‘œ â†’ ì¢Œì¸¡ ë¬¸í•­, ìš°ì¸¡ ì •ë‹µ/í•´ì„¤. 1ì—´ í‘œ â†’ ë¬¸í•­â†’ì •ë‹µâ†’í•´ì„¤ ìˆœì„œ.",
                key="ai_parse_hint"
            )
            if file_ext == ".pdf":
                st.caption("PDF ë ˆì´ì•„ì›ƒ íŒŒì„œëŠ” 2ì—´(ì¢Œ:ë¬¸í•­/ìš°:ì •ë‹µÂ·í•´ì„¤) ë˜ëŠ” 1ì—´ êµ¬ì¡°ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                use_ai_layout = st.checkbox(
                    "AIë¡œ ë ˆì´ì•„ì›ƒ íŒŒì„œ ì‹¤í–‰(ì¶”ì²œ)",
                    value=True,
                    key="use_ai_layout_parser"
                )
                if st.button("ğŸ“ PDF ë ˆì´ì•„ì›ƒ íŒŒì„œ ì‹¤í–‰", use_container_width=True, key="layout_parse_run"):
                    with st.spinner("PDF ë ˆì´ì•„ì›ƒ ë¶„ì„ ì¤‘..."):
                        layout_items = []
                        if use_ai_layout:
                            if st.session_state.ai_model == "ğŸ”µ Google Gemini" and not api_key:
                                st.error("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            elif st.session_state.ai_model == "ğŸŸ¢ OpenAI ChatGPT" and not openai_api_key:
                                st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            else:
                                layout_items = parse_pdf_layout_ai(
                                    uploaded_bytes,
                                    ai_model=st.session_state.ai_model,
                                    api_key=api_key,
                                    openai_api_key=openai_api_key,
                                    hint_text=hint_text
                                )
                        if not layout_items:
                            layout_items = parse_pdf_layout(uploaded_bytes)
                        if layout_items:
                            if auto_attach and st.session_state.past_exam_images:
                                layout_items = auto_attach_images_to_items(
                                    layout_items,
                                    st.session_state.past_exam_images,
                                    strategy=attach_strategy,
                                    max_per_question=max_imgs,
                                    anchors=st.session_state.past_exam_anchors,
                                    min_score=st.session_state.get("ocr_min_score", 0.2),
                                    only_if_keyword=only_attach_keyword
                                )
                            if st.session_state.get("ai_match_images") and st.session_state.past_exam_images:
                                layout_items = ai_match_images_to_items(
                                    layout_items,
                                    st.session_state.past_exam_images,
                                    ai_model=st.session_state.get("ai_model", "ğŸ”µ Google Gemini"),
                                    api_key=api_key,
                                    openai_api_key=openai_api_key,
                                    max_images=st.session_state.get("ai_match_limit", 8)
                                )
                            st.session_state.past_exam_items = layout_items
                            st.success(f"ë ˆì´ì•„ì›ƒ íŒŒì„œ ì™„ë£Œ: {len(layout_items)}ê°œ ë¬¸í•­")
                            st.rerun()
                        else:
                            st.warning("ë ˆì´ì•„ì›ƒ íŒŒì„œ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. OCR í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ AI íŒŒì„œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
            if parse_mode_ai == "ë¸”ë¡ ë¶„í• ":
                block_limit = st.slider("ë¸”ë¡ ì²˜ë¦¬ ê°œìˆ˜", 5, 200, 50, step=5, key="ai_block_limit")
            if st.button("AI íŒŒì„œë¡œ ì¬ë¶„í• ", use_container_width=True, key="ai_parse_run"):
                if st.session_state.ai_model == "ğŸ”µ Google Gemini" and not api_key:
                    st.error("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                elif st.session_state.ai_model == "ğŸŸ¢ OpenAI ChatGPT" and not openai_api_key:
                    st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("AI íŒŒì„œ ì‹¤í–‰ ì¤‘..."):
                        source_text = st.session_state.get("past_exam_text_area", "")
                        if parse_mode_ai == "ë¸”ë¡ ë¶„í• ":
                            blocks = split_exam_blocks(source_text)
                            ai_items = []
                            raw_chunks = []
                            for block in blocks[:block_limit]:
                                item, raw = ai_parse_exam_block(
                                    block,
                                    ai_model=st.session_state.ai_model,
                                    api_key=api_key,
                                    openai_api_key=openai_api_key,
                                    hint_text=hint_text,
                                    return_raw=True
                                )
                                if raw:
                                    raw_chunks.append(raw)
                                if item:
                                    ai_items.append(item)
                            ai_items = clean_parsed_items(ai_items)
                            st.session_state.ai_parse_raw = "\n\n---\n\n".join(raw_chunks)
                        else:
                            ai_items, raw = ai_parse_exam_text(
                                source_text,
                                ai_model=st.session_state.ai_model,
                                api_key=api_key,
                                openai_api_key=openai_api_key,
                                max_items=ai_parse_limit,
                                hint_text=hint_text,
                                return_raw=True
                            )
                            st.session_state.ai_parse_raw = raw
                        if ai_items:
                            if auto_attach and st.session_state.past_exam_images:
                                ai_items = auto_attach_images_to_items(
                                    ai_items,
                                    st.session_state.past_exam_images,
                                    strategy=attach_strategy,
                                    max_per_question=max_imgs,
                                    anchors=st.session_state.past_exam_anchors,
                                    min_score=st.session_state.get("ocr_min_score", 0.2)
                                )
                            st.session_state.past_exam_items = ai_items
                            st.success(f"AI íŒŒì„œ ì™„ë£Œ: {len(ai_items)}ê°œ ë¬¸í•­")
                            st.rerun()
                        else:
                            st.warning("AI íŒŒì„œ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡° íŒíŠ¸ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ê±°ë‚˜, ë¸”ë¡ ë¶„í•  ëª¨ë“œë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
                            raw = st.session_state.get("ai_parse_raw", "")
                            if raw:
                                with st.expander("AI íŒŒì„œ ì›ë¬¸ ê²°ê³¼(ë””ë²„ê·¸)", expanded=False):
                                    st.code(raw[:6000])

        if st.session_state.past_exam_images:
            with st.expander("ğŸ–¼ï¸ ì¶”ì¶œëœ ì´ë¯¸ì§€", expanded=False):
                st.caption(f"ì´ {len(st.session_state.past_exam_images)}ê°œ ì´ë¯¸ì§€")
                cols = st.columns(4)
                for i, img in enumerate(st.session_state.past_exam_images):
                    with cols[i % 4]:
                        st.image(img.get("data_uri"), caption=f"#{i + 1}")

        if st.button("ğŸ” ë³€í™˜ ë¯¸ë¦¬ë³´ê¸°", use_container_width=True, key="past_exam_preview"):
            source_text = st.session_state.get("past_exam_text_area", "").strip()
            if not source_text:
                st.error("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            else:
                if parse_mode == "Cloze(ì •ë‹µ: ê¸°ë°˜)":
                    items = parse_qa_to_cloze(source_text)
                    if not items:
                        items = parse_generated_text_to_structured(source_text, "ğŸ§© ë¹ˆì¹¸ ëš«ê¸° (Anki Cloze)")
                elif parse_mode == "ê°ê´€ì‹(ì„ ì§€ ê¸°ì¤€)":
                    if file_ext == ".pdf":
                        use_ai_layout = st.session_state.get("use_ai_layout_parser", True)
                        if use_ai_layout and ((st.session_state.ai_model == "ğŸ”µ Google Gemini" and api_key) or (st.session_state.ai_model == "ğŸŸ¢ OpenAI ChatGPT" and openai_api_key)):
                            items = [i for i in parse_pdf_layout_ai(
                                uploaded_bytes,
                                ai_model=st.session_state.ai_model,
                                api_key=api_key,
                                openai_api_key=openai_api_key,
                                hint_text=st.session_state.get("ai_parse_hint", "")
                            ) if i.get("type") == "mcq"]
                        else:
                            items = [i for i in parse_pdf_layout(uploaded_bytes) if i.get("type") == "mcq"]
                    else:
                        items = [i for i in parse_exam_text_fuzzy(source_text) if i.get("type") == "mcq"]
                    if not items:
                        items = parse_generated_text_to_structured(source_text, "ğŸ“ ê°ê´€ì‹ ë¬¸ì œ (Case Study)")
                else:
                    if file_ext == ".pdf":
                        use_ai_layout = st.session_state.get("use_ai_layout_parser", True)
                        if use_ai_layout and ((st.session_state.ai_model == "ğŸ”µ Google Gemini" and api_key) or (st.session_state.ai_model == "ğŸŸ¢ OpenAI ChatGPT" and openai_api_key)):
                            items = parse_pdf_layout_ai(
                                uploaded_bytes,
                                ai_model=st.session_state.ai_model,
                                api_key=api_key,
                                openai_api_key=openai_api_key,
                                hint_text=st.session_state.get("ai_parse_hint", "")
                            )
                        else:
                            items = parse_pdf_layout(uploaded_bytes)
                    else:
                        items = parse_exam_text_fuzzy(source_text)
                    if not items:
                        items = parse_exam_text_fuzzy(source_text)
                    if not items:
                        items = parse_generated_text_to_structured(source_text, "ğŸ“ ê°ê´€ì‹ ë¬¸ì œ (Case Study)")
                        if not items:
                            items = parse_qa_to_cloze(source_text)
                if items and auto_attach and st.session_state.past_exam_images:
                    if attach_strategy == "ocr":
                        st.session_state.past_exam_images = ocr_images_for_matching(
                            st.session_state.past_exam_images,
                            engine="easyocr",
                            langs=("ko", "en"),
                            max_images=st.session_state.get("ocr_img_limit", 20)
                        )
                    items = auto_attach_images_to_items(
                        items,
                        st.session_state.past_exam_images,
                        strategy=attach_strategy,
                        max_per_question=max_imgs,
                        anchors=st.session_state.past_exam_anchors,
                        min_score=st.session_state.get("ocr_min_score", 0.2),
                        only_if_keyword=only_attach_keyword
                    )
                if items and st.session_state.get("ai_match_images") and st.session_state.past_exam_images:
                    if st.session_state.ai_model == "ğŸ”µ Google Gemini" and not api_key:
                        st.error("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    elif st.session_state.ai_model == "ğŸŸ¢ OpenAI ChatGPT" and not openai_api_key:
                        st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    else:
                        items = ai_match_images_to_items(
                            items,
                            st.session_state.past_exam_images,
                            ai_model=st.session_state.get("ai_model", "ğŸ”µ Google Gemini"),
                            api_key=api_key,
                            openai_api_key=openai_api_key,
                            max_images=st.session_state.get("ai_match_limit", 8)
                        )
                st.session_state.past_exam_items = items if items else []

        items = st.session_state.get("past_exam_items", [])
        if items:
            st.success(f"âœ… ë³€í™˜ëœ ë¬¸í•­: {len(items)}ê°œ")
            with st.expander("ğŸ“‹ ë³€í™˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ)", expanded=True):
                for i, item_data in enumerate(items[:5], 1):
                    if item_data.get("type") == "mcq":
                        st.markdown(f"**ë¬¸ì œ {i}** (ê°ê´€ì‹)")
                        st.write(f"**ë¬¸í•­:** {item_data.get('problem', '')[:150]}...")
                        st.write(f"**ì„ ì§€:** {', '.join(item_data.get('options', [])[:3])}...")
                        st.write(f"**ì •ë‹µ:** {item_data.get('answer', '?')} ë²ˆ")
                    else:
                        st.markdown(f"**ë¬¸ì œ {i}** (ë¹ˆì¹¸)")
                        st.write(f"**ë‚´ìš©:** {item_data.get('front', '')[:150]}...")
                        st.write(f"**ì •ë‹µ:** {item_data.get('answer', '?')}")
                    st.divider()

            with st.expander("ğŸ› ï¸ ë¬¸í•­ í¸ì§‘", expanded=False):
                total_items = len(items)
                if total_items > 0:
                    start_idx = st.number_input("ì‹œì‘ ë¬¸í•­", min_value=1, max_value=total_items, value=1, step=1, key="edit_start_idx")
                    end_idx = st.number_input("ë ë¬¸í•­", min_value=start_idx, max_value=total_items, value=min(start_idx + 9, total_items), step=1, key="edit_end_idx")
                    image_options = list(range(len(st.session_state.past_exam_images)))

                    def image_label(i):
                        img = st.session_state.past_exam_images[i]
                        page = img.get("page")
                        return f"#{i + 1} | p{page}" if page else f"#{i + 1}"

                    for i in range(start_idx - 1, end_idx):
                        item = items[i]
                        with st.container():
                            qnum_label = f"q{item.get('qnum')}" if item.get("qnum") else "q?"
                            page_label = f"p{item.get('page')}" if item.get("page") else "p?"
                            st.markdown(f"#### ë¬¸í•­ {i + 1} í¸ì§‘ ({item.get('type')}) Â· {qnum_label} Â· {page_label}")
                            item_type = st.selectbox(
                                "ìœ í˜•",
                                ["mcq", "cloze"],
                                index=0 if item.get("type") == "mcq" else 1,
                                key=f"edit_type_{i}"
                            )
                            if item_type == "mcq":
                                st.text_area("ë¬¸í•­", value=item.get("problem", ""), height=120, key=f"edit_problem_{i}")
                                opts = item.get("options", [])
                                st.text_area("ì„ ì§€ (í•œ ì¤„ì— í•˜ë‚˜)", value="\n".join(opts), height=140, key=f"edit_options_{i}")
                                ans_default = int(item.get("answer", 1)) if str(item.get("answer", "")).isdigit() else 1
                                st.selectbox("ì •ë‹µ", [1, 2, 3, 4, 5], index=max(0, min(ans_default - 1, 4)), key=f"edit_answer_{i}")
                            else:
                                st.text_area("ë¬¸í•­", value=item.get("front", ""), height=120, key=f"edit_front_{i}")
                                st.text_input("ì •ë‹µ", value=item.get("answer", ""), key=f"edit_answer_{i}")
                            st.text_area("í•´ì„¤", value=item.get("explanation", ""), height=120, key=f"edit_expl_{i}")
                            if image_options:
                                current_images = item.get("images", [])
                                current_indices = [idx for idx, img in enumerate(st.session_state.past_exam_images) if img.get("data_uri") in current_images]

                                img_pages = sorted({img.get("page") for img in st.session_state.past_exam_images if img.get("page")})
                                page_options = ["ì „ì²´"] + [f"p{p}" for p in img_pages]
                                page_filter = st.selectbox("ì´ë¯¸ì§€ í˜ì´ì§€ í•„í„°", page_options, key=f"img_page_filter_{i}")
                                per_page = st.slider("í˜ì´ì§€ë‹¹ ì´ë¯¸ì§€", 4, 24, 8, key=f"img_per_page_{i}")

                                filtered_indices = []
                                for idx_img, img in enumerate(st.session_state.past_exam_images):
                                    page = img.get("page")
                                    if page_filter != "ì „ì²´":
                                        wanted = int(page_filter.replace("p", ""))
                                        if page != wanted:
                                            continue
                                    filtered_indices.append(idx_img)

                                total_imgs = len(filtered_indices)
                                total_pages = max(1, (total_imgs + per_page - 1) // per_page)
                                page_idx = st.number_input("ì´ë¯¸ì§€ í˜ì´ì§€", 1, total_pages, 1, key=f"img_page_idx_{i}")
                                start = (page_idx - 1) * per_page
                                end = start + per_page
                                subset = filtered_indices[start:end]

                                cols = st.columns(4)
                                for j, idx_img in enumerate(subset):
                                    img = st.session_state.past_exam_images[idx_img]
                                    with cols[j % 4]:
                                        st.image(img.get("data_uri"), width=140, caption=image_label(idx_img))
                                        st.checkbox(
                                            "ì„ íƒ",
                                            value=idx_img in current_indices,
                                            key=f"edit_img_{i}_{idx_img}"
                                        )
                            st.checkbox("ì´ ë¬¸í•­ ì‚­ì œ", key=f"edit_delete_{i}")
                            st.divider()

                    if st.button("âœ… í¸ì§‘ ë‚´ìš© ì ìš©", use_container_width=True, key="apply_edits"):
                        new_items = []
                        for i in range(total_items):
                            if st.session_state.get(f"edit_delete_{i}"):
                                continue
                            item = items[i]
                            item_type = st.session_state.get(f"edit_type_{i}", item.get("type"))
                            if item_type == "mcq":
                                problem = st.session_state.get(f"edit_problem_{i}", item.get("problem", "")).strip()
                                options_text = st.session_state.get(f"edit_options_{i}", "\n".join(item.get("options", [])))
                                options = [o.strip() for o in options_text.splitlines() if o.strip()]
                                answer = st.session_state.get(f"edit_answer_{i}", item.get("answer", 1))
                                updated = {
                                    **item,
                                    "type": "mcq",
                                    "problem": problem,
                                    "options": options,
                                    "answer": int(answer) if str(answer).isdigit() else 1,
                                }
                            else:
                                front = st.session_state.get(f"edit_front_{i}", item.get("front", "")).strip()
                                answer = st.session_state.get(f"edit_answer_{i}", item.get("answer", "")).strip()
                                updated = {
                                    **item,
                                    "type": "cloze",
                                    "front": front,
                                    "answer": answer,
                                }
                            updated["explanation"] = st.session_state.get(f"edit_expl_{i}", item.get("explanation", "")).strip()
                            if image_options:
                                current_images = item.get("images", [])
                                current_indices = [idx for idx, img in enumerate(st.session_state.past_exam_images) if img.get("data_uri") in current_images]
                                sel_set = set(current_indices)
                                for idx_img in image_options:
                                    key = f"edit_img_{i}_{idx_img}"
                                    if key in st.session_state:
                                        if st.session_state.get(key):
                                            sel_set.add(idx_img)
                                        else:
                                            sel_set.discard(idx_img)
                                updated["images"] = [st.session_state.past_exam_images[idx]["data_uri"] for idx in sorted(sel_set)]
                            new_items.append(updated)
                        st.session_state.past_exam_items = new_items
                        st.success("í¸ì§‘ ë‚´ìš©ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()

            col_save, col_down = st.columns(2)
            with col_save:
                if st.button("ğŸ’¾ ë¬¸í•­ ì €ì¥", use_container_width=True, key="past_exam_save"):
                    current_items = st.session_state.get("past_exam_items", [])
                    added = add_questions_to_bank_auto(
                        current_items,
                        subject=exam_subject,
                        unit=exam_unit,
                        quality_filter=enable_filter,
                        min_length=min_length
                    )
                    st.success(f"âœ… {added}ê°œ ë¬¸í•­ ì €ì¥ ì™„ë£Œ")
            with col_down:
                download_data = json.dumps(items, ensure_ascii=False, indent=2)
                st.download_button(
                    label="ğŸ“¥ JSONìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=download_data,
                    file_name="converted_exam_questions.json",
                    mime="application/json",
                    use_container_width=True,
                    key="past_exam_download"
                )
        elif uploaded_exam:
            st.info("ë³€í™˜ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ëˆŒëŸ¬ ë¬¸í•­ì„ ìƒì„±í•˜ì„¸ìš”.")

if active_page == "exam":
    st.title("ğŸ¯ ì‹¤ì „ ëª¨ì˜ê³ ì‚¬")
    st.caption("ì´ íƒ­ì€ API í‚¤ ì—†ì´ë„ ì €ì¥ëœ ë¬¸í•­ìœ¼ë¡œ í•™ìŠµ/ì‹œí—˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    bank = load_questions()
    
    if not bank["text"] and not bank["cloze"]:
        st.warning("ğŸ“Œ ì €ì¥ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € **ğŸ“š ë¬¸ì œ ìƒì„±** íƒ­ì—ì„œ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.")
    else:
        st.info("ê¸°ì¶œë¬¸ì œ íŒŒì¼ ë³€í™˜ì€ **ğŸ§¾ ê¸°ì¶œë¬¸ì œ ë³€í™˜** íƒ­ì—ì„œ ì§„í–‰í•©ë‹ˆë‹¤.")
        if st.session_state.get("exam_mode_entry_anchor") and st.session_state.get("exam_questions"):
            st.success(
                f"ìƒì„± ê²°ê³¼ë¡œ {len(st.session_state.exam_questions)}ê°œ ë¬¸í•­ì´ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. "
                f"ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì¦‰ì‹œ í•™ìŠµ/ì‹œí—˜ì„ ì´ì–´ì„œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
            col_resume1, col_resume2 = st.columns(2)
            with col_resume1:
                if st.button("âœ… ì¤€ë¹„ëœ ì„¸ì…˜ ì´ì–´ í’€ê¸°", use_container_width=True, key="resume_prepared_exam"):
                    st.session_state.exam_started = True
                    st.session_state.exam_finished = False
                    st.session_state.current_question_idx = 0
                    st.session_state.exam_mode_entry_anchor = ""
                    st.rerun()
            with col_resume2:
                if st.button("ğŸ—‘ ì¤€ë¹„ ì„¸ì…˜ ì´ˆê¸°í™”", use_container_width=True, key="clear_prepared_exam"):
                    st.session_state.exam_started = False
                    st.session_state.exam_finished = False
                    st.session_state.exam_questions = []
                    st.session_state.current_question_idx = 0
                    st.session_state.exam_mode_entry_anchor = ""
                    st.rerun()

        # ì‹œí—˜/í•™ìŠµ ì„¤ì •
        if MOBILE_CLIENT:
            st.markdown("<div class='mobile-exam-caption'>ëª¨ë°”ì¼ í’€ì´ ëª¨ë“œ: í„°ì¹˜ ì¤‘ì‹¬ UI</div>", unsafe_allow_html=True)
            mode_choice = st.radio("ëª¨ë“œ", ["ì‹œí—˜ëª¨ë“œ", "í•™ìŠµëª¨ë“œ"], horizontal=False)
            exam_type = st.selectbox("ë¬¸í•­ ìœ í˜•", ["ê°ê´€ì‹", "ë¹ˆì¹¸"])
            mobile_image_width = max(220, min(640, int(st.session_state.image_display_width)))
            st.session_state.image_display_width = st.slider(
                "ë¬¸í•­ ì´ë¯¸ì§€ í¬ê¸°(px)",
                220,
                640,
                mobile_image_width,
                step=10,
                key="image_display_width_slider"
            )
        else:
            c_mode, c_type, c_img = st.columns([1.2, 1, 1])
            with c_mode:
                mode_choice = st.radio("ëª¨ë“œ", ["ì‹œí—˜ëª¨ë“œ", "í•™ìŠµëª¨ë“œ"], horizontal=True)
            with c_type:
                exam_type = st.selectbox("ë¬¸í•­ ìœ í˜•", ["ê°ê´€ì‹", "ë¹ˆì¹¸"])
            with c_img:
                st.session_state.image_display_width = st.slider(
                    "ë¬¸í•­ ì´ë¯¸ì§€ í¬ê¸°(px)",
                    240,
                    900,
                    st.session_state.image_display_width,
                    step=20,
                    key="image_display_width_slider"
                )

        questions_all = bank["text"] if exam_type == "ê°ê´€ì‹" else bank["cloze"]
        subject_unit_map = collect_subject_unit_map(questions_all)
        all_subjects = sorted(subject_unit_map.keys())
        if all_subjects:
            subject_keyword = st.text_input("ë¶„ê³¼ ê²€ìƒ‰", value="", placeholder="ë¶„ê³¼ëª… ì…ë ¥", key="exam_subject_search")
            subject_pool = [s for s in all_subjects if subject_keyword.lower() in s.lower()]
            if not subject_pool:
                subject_pool = ["(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"]
            if "exam_subject_multi" not in st.session_state:
                st.session_state["exam_subject_multi"] = list(all_subjects)
            selected_subjects = st.multiselect(
                "ë¶„ê³¼ ì„ íƒ",
                options=subject_pool if subject_pool != ["(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"] else [],
                key="exam_subject_multi"
            )
            if not selected_subjects:
                # ë¹ˆ ì„ íƒì€ ì „ì²´ ë³´ê¸°ë¡œ ë³µêµ¬í•´ ì‹¤ìˆ˜ë¡œ ì¸í•œ ë¹ˆ í™”ë©´ì„ ë°©ì§€
                selected_subjects = all_subjects

            unit_filter_by_subject = {}
            selected_units = []
            if selected_subjects:
                with st.expander("ë‹¨ì› ì„ íƒ (ë¶„ê³¼ë³„)", expanded=True):
                    for subj in selected_subjects:
                        units = subject_unit_map.get(subj, ["ë¯¸ë¶„ë¥˜"])
                        if not units:
                            units = ["ë¯¸ë¶„ë¥˜"]
                        unit_key = f"unit_filter_{subj}"
                        previous = st.session_state.get(unit_key, units)
                        default_units = previous if set(previous) <= set(units) else units
                        selected_units_for_subject = st.multiselect(
                            f"{subj} ë‹¨ì›",
                            options=units,
                            default=default_units,
                            key=unit_key
                        )
                        if not selected_units_for_subject:
                            selected_units_for_subject = list(units)
                        unit_filter_by_subject[subj] = selected_units_for_subject
                        selected_units.extend(selected_units_for_subject)
            else:
                unit_filter_by_subject = {}
                selected_units = []
            filtered_questions = filter_questions_by_subject_unit_hierarchy(questions_all, selected_subjects, unit_filter_by_subject)
        else:
            selected_subjects = []
            selected_units = []
            filtered_questions = []


        learning_session_mode = "íƒìƒ‰í˜•(ë‹¨ì› ì „ì²´)"
        bookmarked_only = False
        exam_distribution_mode = "ë¹„ë¡€(ë³´ìœ  ë¬¸í•­ ê¸°ì¤€)"
        exam_group_mode = "ë¶„ê³¼+ë‹¨ì›"
        exam_seed = None
        if mode_choice == "í•™ìŠµëª¨ë“œ":
            due_only = st.checkbox("ì˜¤ëŠ˜ ë³µìŠµë§Œ", value=False)
            bookmarked_only = st.checkbox("ë¶ë§ˆí¬ ë¬¸í•­ë§Œ", value=False)
            learning_session_mode = st.radio(
                "í•™ìŠµ ì„¸ì…˜ ë°©ì‹",
                ["íƒìƒ‰í˜•(ë‹¨ì› ì „ì²´)", "ëœë¤í˜•(ë¬¸í•­ ìˆ˜ ì„ íƒ)"],
                horizontal=True,
            )
            st.session_state.auto_next = st.checkbox("ìë™ ë‹¤ìŒ ë¬¸ì œ", value=st.session_state.auto_next)
            if due_only:
                filtered_questions = [q for q in filtered_questions if srs_due(q)]
            if bookmarked_only:
                filtered_questions = [q for q in filtered_questions if bool(q.get("bookmarked"))]
            if not FSRS_AVAILABLE:
                st.info("FSRS ë¯¸ì„¤ì¹˜: ê¸°ë³¸ ë³µìŠµ ì£¼ê¸°(SRS)ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
        else:
            st.session_state.auto_next = False
            exam_distribution_mode = st.radio(
                "ì¶œì œ ë¹„ìœ¨",
                ["ë¹„ë¡€(ë³´ìœ  ë¬¸í•­ ê¸°ì¤€)", "ê· ë“±(ì„ íƒ ê·¸ë£¹ ê¸°ì¤€)"],
                horizontal=True,
            )
            exam_group_mode = st.radio(
                "ì¶œì œ ê·¸ë£¹",
                ["ë¶„ê³¼+ë‹¨ì›", "ë¶„ê³¼"],
                horizontal=True,
            )
            use_seed = st.checkbox("ëœë¤ ì‹œë“œ ê³ ì •", value=False)
            if use_seed:
                exam_seed = int(st.number_input("ëœë¤ ì‹œë“œ", min_value=0, value=42, step=1))

        if mode_choice == "í•™ìŠµëª¨ë“œ":
            with st.expander("ğŸ“… FSRS ë³µìŠµ í", expanded=False):
                show_queue = st.checkbox("ë³µìŠµ í í‘œì‹œ", value=False, key="show_fsrs_queue")
                if show_queue:
                    if FSRS_AVAILABLE:
                        stats = get_fsrs_stats(filtered_questions)
                        if stats:
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("ì˜¤ëŠ˜ ë³µìŠµ", stats["due"])
                            with col2:
                                st.metric("ì—°ì²´", stats["overdue"])
                            with col3:
                                st.metric("ë¯¸ë˜", stats["future"])
                            with col4:
                                st.metric("ì‹ ê·œ", stats["new"])

                        due_list = get_fsrs_queue(filtered_questions, limit=20)
                        if not due_list:
                            st.info("ì˜¤ëŠ˜ ë³µìŠµí•  ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            rows = []
                            for q, due_time in due_list:
                                snippet = (q.get("problem") or q.get("front") or "").strip()
                                snippet = snippet[:80] + "..." if len(snippet) > 80 else snippet
                                rows.append({
                                    "ë¶„ê³¼": q.get("subject") or "General",
                                    "ë¬¸í•­": snippet,
                                    "Due": due_time.isoformat()
                                })
                            safe_dataframe(rows, use_container_width=True, hide_index=True)
                    else:
                        due_list = [q for q in filtered_questions if simple_srs_due(q)]
                        st.metric("ì˜¤ëŠ˜ ë³µìŠµ", len(due_list))
                        if not due_list:
                            st.info("ì˜¤ëŠ˜ ë³µìŠµí•  ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

            with st.expander("âš™ï¸ FSRS ì„¤ì •", expanded=False):
                if not FSRS_AVAILABLE:
                    st.info("FSRS íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì„¤ì •ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.caption("FSRS ì„¤ì •ì€ ë‹¤ìŒ ë³µìŠµë¶€í„° ì ìš©ë©ë‹ˆë‹¤.")
                    desired_retention = st.slider(
                        "ëª©í‘œ ê¸°ì–µ ìœ ì§€ìœ¨",
                        0.7,
                        0.98,
                        float(st.session_state.fsrs_desired_retention),
                        0.01,
                        key="fsrs_desired_retention_slider"
                    )
                    learning_steps_text = st.text_input(
                        "í•™ìŠµ ë‹¨ê³„(ë¶„, ì½¤ë§ˆ)",
                        value=st.session_state.fsrs_learning_steps_text,
                        key="fsrs_learning_steps_input"
                    )
                    relearning_steps_text = st.text_input(
                        "ì¬í•™ìŠµ ë‹¨ê³„(ë¶„, ì½¤ë§ˆ)",
                        value=st.session_state.fsrs_relearning_steps_text,
                        key="fsrs_relearning_steps_input"
                    )
                    max_interval = st.number_input(
                        "ìµœëŒ€ ê°„ê²©(ì¼)",
                        min_value=30,
                        max_value=365000,
                        value=int(st.session_state.fsrs_max_interval),
                        step=30,
                        key="fsrs_max_interval_input"
                    )
                    enable_fuzzing = st.checkbox(
                        "ê°„ê²© ëœë¤í™”(Fuzzing) ì‚¬ìš©",
                        value=bool(st.session_state.fsrs_enable_fuzzing),
                        key="fsrs_enable_fuzzing_input"
                    )
                    advanced = st.checkbox("ê³ ê¸‰: íŒŒë¼ë¯¸í„° ì§ì ‘ ì…ë ¥", value=False, key="fsrs_params_toggle")
                    params_text = None
                    if advanced:
                        params_text = st.text_area(
                            "FSRS parameters (JSON ë°°ì—´)",
                            value=st.session_state.fsrs_params_text,
                            height=120,
                            key="fsrs_params_input"
                        )
                        st.caption("íŒŒë¼ë¯¸í„°ë¥¼ ì˜ëª» ì…ë ¥í•˜ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")

                    col_a, col_b = st.columns(2)
                    with col_a:
                        if st.button("âœ… FSRS ì„¤ì • ì €ì¥", use_container_width=True, key="fsrs_save_btn"):
                            steps = [s.strip() for s in learning_steps_text.split(",") if s.strip()]
                            relearn_steps = [s.strip() for s in relearning_steps_text.split(",") if s.strip()]
                            try:
                                params = json.loads(params_text) if advanced and params_text else list(FSRS_DEFAULT_PARAMETERS)
                                if not isinstance(params, list) or len(params) < 10:
                                    params = list(FSRS_DEFAULT_PARAMETERS)
                            except Exception:
                                params = list(FSRS_DEFAULT_PARAMETERS)
                            settings = {
                                "desired_retention": float(desired_retention),
                                "learning_steps": [int(s) for s in steps if s.isdigit()],
                                "relearning_steps": [int(s) for s in relearn_steps if s.isdigit()],
                                "maximum_interval": int(max_interval),
                                "enable_fuzzing": bool(enable_fuzzing),
                                "parameters": params,
                            }
                            save_fsrs_settings(settings)
                            st.session_state.fsrs_desired_retention = settings["desired_retention"]
                            st.session_state.fsrs_learning_steps_text = ",".join(map(str, settings["learning_steps"]))
                            st.session_state.fsrs_relearning_steps_text = ",".join(map(str, settings["relearning_steps"]))
                            st.session_state.fsrs_max_interval = settings["maximum_interval"]
                            st.session_state.fsrs_enable_fuzzing = settings["enable_fuzzing"]
                            st.session_state.fsrs_params_text = json.dumps(settings["parameters"])
                            st.success("FSRS ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    with col_b:
                        if st.button("â†©ï¸ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”", use_container_width=True, key="fsrs_reset_btn"):
                            settings = load_fsrs_settings()
                            st.session_state.fsrs_desired_retention = settings["desired_retention"]
                            st.session_state.fsrs_learning_steps_text = ",".join(map(str, settings["learning_steps"]))
                            st.session_state.fsrs_relearning_steps_text = ",".join(map(str, settings["relearning_steps"]))
                            st.session_state.fsrs_max_interval = settings["maximum_interval"]
                            st.session_state.fsrs_enable_fuzzing = settings["enable_fuzzing"]
                            st.session_state.fsrs_params_text = json.dumps(settings["parameters"])
                            st.success("FSRS ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")

            with st.expander("ğŸ“ˆ ë³µìŠµ ë¦¬í¬íŠ¸", expanded=False):
                show_report = st.checkbox("ë¦¬í¬íŠ¸ í‘œì‹œ", value=False, key="show_fsrs_report")
                if show_report:
                    if FSRS_AVAILABLE:
                        report = get_fsrs_report(filtered_questions)
                        if report:
                            st.metric("ì´ ì¹´ë“œ", report["total"])
                            st.metric("ìµœê·¼ 7ì¼ ë¦¬ë·° ìˆ˜", report["review_count_7d"])
                            st.metric("í‰ê·  ê°„ê²©(ì¼)", f"{report['avg_interval']:.1f}")
                            if report["last_review"]:
                                st.caption(f"ë§ˆì§€ë§‰ ë¦¬ë·°: {report['last_review']}")

                            rating_rows = [{"í‰ê°€": k, "ê±´ìˆ˜": v} for k, v in report["rating_counts"].items()]
                            safe_dataframe(rating_rows, use_container_width=True, hide_index=True)
                        else:
                            st.info("ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ê¸°ë³¸ SRS ëª¨ë“œì—ì„œëŠ” ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        if questions_all:
            with st.expander("ğŸ“¤ ì‹œí—˜ì§€/ë¬¸ì œì§‘ ë‚´ë³´ë‚´ê¸°", expanded=False):
                st.caption("ì„ íƒí•œ ë¶„ê³¼ ë¬¸í•­ì„ 2ì—´(DOCX) í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤. ì¢Œì¸¡: ë¬¸í•­, ìš°ì¸¡: ì •ë‹µ/í•´ì„¤")
                export_title_default = f"AxiomaQbank_{exam_type}_ë¬¸ì œì§‘"
                export_title = st.text_input("ë¬¸ì„œ ì œëª©", value=export_title_default, key="export_docx_title")
                export_subjects = st.multiselect(
                    "ë‚´ë³´ë‚¼ ë¶„ê³¼ ì„ íƒ",
                    options=all_subjects,
                    default=[s for s in selected_subjects if s in all_subjects] if selected_subjects else all_subjects,
                    key="export_subjects"
                )
                export_include_all_units = st.checkbox(
                    "ì„ íƒ ë¶„ê³¼ ì „ì²´ ë¬¸í•­ ì‚¬ìš© (ë‹¨ì› í•„í„° ë¬´ì‹œ)",
                    value=True,
                    key="export_include_all_units"
                )
                export_unit_filter_by_subject = {}
                if not export_include_all_units and export_subjects:
                    st.markdown("**ë‚´ë³´ë‚¼ ë‹¨ì› ì„ íƒ**")
                    for subj in export_subjects:
                        export_units = subject_unit_map.get(subj, ["ë¯¸ë¶„ë¥˜"])
                        if not export_units:
                            export_units = ["ë¯¸ë¶„ë¥˜"]
                        export_unit_filter_by_subject[subj] = st.multiselect(
                            f"{subj} ë‹¨ì› (ë‚´ë³´ë‚´ê¸°)",
                            options=export_units,
                            default=export_units,
                            key=f"export_unit_filter_{subj}"
                        )
                export_randomize = st.checkbox("ëœë¤ ë°°ì¹˜ ëª¨ë“œ", value=False, key="export_randomize")
                export_seed = None
                if export_randomize:
                    export_seed = st.number_input("ëœë¤ ì‹œë“œ", min_value=0, value=42, step=1, key="export_random_seed")
                if export_subjects:
                    export_candidates = collect_export_questions(
                        questions_all,
                        export_subjects,
                        export_unit_filter_by_subject,
                        include_all_units=export_include_all_units,
                        randomize=export_randomize,
                        random_seed=export_seed
                    )
                else:
                    export_candidates = []
                st.caption(f"ë‚´ë³´ë‚´ê¸° ëŒ€ìƒ ë¬¸í•­: {len(export_candidates)}ê°œ")
                if st.button("DOCX ìƒì„±", key="build_docx_export", use_container_width=True):
                    if not export_candidates:
                        st.warning("ë‚´ë³´ë‚¼ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ë¶„ê³¼/ë‹¨ì› ì„ íƒì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    else:
                        st.session_state.export_docx_bytes = build_docx_question_sheet(export_candidates, title=export_title)
                        st.success("DOCX ìƒì„± ì™„ë£Œ")
                if st.session_state.get("export_docx_bytes"):
                    st.download_button(
                        "ğŸ“¥ DOCX ë‹¤ìš´ë¡œë“œ",
                        data=st.session_state.export_docx_bytes,
                        file_name=f"{export_title}.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key="download_docx_export",
                        use_container_width=True
                    )
        else:
            st.session_state.export_docx_bytes = b""

        if not filtered_questions:
            st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            max_questions = len(filtered_questions)
            max_limit = min(150, max(1, max_questions))
            if mode_choice == "í•™ìŠµëª¨ë“œ" and str(learning_session_mode).startswith("íƒìƒ‰í˜•"):
                num_questions = max_questions
                st.caption(f"íƒìƒ‰í˜•: ì„ íƒí•œ ë²”ìœ„ì˜ {max_questions}ë¬¸í•­ ì „ì²´ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
            else:
                default_num = min(10, max_limit)
                num_questions = st.slider("ë¬¸í•­ ìˆ˜", 1, max_limit, default_num)

            start_label = "ğŸ“ ì‹œí—˜ ì‹œì‘" if mode_choice == "ì‹œí—˜ëª¨ë“œ" else "ğŸ“– í•™ìŠµ ì‹œì‘"
            if st.button(start_label, use_container_width=True, key="start_exam"):
                if len(filtered_questions) < num_questions:
                    st.warning(f"ë¬¸ì œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. {len(filtered_questions)}ê°œë§Œ ì¶œì œí•©ë‹ˆë‹¤.")
                    num_questions = len(filtered_questions)

                if mode_choice == "ì‹œí—˜ëª¨ë“œ":
                    raw_selected = select_exam_questions_balanced(
                        filtered_questions,
                        num_questions,
                        distribution_mode=exam_distribution_mode,
                        group_mode=exam_group_mode,
                        random_seed=exam_seed,
                    )
                else:
                    raw_selected = select_learning_session_questions(
                        filtered_questions,
                        learning_mode=learning_session_mode,
                        num_questions=num_questions,
                        random_seed=exam_seed,
                    )
                distribution_counts = {}
                if mode_choice == "ì‹œí—˜ëª¨ë“œ":
                    for q_raw in raw_selected:
                        gk = _exam_group_key(q_raw, group_mode=exam_group_mode)
                        distribution_counts[gk] = int(distribution_counts.get(gk, 0)) + 1
                parsed_selected = []
                for raw in raw_selected:
                    if exam_type == "ê°ê´€ì‹":
                        parsed = parse_mcq_content(raw)
                    else:
                        parsed = parse_cloze_content(raw)
                    parsed_selected.append(parsed)

                st.session_state.exam_questions = parsed_selected
                st.session_state.current_question_idx = 0
                st.session_state.user_answers = {}
                st.session_state.exam_started = True
                st.session_state.exam_finished = False
                st.session_state.exam_mode = mode_choice
                st.session_state.exam_type = exam_type
                st.session_state.auto_advance_guard = None
                st.session_state.revealed_answers = set()
                st.session_state.exam_stats_applied = False
                st.session_state.graded_questions = set()
                st.session_state.exam_history_saved = False
                st.session_state.current_exam_meta = {
                    "mode": mode_choice,
                    "type": exam_type,
                    "subjects": selected_subjects,
                    "units": selected_units,
                    "num_questions": len(parsed_selected),
                    "learning_session_mode": learning_session_mode if mode_choice == "í•™ìŠµëª¨ë“œ" else "",
                    "distribution_mode": exam_distribution_mode if mode_choice == "ì‹œí—˜ëª¨ë“œ" else "",
                    "distribution_group_mode": exam_group_mode if mode_choice == "ì‹œí—˜ëª¨ë“œ" else "",
                    "distribution_counts": distribution_counts if mode_choice == "ì‹œí—˜ëª¨ë“œ" else {},
                    "seed": exam_seed,
                    "started_at": datetime.now(timezone.utc).isoformat()
                }

        # ì‹œí—˜/í•™ìŠµ ì§„í–‰
        if st.session_state.exam_started and st.session_state.exam_questions:
            exam_qs = st.session_state.exam_questions
            idx = st.session_state.current_question_idx

            if st.session_state.exam_finished:
                st.markdown("## ğŸ“Š ê²°ê³¼")

                total = len(exam_qs)
                answered = len(st.session_state.user_answers)

                # ì •ë‹µ ì±„ì 
                correct_count = 0
                wrong_indices = []
                for i, q in enumerate(exam_qs):
                    if i not in st.session_state.user_answers:
                        continue

                    user_ans = st.session_state.user_answers[i]
                    if is_answer_correct(q, user_ans):
                        correct_count += 1
                    else:
                        wrong_indices.append(i)

                # í†µê³„ ì—…ë°ì´íŠ¸ (ì‹œí—˜ ê²°ê³¼ 1íšŒë§Œ, ì´ë¯¸ ë°˜ì˜ëœ ë¬¸í•­ì€ ì œì™¸)
                if not st.session_state.exam_stats_applied:
                    for i, q in enumerate(exam_qs):
                        if i in st.session_state.user_answers and q.get("id"):
                            if q.get("id") in st.session_state.graded_questions:
                                continue
                            user_ans = st.session_state.user_answers[i]
                            is_correct = is_answer_correct(q, user_ans)
                            updated_stats = update_question_stats(q["id"], is_correct)
                            if isinstance(updated_stats, dict):
                                q["stats"] = updated_stats
                            st.session_state.graded_questions.add(q.get("id"))
                    st.session_state.exam_stats_applied = True

                # ì‹œí—˜ ê¸°ë¡ ì €ì¥ (ì‹œí—˜ëª¨ë“œë§Œ)
                if st.session_state.exam_mode == "ì‹œí—˜ëª¨ë“œ" and not st.session_state.exam_history_saved:
                    items = []
                    for i, q in enumerate(exam_qs):
                        user_ans = st.session_state.user_answers.get(i)
                        items.append({
                            "id": q.get("id"),
                            "type": q.get("type"),
                            "front": q.get("front"),
                            "options": q.get("options"),
                            "correct": q.get("correct"),
                            "answer": q.get("answer"),
                            "user": user_ans,
                            "is_correct": is_answer_correct(q, user_ans) if user_ans is not None else False,
                            "explanation": q.get("explanation"),
                            "subject": q.get("subject"),
                            "difficulty": q.get("difficulty"),
                            "note": q.get("note", ""),
                        })
                    meta = st.session_state.current_exam_meta or {}
                    session = {
                        "session_id": str(uuid.uuid4()),
                        "finished_at": datetime.now(timezone.utc).isoformat(),
                        "mode": meta.get("mode", st.session_state.exam_mode),
                        "type": meta.get("type", st.session_state.exam_type),
                        "subjects": meta.get("subjects", []),
                        "num_questions": len(exam_qs),
                        "answered": answered,
                        "correct": correct_count,
                        "accuracy": int(correct_count / answered * 100) if answered > 0 else 0,
                        "items": items
                    }
                    add_exam_history(session)
                    st.session_state.exam_history_saved = True

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì •ë‹µ", f"{correct_count}/{answered}")
                with col2:
                    st.metric("ë¯¸ì‘ë‹µ", f"{total - answered}")
                with col3:
                    accuracy = int(correct_count / answered * 100) if answered > 0 else 0
                    st.metric("ì •í™•ë„", f"{accuracy}%")
                with col4:
                    st.metric("ìƒíƒœ", "âœ… ì™„ë£Œ" if answered == total else "âš ï¸ ë¯¸ì™„ë£Œ")

                st.markdown("---")

                # ìƒì„¸ ë³´ê¸°
                letters = ['A', 'B', 'C', 'D', 'E']
                for i, q in enumerate(exam_qs, 1):
                    user_ans = st.session_state.user_answers.get(i - 1, None)
                    is_correct = False
                    correct_text = ""
                    correct_display = ""

                    if q.get('type') == 'mcq':
                        correct_num = q.get('correct')  # ìˆ«ì í˜•ì‹: 1-5
                        correct_text = str(correct_num)
                        correct_display = letters[correct_num - 1] if 1 <= correct_num <= 5 else "?"
                        is_correct = (user_ans == correct_num) if user_ans else False
                        user_ans_display = letters[user_ans - 1] if user_ans and 1 <= user_ans <= 5 else "ì‘ë‹µ ì—†ìŒ"
                    else:
                        response_type = q.get("response_type", "cloze")
                        correct_text = q.get('answer') or ""
                        correct_display = correct_text
                        if response_type == "essay":
                            ai_grade = q.get("_ai_grade") if isinstance(q.get("_ai_grade"), dict) else {}
                            is_correct = bool(ai_grade.get("is_correct", False))
                        else:
                            is_correct = fuzzy_match(user_ans, correct_text) if user_ans and correct_text else False
                        user_ans_display = user_ans if user_ans else "ì‘ë‹µ ì—†ìŒ"

                    status_icon = "âœ…" if is_correct else "âŒ"
                    with st.expander(f"{status_icon} ë¬¸ì œ {i}: {user_ans_display}"):
                        st.markdown(q.get('front', q.get('raw', '')))

                        if q.get('type') == 'mcq':
                            st.markdown("**ì„ íƒì§€:**")
                            opts = q.get('options') or []
                            for idx_opt, opt in enumerate(opts[:5]):
                                label = f"{letters[idx_opt]}. {opt}"
                                st.write(label)

                        st.divider()
                        st.write(f"**ë‹¹ì‹ ì˜ ë‹µ:** {user_ans_display}")
                        answer_color = "ğŸŸ¢" if is_correct else "ğŸ”´"
                        st.write(f"{answer_color} **ì •ë‹µ:** {correct_display}")
                        if q.get("response_type") == "essay":
                            if isinstance(q.get("_ai_grade"), dict):
                                st.write(f"AI ì ìˆ˜: {q['_ai_grade'].get('score', 0)} / 100")
                                feedback = q["_ai_grade"].get("feedback")
                                if feedback:
                                    st.write(f"AI í”¼ë“œë°±: {feedback}")
                            else:
                                st.caption("ì„œìˆ í˜•ì€ AI ì±„ì  ì‹¤í–‰ ì „ê¹Œì§€ ì •ì˜¤ íŒì •ì´ í™•ì •ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        if q.get("explanation"):
                            show_exp = st.checkbox("í•´ì„¤ ë³´ê¸°", value=st.session_state.explanation_default, key=f"show_exp_{i}")
                            if show_exp:
                                st.markdown(format_explanation_text(q.get('explanation')))
                        if q.get("subject"):
                            st.caption(f"ğŸ“Œ {q['subject']}")
                        if q.get("unit"):
                            st.caption(f"ë‹¨ì›: {q.get('unit')}")
                        if q.get("difficulty"):
                            st.caption(f"ë‚œì´ë„: {q.get('difficulty', '?')}")
                        if q.get("id"):
                            note_key = f"review_note_{i}"
                            st.text_area("ë©”ëª¨", value=q.get("note", ""), key=note_key, height=80)
                            if st.button("ë©”ëª¨ ì €ì¥", key=f"save_review_note_{i}"):
                                saved = update_question_note(q["id"], st.session_state.get(note_key, ""))
                                if saved:
                                    q["note"] = st.session_state.get(note_key, "")
                                    st.success("ë©”ëª¨ ì €ì¥ë¨")

                # ì˜¤ë‹µë…¸íŠ¸
                if wrong_indices:
                    if st.button("ğŸ“Œ ì˜¤ë‹µë…¸íŠ¸ë¡œ ë‹¤ì‹œ í’€ê¸°"):
                        wrong_qs = [exam_qs[i] for i in wrong_indices]
                        st.session_state.exam_questions = wrong_qs
                        st.session_state.user_answers = {}
                        st.session_state.current_question_idx = 0
                        st.session_state.exam_started = True
                        st.session_state.exam_finished = False
                        st.session_state.exam_mode = "í•™ìŠµëª¨ë“œ"
                        st.session_state.revealed_answers = set()
                        st.session_state.auto_advance_guard = None
                        st.session_state.exam_stats_applied = False
                        st.session_state.graded_questions = set()
                        st.rerun()

                if st.button("ğŸ”„ ë‹¤ì‹œ ì‹œì‘"):
                    st.session_state.exam_started = False
                    st.session_state.exam_finished = False
                    st.session_state.exam_questions = []
                    st.session_state.user_answers = {}
                    st.session_state.current_question_idx = 0
                    st.rerun()



            else:
                if idx < len(exam_qs):
                    q = exam_qs[idx]
                    st.progress((idx + 1) / len(exam_qs))
                    st.caption(f"USMLE ìŠ¤íƒ€ì¼ | Question {idx + 1} of {len(exam_qs)}")
                    nav_slot = st.empty()
                    unanswered_slot = st.empty()
                    st.markdown(f"### Question {idx + 1}")
                    if q.get("type") != "mcq":
                        rt = q.get("response_type", "cloze")
                        rt_label = "ë¹ˆì¹¸í˜•" if rt == "cloze" else ("ë‹¨ë‹µí˜•" if rt == "short" else "ì„œìˆ í˜•")
                        st.caption(f"ìœ í˜•: {rt_label}")

                    # ì…ë ¥
                    if q.get('type') == 'mcq':
                        st.markdown(q.get('front', ''))
                        if q.get("images"):
                            st.image(q.get("images"), width=st.session_state.image_display_width)

                        st.markdown("**Select one option (Aâ€“E):**")
                        opts = q.get('options') or []
                        letters = ['A', 'B', 'C', 'D', 'E']
                        prev_ans = st.session_state.user_answers.get(idx)
                        default_index = (prev_ans - 1) if isinstance(prev_ans, int) and 1 <= prev_ans <= 5 else None
                        if opts:
                            labels_real = [f"{letters[i]}. {opts[i]}" for i in range(min(len(opts), len(letters)))]
                            st.session_state[f"labels_real_{idx}"] = labels_real
                            user_choice_label = st.radio("ì •ë‹µ ì„ íƒ:", labels_real, index=default_index, key=f"q_{idx}")
                            if user_choice_label:
                                chosen_num = letters.index(user_choice_label.split(".")[0]) + 1
                                st.session_state.user_answers[idx] = chosen_num
                            else:
                                st.session_state.user_answers.pop(idx, None)
                        else:
                            st.session_state[f"labels_real_{idx}"] = letters
                            user_choice = st.radio("ì •ë‹µ ì„ íƒ:", letters, index=default_index, key=f"q_{idx}")
                            if user_choice:
                                chosen_num = letters.index(user_choice) + 1
                                st.session_state.user_answers[idx] = chosen_num
                            else:
                                st.session_state.user_answers.pop(idx, None)

                        if not MOBILE_CLIENT:
                            st.text_input(
                                "í‚¤ë³´ë“œ ì…ë ¥ (A-E ë˜ëŠ” 1-5)",
                                key=f"shortcut_{idx}",
                                on_change=apply_mcq_shortcut,
                                args=(idx,)
                            )

                        if idx in st.session_state.user_answers:
                            your = st.session_state.user_answers[idx]
                            your_letter = letters[your - 1] if 1 <= your <= 5 else "?"
                            st.caption(f"ğŸ“ Your answer: {your_letter}")
                    else:
                        st.markdown(q.get('front', q.get('raw', '')))
                        if q.get("images"):
                            st.image(q.get("images"), width=st.session_state.image_display_width)
                        prev_text = st.session_state.user_answers.get(idx, "")
                        response_type = q.get("response_type", "cloze")
                        if response_type == "essay":
                            user_input = st.text_area("ì„œìˆ í˜• ë‹µì•ˆ ì…ë ¥:", value=prev_text, key=f"cloze_{idx}", height=160)
                        elif response_type == "short":
                            user_input = st.text_input("ë‹¨ë‹µí˜• ì •ë‹µ ì…ë ¥:", value=prev_text, key=f"cloze_{idx}")
                        else:
                            user_input = st.text_input("ì •ë‹µ ì…ë ¥ (í•œê¸€/ì˜ë¬¸):", value=prev_text, key=f"cloze_{idx}")
                        if user_input:
                            st.session_state.user_answers[idx] = user_input
                        elif idx in st.session_state.user_answers:
                            st.session_state.user_answers.pop(idx, None)

                        if response_type == "essay" and user_input:
                            if st.button("ğŸ§  AI ì±„ì  (ì„œìˆ í˜•)", key=f"grade_essay_{idx}"):
                                if st.session_state.ai_model == "ğŸ”µ Google Gemini" and not api_key:
                                    st.error("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                                elif st.session_state.ai_model == "ğŸŸ¢ OpenAI ChatGPT" and not openai_api_key:
                                    st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                                else:
                                    with st.spinner("AI ì±„ì  ì¤‘..."):
                                        grade, err = grade_essay_answer_ai(
                                            q,
                                            user_input,
                                            ai_model=st.session_state.ai_model,
                                            api_key=api_key,
                                            openai_api_key=openai_api_key
                                        )
                                    if grade:
                                        q["_ai_grade"] = grade
                                        st.success(f"AI ì±„ì  ì™„ë£Œ: {grade.get('score', 0)}ì ")
                                    else:
                                        st.warning(f"AI ì±„ì  ì‹¤íŒ¨: {err}")
                        if response_type == "essay" and isinstance(q.get("_ai_grade"), dict):
                            st.caption(f"AI ì ìˆ˜: {q['_ai_grade'].get('score', 0)} / 100")
                            feedback = q["_ai_grade"].get("feedback")
                            if feedback:
                                st.caption(f"í”¼ë“œë°±: {feedback}")

                    # ëˆ„ì  í’€ì´ ì •ë³´ + ë¶ë§ˆí¬
                    attempt = get_question_attempt_summary(q)
                    if attempt["attempts"] > 0:
                        last_dt = parse_iso_datetime(attempt.get("last_time"))
                        last_text = ""
                        if last_dt:
                            if last_dt.tzinfo is None:
                                last_dt = last_dt.replace(tzinfo=timezone.utc)
                            last_text = last_dt.astimezone().strftime("%Y-%m-%d %H:%M")
                        verdict = "ì •ë‹µ" if attempt.get("last_correct") is True else ("ì˜¤ë‹µ" if attempt.get("last_correct") is False else "-")
                        info = f"ëˆ„ì  í’€ì´ {attempt['attempts']}íšŒ (ì • {attempt['right']} / ì˜¤ {attempt['wrong']}) Â· ìµœê·¼ {verdict}"
                        if last_text:
                            info += f" Â· {last_text}"
                        st.caption(info)
                    else:
                        st.caption("ì²« í’€ì´ ë¬¸í•­")

                    if q.get("id"):
                        mark_label = "â­ ë‹¤ì‹œë³´ê¸° í•´ì œ" if q.get("bookmarked") else "â˜† ë‹¤ì‹œë³´ê¸° ì €ì¥"
                        if st.button(mark_label, key=f"bookmark_{idx}", use_container_width=False):
                            new_mark = not bool(q.get("bookmarked"))
                            if update_question_bookmark(q["id"], new_mark):
                                q["bookmarked"] = new_mark
                                st.success("ë‹¤ì‹œë³´ê¸° ëª©ë¡ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.rerun()

                    # ë¬¸í•­ ì´ë™/ë¯¸ì‘ë‹µ (ë‹µì•ˆ ë°˜ì˜ í›„ ê°±ì‹ )
                    answered_idx = set(st.session_state.user_answers.keys())
                    nav_options = list(range(len(exam_qs)))

                    def nav_format(i):
                        star = "â­ " if exam_qs[i].get("bookmarked") else ""
                        status = "âœ…" if i in answered_idx else "â—‹"
                        return f"{i + 1} {star}{status}"

                    if MOBILE_CLIENT:
                        nav_idx = nav_slot.select_slider(
                            "ë¬¸í•­ ì´ë™",
                            options=nav_options,
                            value=idx,
                            format_func=nav_format,
                            key="nav_select_mobile",
                        )
                    else:
                        nav_idx = nav_slot.selectbox(
                            "ë¬¸í•­ ì´ë™",
                            nav_options,
                            index=idx,
                            format_func=nav_format,
                            key="nav_select",
                        )
                    if nav_idx != idx:
                        st.session_state.current_question_idx = nav_idx

                    unanswered = [str(i + 1) for i in range(len(exam_qs)) if i not in answered_idx]
                    if unanswered:
                        unanswered_slot.caption(f"ë¯¸ì‘ë‹µ: {', '.join(unanswered)}")

                    # ë©”ëª¨
                    if q.get("id"):
                        note_key = f"note_{idx}"
                        st.text_area("ë©”ëª¨", value=q.get("note", ""), key=note_key, height=80)
                        if st.button("ë©”ëª¨ ì €ì¥", key=f"save_note_{idx}"):
                            saved = update_question_note(q["id"], st.session_state.get(note_key, ""))
                            if saved:
                                q["note"] = st.session_state.get(note_key, "")
                                st.success("ë©”ëª¨ ì €ì¥ë¨")

                    # í•™ìŠµëª¨ë“œ: ì •ë‹µ í™•ì¸ í›„ í‘œì‹œ
                    if st.session_state.exam_mode == "í•™ìŠµëª¨ë“œ" and idx in st.session_state.user_answers:
                        st.markdown("---")
                        reveal_key = f"reveal_{idx}"
                        if st.button("ì •ë‹µ í™•ì¸", key=reveal_key):
                            st.session_state.revealed_answers.add(idx)

                        if idx in st.session_state.revealed_answers:
                            if q.get('type') == 'mcq':
                                correct_num = q.get('correct')
                                correct_display = letters[correct_num - 1] if isinstance(correct_num, int) and 1 <= correct_num <= 5 else "?"
                                is_correct = (st.session_state.user_answers[idx] == correct_num) if correct_num else False
                            else:
                                response_type = q.get("response_type", "cloze")
                                correct_text = q.get('answer') or ""
                                if response_type == "essay":
                                    if st.button("ğŸ§  AI ì±„ì  ì‹¤í–‰", key=f"learn_grade_essay_{idx}"):
                                        if st.session_state.ai_model == "ğŸ”µ Google Gemini" and not api_key:
                                            st.error("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                                        elif st.session_state.ai_model == "ğŸŸ¢ OpenAI ChatGPT" and not openai_api_key:
                                            st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                                        else:
                                            with st.spinner("AI ì±„ì  ì¤‘..."):
                                                grade, err = grade_essay_answer_ai(
                                                    q,
                                                    st.session_state.user_answers[idx],
                                                    ai_model=st.session_state.ai_model,
                                                    api_key=api_key,
                                                    openai_api_key=openai_api_key
                                                )
                                            if grade:
                                                q["_ai_grade"] = grade
                                            else:
                                                st.warning(f"AI ì±„ì  ì‹¤íŒ¨: {err}")
                                    is_correct = bool(isinstance(q.get("_ai_grade"), dict) and q["_ai_grade"].get("is_correct"))
                                else:
                                    is_correct = fuzzy_match(st.session_state.user_answers[idx], correct_text) if correct_text else False
                                correct_display = correct_text

                            answer_color = "ğŸŸ¢" if is_correct else "ğŸ”´"
                            st.write(f"{answer_color} **ì •ë‹µ:** {correct_display}")
                            if q.get("response_type") == "essay":
                                if isinstance(q.get("_ai_grade"), dict):
                                    st.write(f"AI ì ìˆ˜: {q['_ai_grade'].get('score', 0)} / 100")
                                    feedback = q["_ai_grade"].get("feedback")
                                    if feedback:
                                        st.write(f"AI í”¼ë“œë°±: {feedback}")
                                else:
                                    st.info("ì„œìˆ í˜•ì€ AI ì±„ì  ì‹¤í–‰ í›„ ì •ì˜¤ íŒì •ì´ ë°˜ì˜ë©ë‹ˆë‹¤.")
                            # í•™ìŠµëª¨ë“œ í†µê³„ ì—…ë°ì´íŠ¸ (1íšŒ)
                            if q.get("id") and q.get("id") not in st.session_state.graded_questions:
                                updated_stats = update_question_stats(q["id"], is_correct)
                                if isinstance(updated_stats, dict):
                                    q["stats"] = updated_stats
                                st.session_state.graded_questions.add(q.get("id"))
                            explanation_text = q.get("explanation") or q.get("rationale") or q.get("analysis") or ""
                            show_exp = st.checkbox("í•´ì„¤ ë³´ê¸°", value=st.session_state.explanation_default, key=f"learn_exp_{idx}")
                            if show_exp:
                                if explanation_text.strip():
                                    st.markdown(format_explanation_text(explanation_text))
                                else:
                                    st.caption("í•´ì„¤ì´ ì—†ìŠµë‹ˆë‹¤.")
                                    if st.button("AI í•´ì„¤ ìƒì„±", key=f"ai_exp_{idx}"):
                                        if st.session_state.ai_model == "ğŸ”µ Google Gemini" and not api_key:
                                            st.error("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                                        elif st.session_state.ai_model == "ğŸŸ¢ OpenAI ChatGPT" and not openai_api_key:
                                            st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                                        else:
                                            with st.spinner("AI í•´ì„¤ ìƒì„± ì¤‘..."):
                                                text, err = generate_single_explanation_ai(
                                                    q,
                                                    ai_model=st.session_state.ai_model,
                                                    api_key=api_key,
                                                    openai_api_key=openai_api_key,
                                                    return_error=True
                                                )
                                            if text:
                                                q["explanation"] = text
                                                if q.get("id"):
                                                    update_question_explanation(q["id"], text)
                                                st.success("í•´ì„¤ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                                st.markdown(format_explanation_text(text))
                                            else:
                                                msg = f"í•´ì„¤ ìƒì„± ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                                                if err:
                                                    msg += f" (ì—ëŸ¬: {err})"
                                                st.warning(msg)

                            if q.get("id"):
                                st.markdown("**ë³µìŠµ í‰ê°€**")
                                cols = st.columns(4)
                                if cols[0].button("Again", key=f"srs_again_{idx}"):
                                    rating = Rating.Again if FSRS_AVAILABLE else "Again"
                                    srs = apply_srs_rating(q["id"], rating)
                                    if srs:
                                        q["fsrs"] = srs if FSRS_AVAILABLE else q.get("fsrs")
                                        st.success(f"ë‹¤ìŒ ë³µìŠµ: {srs.get('due')}")
                                if cols[1].button("Hard", key=f"srs_hard_{idx}"):
                                    rating = Rating.Hard if FSRS_AVAILABLE else "Hard"
                                    srs = apply_srs_rating(q["id"], rating)
                                    if srs:
                                        q["fsrs"] = srs if FSRS_AVAILABLE else q.get("fsrs")
                                        st.success(f"ë‹¤ìŒ ë³µìŠµ: {srs.get('due')}")
                                if cols[2].button("Good", key=f"srs_good_{idx}"):
                                    rating = Rating.Good if FSRS_AVAILABLE else "Good"
                                    srs = apply_srs_rating(q["id"], rating)
                                    if srs:
                                        q["fsrs"] = srs if FSRS_AVAILABLE else q.get("fsrs")
                                        st.success(f"ë‹¤ìŒ ë³µìŠµ: {srs.get('due')}")
                                if cols[3].button("Easy", key=f"srs_easy_{idx}"):
                                    rating = Rating.Easy if FSRS_AVAILABLE else "Easy"
                                    srs = apply_srs_rating(q["id"], rating)
                                    if srs:
                                        q["fsrs"] = srs if FSRS_AVAILABLE else q.get("fsrs")
                                        st.success(f"ë‹¤ìŒ ë³µìŠµ: {srs.get('due')}")

                    # í•™ìŠµëª¨ë“œ ìë™ ë‹¤ìŒ ë¬¸ì œ
                    if st.session_state.exam_mode == "í•™ìŠµëª¨ë“œ" and st.session_state.auto_next:
                        guard = st.session_state.auto_advance_guard
                        current_answer = st.session_state.user_answers.get(idx)
                        if current_answer and idx in st.session_state.revealed_answers and guard != (idx, str(current_answer)) and idx < len(exam_qs) - 1:
                            st.session_state.auto_advance_guard = (idx, str(current_answer))
                            st.session_state.current_question_idx += 1
                            st.rerun()

                    # ë„¤ë¹„ê²Œì´ì…˜
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.button("â¬…ï¸ ì´ì „", on_click=goto_prev_question, disabled=idx <= 0)
                    with col2:
                        st.button("ë‹¤ìŒ â¡ï¸", on_click=goto_next_question, disabled=idx >= len(exam_qs) - 1)
                    with col3:
                        if st.session_state.exam_mode == "ì‹œí—˜ëª¨ë“œ":
                            if idx == len(exam_qs) - 1:
                                st.button("âœ… ì±„ì ", on_click=finish_exam_session)
                        else:
                            if idx == len(exam_qs) - 1:
                                st.button("âœ… ì„¸ì…˜ ì¢…ë£Œ", on_click=finish_exam_session)
